
 <!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="UTF-8">
  
    <title>机器学习中的数学：（二）解析几何 | Hexo</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=3, minimum-scale=1">
    
    <meta name="author" content="John Doe">
    
    <meta name="description" content="解析几何(Analytic Geometry)这章将从几何的角度理解之前提及的一些概念。
范数(Norm)范数实际上就是向量的一个长度范数有以下性质：

第一个绝对齐次（？）实际上数量积不就是对向量长度的一个延伸，所以，缩放的量可以提出来。
第二个三角不等式，因为两个向量和这两个向量的向量和会形成一">
    
    
    
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/pacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/pacman.jpg">
    
    
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head>

  <body>
    <header>
      <div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.svg" alt="Hexo" title="Hexo"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Hexo">Hexo</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
					<li>
					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="text" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:Baymine.github.io">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>

    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2021/04/22/机器学习中的数学：（二）解析几何/" title="机器学习中的数学：（二）解析几何" itemprop="url">机器学习中的数学：（二）解析几何</a>
  </h1>
  <p class="article-author">By
    
      <a href="https://Baymine.github.io" title="John Doe">John Doe</a>
    </p>
  <p class="article-time">
    <time datetime="2021-04-22T07:17:46.000Z" itemprop="datePublished">2021-04-22</time>
    Updated:<time datetime="2023-03-08T11:49:30.857Z" itemprop="dateModified">2023-03-08</time>
    
  </p>
</header>
	<div class="article-content">
		
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">Contents</strong>
		<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A7%A3%E6%9E%90%E5%87%A0%E4%BD%95-Analytic-Geometry"><span class="toc-number">1.</span> <span class="toc-text">解析几何(Analytic Geometry)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8C%83%E6%95%B0-Norm"><span class="toc-number">1.1.</span> <span class="toc-text">范数(Norm)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9B%BC%E5%93%88%E9%A1%BF%E8%8C%83%E6%95%B0%EF%BC%88Manhattan-Norm%EF%BC%89"><span class="toc-number">1.1.1.</span> <span class="toc-text">曼哈顿范数（Manhattan Norm）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E8%8C%83%E6%95%B0%EF%BC%88Euclidean-Norm%EF%BC%89"><span class="toc-number">1.1.2.</span> <span class="toc-text">欧几里得范数（Euclidean Norm）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E7%A7%AF%EF%BC%88Inner-Product%EF%BC%89"><span class="toc-number">1.2.</span> <span class="toc-text">内积（Inner Product）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%BF%E4%B9%89%E5%86%85%E7%A7%AF"><span class="toc-number">1.2.1.</span> <span class="toc-text">广义内积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E7%A7%B0%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5%EF%BC%88Symmetric-Positive-Definite-Matrices%EF%BC%89"><span class="toc-number">1.2.2.</span> <span class="toc-text">对称正定矩阵（Symmetric, Positive Definite Matrices）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%95%BF%E5%BA%A6%E4%B8%8E%E8%B7%9D%E7%A6%BB%EF%BC%88Lengths-and-Distances%EF%BC%89"><span class="toc-number">1.3.</span> <span class="toc-text">长度与距离（Lengths and Distances）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%B9%E8%A7%92%E4%B8%8E%E6%AD%A3%E4%BA%A4%E6%80%A7-Angles-and-Orthogonality"><span class="toc-number">1.4.</span> <span class="toc-text">夹角与正交性(Angles and Orthogonality)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%84%E8%8C%83%E6%AD%A3%E4%BA%A4%E5%9F%BA%EF%BC%88Orthonormal-Basis%EF%BC%89"><span class="toc-number">1.4.1.</span> <span class="toc-text">规范正交基（Orthonormal Basis）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E4%BA%A4%E8%A1%A5%EF%BC%88Orthogonal-Complement%EF%BC%89"><span class="toc-number">1.4.2.</span> <span class="toc-text">正交补（Orthogonal Complement）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E7%9A%84%E5%86%85%E7%A7%AF"><span class="toc-number">1.5.</span> <span class="toc-text">函数的内积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E4%BA%A4%E6%8A%95%E5%BD%B1%EF%BC%88Orthogonal-Projections%EF%BC%89"><span class="toc-number">1.6.</span> <span class="toc-text">正交投影（Orthogonal Projections）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E4%BA%A4%E6%8A%95%E5%BD%B1%E5%88%B0%E4%B8%80%E7%BB%B4%E5%AD%90%E7%A9%BA%E9%97%B4"><span class="toc-number">1.6.1.</span> <span class="toc-text">正交投影到一维子空间</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E4%BA%A4%E6%8A%95%E5%BD%B1%E5%88%B0%E4%B8%80%E8%88%AC%E7%9A%84%E5%AD%90%E7%A9%BA%E9%97%B4"><span class="toc-number">1.6.2.</span> <span class="toc-text">正交投影到一般的子空间</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%BC%E6%8B%89%E5%A7%86-%E6%96%BD%E5%AF%86%E7%89%B9%E6%AD%A3%E4%BA%A4%E5%8C%96%EF%BC%88Gram-Schmidt-Orthogonalization%EF%BC%89"><span class="toc-number">1.6.3.</span> <span class="toc-text">格拉姆-施密特正交化（Gram-Schmidt Orthogonalization）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E4%BB%BF%E5%B0%84%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E6%AD%A3%E4%BA%A4%E6%8A%95%E5%BD%B1"><span class="toc-number">1.6.4.</span> <span class="toc-text">在仿射空间中的正交投影</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%8B%E8%BD%AC%E5%8F%98%E6%8D%A2"><span class="toc-number">1.7.</span> <span class="toc-text">旋转变换</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E4%BA%8C%E7%BB%B4%E5%AE%9E%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E6%97%8B%E8%BD%AC%EF%BC%88Rotations-in-mathbb-R-2-%EF%BC%89"><span class="toc-number">1.7.1.</span> <span class="toc-text">在二维实空间中的旋转（Rotations in $\mathbb R^2$）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E4%B8%89%E7%BB%B4%E5%AE%9E%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E6%97%8B%E8%BD%AC-Rotations-in-mathbb-R-2"><span class="toc-number">1.7.2.</span> <span class="toc-text">在三维实空间中的旋转(Rotations in $\mathbb R^2$)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8-mathcal-n-%E7%BB%B4%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E6%97%8B%E8%BD%AC"><span class="toc-number">1.7.3.</span> <span class="toc-text">在$\mathcal n$维空间中的旋转</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%8B%E8%BD%AC%E7%9A%84%E7%89%B9%E6%80%A7"><span class="toc-number">1.7.4.</span> <span class="toc-text">旋转的特性</span></a></li></ol></li></ol></li></ol>
		</div>
		
		<h1 id="解析几何-Analytic-Geometry"><a href="#解析几何-Analytic-Geometry" class="headerlink" title="解析几何(Analytic Geometry)"></a>解析几何(Analytic Geometry)</h1><p>这章将从几何的角度理解之前提及的一些概念。</p>
<h2 id="范数-Norm"><a href="#范数-Norm" class="headerlink" title="范数(Norm)"></a>范数(Norm)</h2><p>范数实际上就是向量的一个长度<br><img src="https://img-blog.csdnimg.cn/20210419083819764.png" alt="在这里插入图片描述"><br>范数有以下性质：<br><img src="https://img-blog.csdnimg.cn/20210419083913865.png" alt="在这里插入图片描述"></p>
<ul>
<li>第一个绝对齐次（？）实际上数量积不就是对向量长度的一个延伸，所以，缩放的量可以提出来。</li>
<li>第二个三角不等式，因为两个向量和这两个向量的向量和会形成一个三角形，三角形有一个性质就是两边之和大于等于第三边</li>
<li>最后一个是因为长度是非负的</li>
</ul>
<p>下面是两种不同的范数，这种区别是对距离的定于不同导致的。</p>
<h3 id="曼哈顿范数（Manhattan-Norm）"><a href="#曼哈顿范数（Manhattan-Norm）" class="headerlink" title="曼哈顿范数（Manhattan Norm）"></a>曼哈顿范数（Manhattan Norm）</h3><p><img src="https://img-blog.csdnimg.cn/20210419084501411.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>由上图可以了解到曼哈顿距离和欧几里得距离的区别，这样曼哈顿距离就是对应的向量（坐标）所有元素的绝对值之和。其实就是点在水平和竖直方向的位移总和。($x_i$表示向量的元素，$|\cdot|$表示绝对值)<br><img src="https://img-blog.csdnimg.cn/20210419084753190.png" alt="在这里插入图片描述"><br>表示方式：$\ell_1$</p>
<h3 id="欧几里得范数（Euclidean-Norm）"><a href="#欧几里得范数（Euclidean-Norm）" class="headerlink" title="欧几里得范数（Euclidean Norm）"></a>欧几里得范数（Euclidean Norm）</h3><p>这个使用的就是直观的“直线距离”：<br><img src="https://img-blog.csdnimg.cn/20210419090116185.png" alt="在这里插入图片描述"><br>表示方式：$\ell_2$</p>
<p>曼哈顿范数（左）和欧几里得范数（右）的实例：<br><img src="https://img-blog.csdnimg.cn/20210419092014679.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="内积（Inner-Product）"><a href="#内积（Inner-Product）" class="headerlink" title="内积（Inner Product）"></a>内积（Inner Product）</h2><p>内积可以理解为，两个向量在同一向量空间（转换后）下的长度的乘积。<br><code>点积</code>：两维度相同的向量相乘最后得到一个实数。</p>
<script type="math/tex; mode=display">x^\top y = \sum_{i=1}^{n}x_iy_i</script><p>点积的几何含义：<br><img src="https://img-blog.csdnimg.cn/20210419123348905.png?x-oss-process=imag,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>所以从图像上看，可以得到部分点积的性质：当两向量相反的时候，点积为负数；当两向量垂直的时候，点积为0（在另一个向量的投影的长度为0）。当两向量方向相同的时候，点积为正。<br>内积的齐次性和对称性：两个向量哪个投影至哪个其实并没有什么区别，所以，二者乘积的顺序是无关紧要的。</p>
<blockquote>
<p>点积为什么是这样计算的？<br><img src="https://img-blog.csdnimg.cn/20210419124954776.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/2021041913015911.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
</blockquote>
<h3 id="广义内积"><a href="#广义内积" class="headerlink" title="广义内积"></a>广义内积</h3><p><code>双线性映射</code>（bilinear mapping）<br><img src="https://img-blog.csdnimg.cn/20210419092253723.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>当映射的参数顺序交换后，映射结果保持一致，这种性质称为<code>对称</code>(symmetric).当映射结果不会小于0， 这种性质称为<code>正定</code>（positive definite）<br><img src="https://img-blog.csdnimg.cn/20210419093426481.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>这样，内积的广义定义就是一个正定、对称的双线性映射。<br><img src="https://img-blog.csdnimg.cn/20210419093519239.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<blockquote>
<p>内积空间是不是就是向量空间中两两通过运算之后得到一个实数的向量组成的空间？理解一下上图最后一句化的含义。<br><img src="https://img-blog.csdnimg.cn/20210419105239390.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
</blockquote>
<h3 id="对称正定矩阵（Symmetric-Positive-Definite-Matrices）"><a href="#对称正定矩阵（Symmetric-Positive-Definite-Matrices）" class="headerlink" title="对称正定矩阵（Symmetric, Positive Definite Matrices）"></a>对称正定矩阵（Symmetric, Positive Definite Matrices）</h3><p><img src="https://img-blog.csdnimg.cn/20210419131322340.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>由于内积是正定的，所以有上式可以得出：</p>
<script type="math/tex; mode=display">\forall x \in V \backslash \{0\}:x^T\bold Ax > 0</script><p>$x$是任意的非零向量。<br>对于一个满足上式的对称矩阵，称为<strong>正定矩阵</strong></p>
<script type="math/tex; mode=display">\forall x \in V \backslash \{0\}:x^T\bold Ax \ge 0</script><p>满足上式的对称矩阵称为<strong>半正定矩阵</strong></p>
<p>可以使用一个正定矩阵定义一个内积：<br><img src="https://img-blog.csdnimg.cn/20210419132359212.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210419133148481.png" alt="在这里插入图片描述"><br>因为矩阵$\bold A$正定，所以$\bold x^T \bold A \bold x&gt;0$。这一就是说，$\bold A\bold x\ne 0$所以A的零空间只能是$\bold 0$。同时，对角线的元素都大于0，原因如下：<br><img src="https://img-blog.csdnimg.cn/20210419133529785.png" alt="在这里插入图片描述"></p>
<h2 id="长度与距离（Lengths-and-Distances）"><a href="#长度与距离（Lengths-and-Distances）" class="headerlink" title="长度与距离（Lengths and Distances）"></a>长度与距离（Lengths and Distances）</h2><p>内积和范数之间的关系十分紧密。这样理解，（在欧氏几何内）内积其实就是一个向量在另一个向量上投影之后，得到的向量，这两个向量的长度的乘积就是内积。范数简单来说就是向量的长度。所以，两个相同的向量的内积就是这个向量的范数的平方。</p>
<script type="math/tex; mode=display">\|x\| := \sqrt {\langle x, x\rangle}</script><p><strong>柯西-施瓦茨不等式</strong>（Cauchy-Schwarz Inequality）：<br><img src="https://img-blog.csdnimg.cn/20210419202022580.png" alt="在这里插入图片描述"><br>对于这个公式用图形非常好理解：不等式左边是投影之后的两向量的乘积（见之前点积部分介绍的投影），而右边是两向量没有经过投影的长度乘积。而只有两向量相等的时候，一个向量投影到另一个向量不会损失长度，这时候不等式取得等号，否则投影之后的向量长度都会变小。<br>在欧几里得空间中有特例：<br><img src="https://img-blog.csdnimg.cn/20210419202410822.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>距离和度规</strong>（Distance and Metric）：<br><strong>距离</strong>的定义：<br><img src="https://img-blog.csdnimg.cn/20210419202803485.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>度规</strong>的定义：<br>在数学中，度量（度规）或距离函数是个函数，定义了集合内每一对元素之间的距离。<br><img src="https://img-blog.csdnimg.cn/20210419202929939.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>度规和内积有类似的性质，但是他们在某方面又是不同的。当两个向量越接近的时候，内积越大，而度规越小。</p>
<h2 id="夹角与正交性-Angles-and-Orthogonality"><a href="#夹角与正交性-Angles-and-Orthogonality" class="headerlink" title="夹角与正交性(Angles and Orthogonality)"></a>夹角与正交性(Angles and Orthogonality)</h2><p>内积可以用于定义<strong>两向量的夹角</strong>：<br>由之前提到的的柯西-施瓦茨不等式：<script type="math/tex">|\langle\boldsymbol{x}, \boldsymbol{y}\rangle| \leqslant\|\boldsymbol{x}\|\|\boldsymbol{y}\|</script>可以得到：</p>
<script type="math/tex; mode=display">-1 \leqslant \frac{\langle\boldsymbol{x}, \boldsymbol{y}\rangle}{\|\boldsymbol{x}\|\|\boldsymbol{y}\|} \leqslant 1</script><p><img src="https://img-blog.csdnimg.cn/20210420164254641.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210420164311265.png" alt="在这里插入图片描述">在这个范围内，余弦函数的单调的。$\omega$用来表示两个向量的相近程度。<br>内积更重要的是可以为定义<strong>两向量的正交性</strong>:<br><img src="https://img-blog.csdnimg.cn/20210420165005906.png" alt="在这里插入图片描述"><br>两向量正交实际上就是他们之间的夹角为$90\degree$,这时候的余弦值为0，由</p>
<script type="math/tex; mode=display">\cos \omega=\frac{\langle\boldsymbol{x}, \boldsymbol{y}\rangle}{\|\boldsymbol{x}\|\|\boldsymbol{y}\|}</script><p>因为$|\bold x|$和$|\bold y|$都是正定的，所以当$\cos \omega = 0$是，$\langle \bold x, \bold y \rangle$等于0.当x、y的范数（长度）为1时，称为<strong>规范化正交</strong>(orthonormal).当一个向量是$\bold 0$时，它与所有的向量都正交。<br>正交依赖于内积，所以在不同的内积的情况下，正交性可能不同。</p>
<p><strong>正交矩阵</strong><br><img src="https://img-blog.csdnimg.cn/20210420165940150.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<blockquote>
<p>转置矩阵的变换关系？</p>
</blockquote>
<script type="math/tex; mode=display">\|A x\|^{\top}=(A x)^{\top}(A x)=x^{\top} A^{\top} A x=x^{\top} \boldsymbol{I} x=x^{\top} x=\|x\|^{2}</script><script type="math/tex; mode=display">\cos \omega=\frac{(\boldsymbol{A} \boldsymbol{x})^{\top}(\boldsymbol{A} \boldsymbol{y})}{\|\boldsymbol{A} \boldsymbol{x}\|\|\boldsymbol{A} \boldsymbol{y}\|}=\frac{\boldsymbol{x}^{\top} \boldsymbol{A}^{\top} \boldsymbol{A} \boldsymbol{y}}{\sqrt{\boldsymbol{x}^{\top} \boldsymbol{A}^{\top} \boldsymbol{A} \boldsymbol{x} \boldsymbol{y}^{\top} \boldsymbol{A}^{\top} \boldsymbol{A} \boldsymbol{y}}}=\frac{\boldsymbol{x}^{\top} \boldsymbol{y}}{\|\boldsymbol{x}\|\|\boldsymbol{y}\|}</script><p>由上可知，向量在经过正交变换之后，他们之间的夹角和长度都没有发生变化，实际上，正交变换就是将向量进行旋转操作。</p>
<h3 id="规范正交基（Orthonormal-Basis）"><a href="#规范正交基（Orthonormal-Basis）" class="headerlink" title="规范正交基（Orthonormal Basis）"></a>规范正交基（Orthonormal Basis）</h3><p><img src="https://img-blog.csdnimg.cn/2021042017035145.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>一对规范正交基满足两个条件，<del>二者之间的夹角和他们各自的长度。</del> 规范（长度为1）且正交（两对基相互垂直）</p>
<blockquote>
<p><strong>格拉姆-施密特正交化 Gram–Schmidt process</strong><br>这里时利用高斯消元法来取得正交规范正交基<img src="https://img-blog.csdnimg.cn/20210420171209130.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="正交补（Orthogonal-Complement）"><a href="#正交补（Orthogonal-Complement）" class="headerlink" title="正交补（Orthogonal Complement）"></a>正交补（Orthogonal Complement）</h3><p><img src="https://img-blog.csdnimg.cn/20210420213004774.png" alt="在这里插入图片描述"><br>一个向量空间的两个子空间，这两个子空间的维度之和等于原先的向量空间的维度，准确来说，一个子空间占领原空间的部分维度，另一个子空间占领剩余的维度，二者在维度上没有关系。<br>一个实例<br><img src="https://img-blog.csdnimg.cn/20210420213347790.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
</blockquote>
<p>这样，原先向量空间中的任意向量，都可以用这个子空间的有序基以及其正交补的有序基表示出来（分解）：</p>
<script type="math/tex; mode=display">\boldsymbol{x}=\sum_{m=1}^{M} \lambda_{m} \boldsymbol{b}_{m}+\sum_{j=1}^{D-M} \psi_{j} \boldsymbol{b}_{j}^{\perp}, \quad \lambda_{m}, \psi_{j} \in \mathbb{R}</script><p>其中，$\boldsymbol x$是原先的向量空间的一个向量，$\bold b$是原先空间的一个子空间的有序基，$\bold b^{\perp}$是这个子空间的正交补的有序基。<br><img src="https://img-blog.csdnimg.cn/20210420213930621.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="函数的内积"><a href="#函数的内积" class="headerlink" title="函数的内积"></a>函数的内积</h2><p>有之前的点积：</p>
<script type="math/tex; mode=display">x^Ty = \sum_{i = 1}^nx_iy_i</script><p>当向量的维度有无限维时，可以将这个利用定积分的定义，写成积分形式。</p>
<script type="math/tex; mode=display">\int_{a}^{b}f(x) = \lim_{\lambda \rarr 0}\sum_{i=1}^nf(\xi_i)\Delta x_i,\quad \lambda = max\{\Delta x_1,\Delta x_2,...,\Delta x_n\}</script><p>从而：<br><img src="https://img-blog.csdnimg.cn/20210420220554149.png" alt="在这里插入图片描述"></p>
<p>当两个函数在一定区间上的定积分为0时，说这两个函数时正交函数。</p>
<blockquote>
<p>所有的正交函数够成的一个子空间<img src="https://img-blog.csdnimg.cn/2021042022121317.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>想要正确理解这个无穷维向量的内积，需要将积分延伸到希尔伯特空间（Hilbert space）中。</p>
</blockquote>
<h2 id="正交投影（Orthogonal-Projections）"><a href="#正交投影（Orthogonal-Projections）" class="headerlink" title="正交投影（Orthogonal Projections）"></a>正交投影（Orthogonal Projections）</h2><p>在机器学习中，由于研究对象通常由多标签组成的，所以就不得不使用高维矩阵，但是实际上，大多数的信息仅仅存储在少部分的标签中，所以，当需要对矩阵进行可视化或者数据压缩的时候，为了减少造成的信息损失，可以使用正交投影，这样压缩之后的数据损失最小。<br>下面是对投影的定义：<br><img src="https://img-blog.csdnimg.cn/20210421103057918.png" alt="在这里插入图片描述"></p>
<blockquote>
<p>$\pi^2 = \pi \circ \pi = \pi$怎么理解？<br><del>应该是对一个向量进行两次投影的与进行一次投影的效果是一致的。</del> 假设一个向量被正交投影到向量空间V中，然后再被正交投影到W中，那么这个向量可以直接利用一次正交变换投影到W中.<br>类似于$A\perp B, B\perp C\Rightarrow A\perp C$<br><img src="https://img-blog.csdnimg.cn/20210421213521182.png" alt="在这里插入图片描述"></p>
</blockquote>
<p>投影本质上就是一种对向量的变换，所以可以用矩阵来描述，所以投影操作对应的矩阵就是<strong>投影矩阵</strong>（projection matrices，$\bold P<em>{\pi}^2 = \bold P</em>{\pi}$）</p>
<h3 id="正交投影到一维子空间"><a href="#正交投影到一维子空间" class="headerlink" title="正交投影到一维子空间"></a>正交投影到一维子空间</h3><p>可以通过以下三步求解投影矩阵：<br><img src="https://img-blog.csdnimg.cn/20210421214613478.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p><strong>1.找到坐标$\lambda$:</strong></p>
<script type="math/tex; mode=display">\left\langle\boldsymbol{x}-\pi_{U}(\boldsymbol{x}), \boldsymbol{b}\right\rangle=0 \stackrel{\pi_{U}(\boldsymbol{x})=\lambda \boldsymbol{b}}{\Longleftrightarrow}\langle\boldsymbol{x}-\lambda \boldsymbol{b}, \boldsymbol{b}\rangle=0$$注意到$\boldsymbol{x}-\pi_{U}(\boldsymbol{x})$是向量及其投影向量做差之后得到的向量，所以与投影到的向量正交。因为投影之后的向量属于向量空间U，所以可以用U中的有序基线性$\bold b$表示。
$$\langle\boldsymbol{x}, \boldsymbol{b}\rangle-\lambda\langle\boldsymbol{b}, \boldsymbol{b}\rangle=0 \Longleftrightarrow \lambda=\frac{\langle\boldsymbol{x}, \boldsymbol{b}\rangle}{\langle\boldsymbol{b}, \boldsymbol{b}\rangle}=\frac{\langle\boldsymbol{b}, \boldsymbol{x}\rangle}{\|\boldsymbol{b}\|^{2}} .</script><p>这里是利用了内积的双线性的性质，将原先的式子进行了拆分，最后的等式是利用了内积的对称性。之后分离出$\lambda$，任务完成。</p>
<script type="math/tex; mode=display">\lambda=\frac{\boldsymbol{b}^{\top} \boldsymbol{x}}{\boldsymbol{b}^{\top} \boldsymbol{b}}=\frac{\boldsymbol{b}^{\top} \boldsymbol{x}}{\|\boldsymbol{b}\|^{2}}</script><p>（这里探究当内积为点积的情况）</p>
<p><strong>2.找到投影点（投影后的向量）：</strong></p>
<script type="math/tex; mode=display">\pi_{U}(\boldsymbol{x})=\lambda \boldsymbol{b}=\frac{\langle\boldsymbol{x}, \boldsymbol{b}\rangle}{\|\boldsymbol{b}\|^{2}} \boldsymbol{b}=\frac{\boldsymbol{b}^{\top} \boldsymbol{x}}{\|\boldsymbol{b}\|^{2}} \boldsymbol{b}</script><p>将之前的结果带入式中，最后的等式为当内积为点积的时候成立。</p>
<script type="math/tex; mode=display">\left\|\pi_{U}(\boldsymbol{x})\right\| \stackrel{(3.42)}{=} \frac{\left|\boldsymbol{b}^{\top} \boldsymbol{x}\right|}{\|\boldsymbol{b}\|^{2}}\|\boldsymbol{b}\| \stackrel{(3.25)}{=}|\cos \omega|\|\boldsymbol{x}\|\|\boldsymbol{b}\| \frac{\|\boldsymbol{b}\|}{\|\boldsymbol{b}\|^{2}}=|\cos \omega|\|\boldsymbol{x}\| .</script><p>点积为内积的情况下,同时，联立了$\cos \omega=\frac{\langle\boldsymbol{x}, \boldsymbol{y}\rangle}{|\boldsymbol{x}||\boldsymbol{y}|}$</p>
<p><strong>3.找到投影矩阵</strong></p>
<script type="math/tex; mode=display">\pi_{U}(\boldsymbol{x})=\lambda \boldsymbol{b}=\boldsymbol{b} \lambda=\boldsymbol{b} \frac{\boldsymbol{b}^{\top} \boldsymbol{x}}{\|\boldsymbol{b}\|^{2}}=\frac{\boldsymbol{b} \boldsymbol{b}^{\top}}{\|\boldsymbol{b}\|^{2}} \boldsymbol{x}</script><p>于是：</p>
<script type="math/tex; mode=display">\bold P_\pi = \frac{\bold b\bold b^T}{\|\bold b\|^2}</script><p>这样看投影矩阵就是一个对称矩阵。</p>
<h3 id="正交投影到一般的子空间"><a href="#正交投影到一般的子空间" class="headerlink" title="正交投影到一般的子空间"></a>正交投影到一般的子空间</h3><p>假设一个子空间$U \subseteq \mathbb R^n, \quad dim(U)\ge1$,因为投影的向量属于U，所以，这个投影向量可以用U的有序基表示出来：</p>
<script type="math/tex; mode=display">\bold \pi_U(\bold x) =\sum\limits_{i=1}^m\lambda_i\bold b_i</script><p><strong>1.找出投影的坐标</strong>$\lambda_1,\lambda_2…,\lambda_n$:</p>
<script type="math/tex; mode=display">\bold\pi_U(\bold x) = \sum\limits_{i=1}^m\lambda_i\bold b_i = \bold B\bold\lambda\\\bold B=[\bold b_1,...,\bold b_m]\in\mathbb R^{n\times m},\quad\lambda=[\lambda_1,...,\lambda_m]^T\in\mathbb R^m</script><p>假设内积为点乘：</p>
<script type="math/tex; mode=display">\left\langle\boldsymbol{b}_{1}, \boldsymbol{x}-\pi_{U}(\boldsymbol{x})\right\rangle=\boldsymbol{b}_{1}^{\top}\left(\boldsymbol{x}-\pi_{U}(\boldsymbol{x})\right)=0\\\vdots\\\left\langle\boldsymbol{b}_{m}, \boldsymbol{x}-\pi_{U}(\boldsymbol{x})\right\rangle=\boldsymbol{b}_{m}^{\top}\left(\boldsymbol{x}-\pi_{U}(\boldsymbol{x})\right)=0</script><p>由$\bold\pi_U = \bold B\bold\lambda$,带入到上式中：</p>
<script type="math/tex; mode=display">\bold b^T_1(\bold x - \bold B\bold\lambda)=0\\\vdots\\\bold b^T_m(\bold x-\bold B\lambda)=0</script><p>转换成矩阵形式：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\left[\begin{array}{c}
b_{1}^{\top} \\
\vdots \\
b_{m}^{\top}
\end{array}\right][x-B \lambda]=0 & \Longleftrightarrow B^{\top}(x-B \lambda)=0 
& \Longleftrightarrow B^{\top} B \lambda=B^{\top} x .
\end{aligned}</script><p>因为$\bold B$是U的有序基，所以他是可逆的，所以可以得到：</p>
<script type="math/tex; mode=display">\lambda=(\bold B^T\bold B)^{-1}\bold B^T\bold x</script><p>其中：$(\bold B^T\bold B)^{-1}\bold B^T$称为伪逆，可以用于计算非方阵矩阵。<br><strong>2.找到投影向量：</strong><br>由$\pi_U = \bold B\lambda$,带入上式：</p>
<script type="math/tex; mode=display">\pi_U(x) = \bold B(\bold B^T\bold B)^{-1}\bold B^T\bold x</script><p><strong>3.找到投影矩阵：</strong><br>由$\bold P_\pi \bold x=\pi_U(\bold x)$,由上式可以得出：</p>
<script type="math/tex; mode=display">\bold P_\pi=\bold B(\bold B^T\bold B)^{-1}\bold B^T</script><blockquote>
<p>原始向量与投影向量之差够成的向量的范数，称为<strong>重构误差</strong>（reconstruction error.）或者投影误差。<img src="https://img-blog.csdnimg.cn/20210422110018669.png" alt="在这里插入图片描述"></p>
</blockquote>
<p>虽然说$\pi_U(\bold x)\in \mathbb R^n$但是我们只需要用U的有序基就可以表示$\pi_U(\bold x)$</p>
<p>用正交投影可以用于求非齐次方程$\bold A\bold x=\bold b$无解的时候的近似解。当这个方程无解的时候，说明$\bold x$和$\bold b$不在同一个向量空间中，所以无法通过一些变换（$\bold A$）得到$\bold b$。这时候可以利用正交投影，将其中一个向量投影到另一个向量的向量空间中，这样可以得到一个近似解，其中的主要思想就是找到一个在A的张成空间中，与b最相近的向量。这样得到的解称为<strong>最小二乘解</strong>（least-squares solution）</p>
<h3 id="格拉姆-施密特正交化（Gram-Schmidt-Orthogonalization）"><a href="#格拉姆-施密特正交化（Gram-Schmidt-Orthogonalization）" class="headerlink" title="格拉姆-施密特正交化（Gram-Schmidt Orthogonalization）"></a>格拉姆-施密特正交化（Gram-Schmidt Orthogonalization）</h3><p><img src="https://img-blog.csdnimg.cn/20210422124223522.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<blockquote>
<p>这里的目标是求出$u<em>2$，利用已知的数据$b_2,u_1$计算出$\pi</em>{span[u<em>1]}(b_2)$这样就可以利用$b_2,\pi</em>{span[u_1]}(b_2)$计算$u_2$了。</p>
</blockquote>
<p>我们可以使用向量以及其投影所在的向量空间的有序基作差，得到一个法向量。然后递归地将有序基转化成正交基。</p>
<script type="math/tex; mode=display">\bold {\mathcal u}:=\bold b_1 \\ \mathcal u_k:=\bold b_k- \pi_{span[\bold u_1,\dots,\bold u_{k-1}]}(\bold b_k),\quad k =2,\dots,n</script><p>其中，$\bold b<em>k$是之前缔造的正交向量组成的向量空间（$\bold u_1,\dots,\bold u</em>{k-1}$）</p>
<h3 id="在仿射空间中的正交投影"><a href="#在仿射空间中的正交投影" class="headerlink" title="在仿射空间中的正交投影"></a>在仿射空间中的正交投影</h3><p><img src="https://img-blog.csdnimg.cn/2021042214030141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>先将目标向量与支撑点($\bold x_0$)相减，得到的向量就是以仿射空间为起点的，这时候，问题就转换成我们之前讨论过的问题了。<script type="math/tex">\pi_L(\bold x)=\bold x_0+\pi_U(\bold x-\bold x_0)</script><br><img src="https://img-blog.csdnimg.cn/20210422140821843.png" alt="在这里插入图片描述"></p>
<h2 id="旋转变换"><a href="#旋转变换" class="headerlink" title="旋转变换"></a>旋转变换</h2><p>旋转实际上就是一种正交变换。在文中规定当旋转角度为正数的时候，图像作逆时针旋转。<br><img src="https://img-blog.csdnimg.cn/20210422142037260.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="在二维实空间中的旋转（Rotations-in-mathbb-R-2-）"><a href="#在二维实空间中的旋转（Rotations-in-mathbb-R-2-）" class="headerlink" title="在二维实空间中的旋转（Rotations in $\mathbb R^2$）"></a>在二维实空间中的旋转（Rotations in $\mathbb R^2$）</h3><p><img src="https://img-blog.csdnimg.cn/20210422144422923.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>因为旋转之后的基向量仍然是线性无关的，所以，旋转也是一种基变换。由上可以得到旋转矩阵（旋转之后的向量）：</p>
<script type="math/tex; mode=display">\Phi\left(\boldsymbol{e}_{1}\right)=\left[\begin{array}{c}\cos \theta \\ \sin \theta\end{array}\right], \quad \Phi\left(\boldsymbol{e}_{2}\right)=\left[\begin{array}{c}-\sin \theta \\ \cos \theta\end{array}\right]</script><script type="math/tex; mode=display">\boldsymbol{R}(\theta)=\left[\begin{array}{ll}\Phi\left(\boldsymbol{e}_{1}\right) & \Phi\left(\boldsymbol{e}_{2}\right)\end{array}\right]=\left[\begin{array}{cc}\cos \theta & -\sin \theta \\ \sin \theta & \cos \theta\end{array}\right] .</script><h3 id="在三维实空间中的旋转-Rotations-in-mathbb-R-2"><a href="#在三维实空间中的旋转-Rotations-in-mathbb-R-2" class="headerlink" title="在三维实空间中的旋转(Rotations in $\mathbb R^2$)"></a>在三维实空间中的旋转(Rotations in $\mathbb R^2$)</h3><p><img src="https://img-blog.csdnimg.cn/20210422145419775.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>可以这样理解，先固定一个坐标轴，然后从上往下看去，得到这个向量在另外两个基向量所形成的向量空间中正交投影，然后再作相应的旋转操作。</p>
<p>关于$\bold e_1$的旋转操作：</p>
<script type="math/tex; mode=display">\bold R_1(\theta)=\left[\begin{array}{c}    \Phi(\bold e_1)&\Phi(\bold e_2) &\Phi(\bold e_3)   \end{array}\right]=\left[\begin{array}{c} 1&0&0 \\0&\cos\theta&-\sin\theta\\0&\sin\theta&\cos\theta       \end{array}\right]</script><p>类似的，只要固定哪个坐标轴，哪个坐标轴就是基向量。</p>
<h3 id="在-mathcal-n-维空间中的旋转"><a href="#在-mathcal-n-维空间中的旋转" class="headerlink" title="在$\mathcal n$维空间中的旋转"></a>在$\mathcal n$维空间中的旋转</h3><p><strong>吉文斯旋转</strong>（Givens Rotation）：<br><img src="https://img-blog.csdnimg.cn/20210422150526421.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>实际上就是等价于单位矩阵对应位置上变成一个正弦或者余弦值。</p>
<h3 id="旋转的特性"><a href="#旋转的特性" class="headerlink" title="旋转的特性"></a>旋转的特性</h3><p>简单来说就是变换之后向量之间的距离角度不变，三维及三维以上的旋转操作不满足交换律，二维的满足。<br><img src="https://img-blog.csdnimg.cn/20210422151402308.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
  
	</div>
		<footer class="article-footer clearfix">




<div class="article-share" id="share">

  <div data-url="https://baymine.github.io/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%EF%BC%9A%EF%BC%88%E4%BA%8C%EF%BC%89%E8%A7%A3%E6%9E%90%E5%87%A0%E4%BD%95/" data-title="机器学习中的数学：（二）解析几何 | Hexo" data-tsina="" class="share clearfix">
  </div>

</div>
</footer>   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2021/04/25/论文笔记/" title="论文笔记">
  <strong>PREVIOUS:</strong><br/>
  <span>
  论文笔记</span>
</a>
</div>


<div class="next">
<a href="/2021/04/21/机器学习中的数学：（一）线性代数/"  title="机器学习中的数学：（一）线性代数">
 <strong>NEXT:</strong><br/> 
 <span>机器学习中的数学：（一）线性代数
</span>
</a>
</div>

</nav>

	
</div>  
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">Contents</strong>
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A7%A3%E6%9E%90%E5%87%A0%E4%BD%95-Analytic-Geometry"><span class="toc-number">1.</span> <span class="toc-text">解析几何(Analytic Geometry)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8C%83%E6%95%B0-Norm"><span class="toc-number">1.1.</span> <span class="toc-text">范数(Norm)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9B%BC%E5%93%88%E9%A1%BF%E8%8C%83%E6%95%B0%EF%BC%88Manhattan-Norm%EF%BC%89"><span class="toc-number">1.1.1.</span> <span class="toc-text">曼哈顿范数（Manhattan Norm）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E8%8C%83%E6%95%B0%EF%BC%88Euclidean-Norm%EF%BC%89"><span class="toc-number">1.1.2.</span> <span class="toc-text">欧几里得范数（Euclidean Norm）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E7%A7%AF%EF%BC%88Inner-Product%EF%BC%89"><span class="toc-number">1.2.</span> <span class="toc-text">内积（Inner Product）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%BF%E4%B9%89%E5%86%85%E7%A7%AF"><span class="toc-number">1.2.1.</span> <span class="toc-text">广义内积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E7%A7%B0%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5%EF%BC%88Symmetric-Positive-Definite-Matrices%EF%BC%89"><span class="toc-number">1.2.2.</span> <span class="toc-text">对称正定矩阵（Symmetric, Positive Definite Matrices）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%95%BF%E5%BA%A6%E4%B8%8E%E8%B7%9D%E7%A6%BB%EF%BC%88Lengths-and-Distances%EF%BC%89"><span class="toc-number">1.3.</span> <span class="toc-text">长度与距离（Lengths and Distances）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%B9%E8%A7%92%E4%B8%8E%E6%AD%A3%E4%BA%A4%E6%80%A7-Angles-and-Orthogonality"><span class="toc-number">1.4.</span> <span class="toc-text">夹角与正交性(Angles and Orthogonality)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%84%E8%8C%83%E6%AD%A3%E4%BA%A4%E5%9F%BA%EF%BC%88Orthonormal-Basis%EF%BC%89"><span class="toc-number">1.4.1.</span> <span class="toc-text">规范正交基（Orthonormal Basis）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E4%BA%A4%E8%A1%A5%EF%BC%88Orthogonal-Complement%EF%BC%89"><span class="toc-number">1.4.2.</span> <span class="toc-text">正交补（Orthogonal Complement）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E7%9A%84%E5%86%85%E7%A7%AF"><span class="toc-number">1.5.</span> <span class="toc-text">函数的内积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E4%BA%A4%E6%8A%95%E5%BD%B1%EF%BC%88Orthogonal-Projections%EF%BC%89"><span class="toc-number">1.6.</span> <span class="toc-text">正交投影（Orthogonal Projections）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E4%BA%A4%E6%8A%95%E5%BD%B1%E5%88%B0%E4%B8%80%E7%BB%B4%E5%AD%90%E7%A9%BA%E9%97%B4"><span class="toc-number">1.6.1.</span> <span class="toc-text">正交投影到一维子空间</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E4%BA%A4%E6%8A%95%E5%BD%B1%E5%88%B0%E4%B8%80%E8%88%AC%E7%9A%84%E5%AD%90%E7%A9%BA%E9%97%B4"><span class="toc-number">1.6.2.</span> <span class="toc-text">正交投影到一般的子空间</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%BC%E6%8B%89%E5%A7%86-%E6%96%BD%E5%AF%86%E7%89%B9%E6%AD%A3%E4%BA%A4%E5%8C%96%EF%BC%88Gram-Schmidt-Orthogonalization%EF%BC%89"><span class="toc-number">1.6.3.</span> <span class="toc-text">格拉姆-施密特正交化（Gram-Schmidt Orthogonalization）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E4%BB%BF%E5%B0%84%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E6%AD%A3%E4%BA%A4%E6%8A%95%E5%BD%B1"><span class="toc-number">1.6.4.</span> <span class="toc-text">在仿射空间中的正交投影</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%8B%E8%BD%AC%E5%8F%98%E6%8D%A2"><span class="toc-number">1.7.</span> <span class="toc-text">旋转变换</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E4%BA%8C%E7%BB%B4%E5%AE%9E%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E6%97%8B%E8%BD%AC%EF%BC%88Rotations-in-mathbb-R-2-%EF%BC%89"><span class="toc-number">1.7.1.</span> <span class="toc-text">在二维实空间中的旋转（Rotations in $\mathbb R^2$）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E4%B8%89%E7%BB%B4%E5%AE%9E%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E6%97%8B%E8%BD%AC-Rotations-in-mathbb-R-2"><span class="toc-number">1.7.2.</span> <span class="toc-text">在三维实空间中的旋转(Rotations in $\mathbb R^2$)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8-mathcal-n-%E7%BB%B4%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E6%97%8B%E8%BD%AC"><span class="toc-number">1.7.3.</span> <span class="toc-text">在$\mathcal n$维空间中的旋转</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%8B%E8%BD%AC%E7%9A%84%E7%89%B9%E6%80%A7"><span class="toc-number">1.7.4.</span> <span class="toc-text">旋转的特性</span></a></li></ol></li></ol></li></ol>
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  

  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			<li><a href="/tags/C/" title="C++">C++<sup>1</sup></a></li>
		
			<li><a href="/tags/C-primer/" title="C++ primer">C++ primer<sup>1</sup></a></li>
		
			<li><a href="/tags/DB/" title="DB">DB<sup>1</sup></a></li>
		
			<li><a href="/tags/OS/" title="OS">OS<sup>2</sup></a></li>
		
			<li><a href="/tags/Projects/" title="Projects">Projects<sup>1</sup></a></li>
		
			<li><a href="/tags/bugs/" title="bugs">bugs<sup>1</sup></a></li>
		
			<li><a href="/tags/computer-network/" title="computer network">computer network<sup>2</sup></a></li>
		
			<li><a href="/tags/侯捷C/" title="侯捷C++">侯捷C++<sup>5</sup></a></li>
		
		</ul>
</div>


  <div class="rsspart">
	<a href="" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<div class="social-font clearfix">
		
		
		
		
		
	</div>
		<p class="copyright">Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/A-limon/pacman" target="_blank" title="Pacman">Pacman</a> © 2023 
		
		<a href="https://Baymine.github.io" target="_blank" title="John Doe">John Doe</a>
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.1.0.min.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  if(ah.length==0){
    t.css('display','none');
  }else{
    c.click(function(){
      ta.css('display', 'block').addClass('fadeIn');
    });
    o.click(function(){
      ta.css('display', 'none');
    });
    $(window).scroll(function(){
      ta.css("top",Math.max(140,320-$(this).scrollTop()));
    });
  };
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina');
  var html = [
  '<a href="#" class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#share"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="#textlogo" class="article-back-to-top" title="Top"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="QRcode"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="Weibo"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
});     
</script>






  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
