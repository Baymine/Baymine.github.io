---
layout: post
title: "论文笔记"
date: 2021-04-25 07:06:35 +0000
categories: [blog]
tags: []
---



# [](#Multi-band-weighted-lp-norm-minimization-for-image-denois)Multi-band weighted lp norm minimization for image denois
## [](#%E5%86%85%E5%AE%B9%E5%AD%A6%E4%B9%A0)内容学习
### [](#Low-rank-matrix-approximation-LRMA)Low rank matrix approximation (LRMA)
### [](#%E8%B0%B1%E6%A8%A1)谱模

（Spectral Norm，矩阵的模）：

$$\|A\|_{2}=\sqrt{\lambda_{\max }\left(A^{*} A\right)}=\sigma_{\max }(A)$$

范数的下标表示这个模是在欧几里得空间下的。实际上就是说A的谱模就是A的最大奇异值。
**矩阵的低秩近似**：
浅显地理解就是舍弃掉矩阵中地一些行、列，而造成最小的损失。
**Schatten norms**：

> 

其实这个p值代表的是这个范数所在的空间，当p=2时，即为欧几里得空间。

Schatten p-norm ：（）

$$\|A\|_{p}=\left(\sum_{i=1}^{\min \{m, n\}} \sigma_{i}^{p}(A)\right)^{\frac{1}{p}}$$

当p=2时：Frobenius norm
当p=1时：nuclear norm，定义为

$$\|A\|_{*}=\operatorname{trace}\left(\sqrt{A^{*} A}\right)=\sum_{i=1}^{\min \{m, n\}} \sigma_{i}(A)$$

当p=时：Frobenius norm

> 

文中提到了核范数最小化来求解矩阵的低秩逼近，但是容易产生一个问题：”this is likely to overshrink the rank components due to having the same threshold.”
所以现在有一个问题，就是如何使用范数最小化来求解矩阵的低秩逼近？

一个运算符号：arg min在这里表示当这个运算符后面的式子取得最小值的时候，X的值。
<!-- Image removed: CSDN link no longer accessible -->

复习一下范数：
范数实际上就是将一个实数或者虚数向量空间映射到一个非负实数的函数。表现起来像是距离。

### [](#%E8%BD%AF%E9%98%88%E5%80%BC%E5%87%BD%E6%95%B0%EF%BC%88Soft-threshold-Function%EF%BC%89)软阈值函数（Soft-threshold Function）

$$\operatorname{soft}(x, T)=\left\{\begin{array}{cc}$$
x+T & x \leq-T \\
0 & |x| \leq T \\
x-T & x \geq T
$$\end{array}\right.$$

<!-- Image removed: CSDN link no longer accessible -->

软阈值函数可以用于求解优化问题：

\argmin_x \|\boldsymbol X-\boldsymbol B\|^2_F+\lambda\|\boldsymbol X\|_*

此问题最终解的形式就是软阈值函数。

### [](#%E5%8A%A0%E6%80%A7%E9%AB%98%E6%96%AF%E7%99%BD%E5%99%AA%E5%A3%B0%EF%BC%88additive-white-Gaussian-noise%EF%BC%89)加性高斯白噪声（additive white Gaussian noise）

一种用于模拟自然噪音的模型。

Additive white Gaussian noise (AWGN) is a basic noise model used in information theory to mimic the effect of many random processes that occur in nature. The modifiers denote specific characteristics:

**Additive** because it is added to any noise that might be intrinsic to the information system.
**White** refers to the idea that it has uniform power across the frequency band for the information system. It is an analogy to the color white which has uniform emissions at all frequencies in the visible spectrum.
**Gaussian** because it has a normal distribution(正态分布) in the time domain with an average time domain value of zero.

> 

时域（Time domain）:描述数学函数或物理信号对时间的关系.
就是描述函数随时间变化的情况。

### [](#%E6%AD%A3%E5%88%99%E5%8C%96%EF%BC%88regularization%EF%BC%89)正则化（regularization）

正则化是为了防止问题过拟合，在拟合方程中加上一些惩罚项，以减少拟合的参数。

> 

regularization is the process of adding information in order to solve an ill-posed problem or to prevent overfitting.
The regularization term, or penalty, imposes a cost on the optimization function to make the optimal solution unique.

<!-- Image removed: CSDN link no longer accessible -->
一个正则式往往加到代价函数中：

$$\min_f \sum^n_{i=1}V(f(x_i),y_i)+\lambda R(f)$$

其中，V为代价函数，表示预测值与之间的差距，是一个控制正则式权重的项。为对f函数复杂程度的惩罚函数。

### [](#%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0%EF%BC%88Lagrange-multiplier%EF%BC%89)拉格朗日乘数（Lagrange multiplier）

拉格朗日乘数是一种用于求解线性约束问题中的极大值或者极小值的策略。主要思想就是将一个约束问题转化成一个非约束问题。大致可以描述为：
<!-- Image removed: CSDN link no longer accessible -->
一个函数在线性约束下的最优问题，这样可以得到**拉格朗日函数**(Lagrangian Function):

$$\mathcal L(x,\lambda)=f(x)-\lambda g(x)# [](#Optimization-by-Simulated-Annealing)Optimization by Simulated Annealing$$
## [](#Metropolis-algorithm)Metropolis algorithm
### [](#Markvo-Chain)Markvo Chain

A **Markov chain** is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.
概率的**无记忆性**（memorylessness）：
In other words, conditional on the present state of the system, its future and past states are independent.
<!-- Image removed: CSDN link no longer accessible -->

$$\Pr(X_{n+1}=x\mid X_{1}=x_{1},X_{2}=x_{2},\ldots ,X_{n}=x_{n})=\Pr(X_{n+1}=x\mid X_{n}=x_{n})## [](#Travelling-salesman-problem)Travelling salesman problem$$
> 

Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city?”

<!-- Image removed: CSDN link no longer accessible -->

## [](#Heuristic-computer-science)Heuristic (computer science)

In mathematical optimization and computer science, heuristic (from Greek εὑρίσκω “I find, discover”) is a technique designed for solving a problem more quickly when classic methods are too slow, or for finding an approximate solution when classic methods fail to find any exact solution.