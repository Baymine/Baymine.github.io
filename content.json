{"posts":[{"title":"Bug 记录","text":"Bug 笔记VS 20191.警告 C6031 返回值被忽略: “scanf”。主要是没有检查输入是否成功。 12//修改：加上一个条件判断语句if(scanf(\"%d\",&amp;a) == 0) return -1; 2.变量不明确：这多半是因为变量名或者是函数名与现有库中的变量有冲突。 3.E0520 应使用“{…}”初始化聚合对象 4.C4996 ‘fopen’: This function or variable may be unsafe. Consider using fopen_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS.加上下面的语句，然后在 项目-&gt;属性-&gt;C/C++-&gt;预处理器-&gt;预处理器定义中添加_CRT_SECURE_NO_WARNINGS1#define _CRT_SECURE_NO_WARNINGS 5.C++不允许使用不完整的类型说明不完整类型是这样一种类型，它缺乏足够的信息例如长度去描述一个完整的对象。所以一个数组没有给定长度，直接赋值就会产生这样的错误。 6.c++ 非静态成员引用必须与特定对象相对这是在调用类成员函数的时候出现的问题1234className::funcName(para) // ErrorclassName CN;CN.funcName(para);//Pass PAT1.（当输出结果为很大的数字时出现）比较赋值的变量一定要进行初始化，因为PAT编译器不会默认初始化为0.（基本上就是一个很大的随机数） Ubuntusudo apt-get install g++-multilib遇到一种情况，就是出现缺少一些库","link":"/2021/01/04/Bug-%E8%AE%B0%E5%BD%95/"},{"title":"C++ Memory Management","text":"第一讲 primitives1. overview 资料： DL Malloc 涉及的库 2、3. 内存分配的每一层面及基本用法 本课程只考虑CRT以上的层次。 基本工具 基本用法 12345678910111213void* p3 = ::operator new (512); // 512 bytes::operator delete(p3);#ifdef __BORLANDC__ // 不同库不同 // 申请5个int。 一般容器中使用 int* p4 = allocator&lt;int&gt;().allocate(5); allocator&lt;int&gt;().deallocate(p4, 5);#endif#ifdef __GNUC__ // 较早版本中 void* p4 = alloc::allocate(512); alloc::deallocate(p4, 512); #endif 4、5、6、基本构件——new delete expressionnew 中实际上就是在调用malloc 123456789class_name* pc = new class_name(1, 2);// 编译器转换为// 加上try catchvoid* mem = operator new(sizeof(class_name));pc = static_cast&lt;class_name*&gt;(mem);pc-&gt;class_name::class_name(1, 2); // 只有编译其才能这样调用构造函数// 但是可以直接调用析构函数 7、Array new当new一个数组的时候，系统会使用4个字节存放数组的一些信息，即为下图中的 cookie 1Complex* pca = new Complex[3]; 在进行array new的时候，单个元素不会独自进行内存对齐。 构建的时候是从上往下，析构的时候是由下往上 61h就是cokie，需要进行内存对齐（VC6)中是16位对齐 对于申请的int类型的数组，可以直接使用delete，因为这些数据类型没有析构函数， 因为数组个数被写入，所以内存的整体布局会发生变化，所以不能直接用 delete来回收 61h的大小计算 类大小类个数=((34) 3) = 36\\ 上下debugger header = 32 + 4\\ 两个61h=42=8 最后向16的倍数内存对齐最后的 pad 8.palcement new允许将对象构造与已分配的内存中 9.random placement new 的重载 嵌入式指针使用案例（内存池） 通过一次性申请一定量的内存，减少每个内存中的cookie的数量，同时减少malloc的调用 整个内存是通过一个链表管理的，释放内存就是将空闲的内存插入到链表头部 但是申请的内存没有真正释放，所以可能会存在使用峰值的问题 可以自定义handler来让更多的空间可用，或者调用abort() 或 exit(); 1set_new_handler(handlerFunctionPoint); default, delete 关键字","link":"/2022/12/18/C-Memory-Management/"},{"title":"Basic Knoledge","text":"杂项 Small tricks 123// 取中间的数：int mid = (left + right) / 2; // 有溢出的风险int mid = left + ((right - left) &gt;&gt; 1); // 这样更好 当异常发⽣时，C++通常会调⽤对象的析构函数来释放资源 指向虚函数表的指针 vptr需要在构造函数中进⾏初始化 如何让类不能实例化 将类定义位抽象类（包含纯虚函数） 将构造器声明为 private 虚继承 在菱形继承的场景下，会产生两份基类数据，浪费空间，同时访问基类还需要通过域运算符 利用虚继承，在间接继承共同基类时是保留一份基类成员。创建派生类实例的时候，只需要调用一次基类的构造函数 12class A{}class B : virtual public A{} 在 C 语言中，数据类型指的是用于声明不同类型的变量或函数的一个广泛的系统。变量的类型决定了变量存储占用的空间，以及如何解释存储的位模式。 Linux 和 UNIX 的关系/区别 Linux 是一个类似 Unix 的操作系统，Unix 要早于 Linux，Linux 的初衷就是要替代 UNIX，并在功能和用户体验上进行优化，所以 Linux 模仿了 UNIX（但并没有抄袭 UNIX 的源码），使得 Linux 在外观和交互上与 UNIX 非常类似。 析构函数 类类型：如 struct、class、union 没有自定义析构函数，那么编译器就会为它们生成内联(inline)、public 的析构函数。 对于析构函数的调用，需要是 public 的访问权限，否则会导致编译错误。 Git \\text{工作区}\\stackrel{add}{\\rightarrow}\\text{暂存区}\\stackrel{commit}{\\rightarrow}\\text{本地仓库}\\stackrel{push}{\\rightarrow}\\text{远程仓库}\\stackrel{pull}{\\rightarrow}\\text{本地} 1234567891011121314151617181920212223242526272829303132# In the work directorygit config --global user.name \"yourName\"git config --global user.email yourEmailgit init # initialize the repositorygit status # repository informationgit add fileNamegit commit -m \"commit msg\"EADADWEgit log # 查看以前的版本touch .gitignore # 不追踪的文件# 创建新分支git branch branchName# 两种切换分支的命令git checkout branchName - git checkout -d branchName # 删除分支 - git checkout -b temp # 创建并切换到新建的分支git switch branchName# 合并分支git merge temp# add 和 commit合在一起写git commit -a -m \"msg\" # 或者-am# 下载远程内容#### 直接下载zip是不会下载版本信息的，所以需要使用以下命令git clone ESDAW C/C++条件变量的虚假唤醒1234567891011121314// wait 端lock(mutex);while(queue.empty()){ // 如果使用if可能会导致虚假唤醒 cond.wait();}x = queue.pop();unlock(mutex);// signal/broadcast端lock(mutex);queue.push_back(x);unlock(mutex);cond.notify(); 当条件变量满足的时候，挂起的线程会被唤醒，当他准备获取锁之前，有其他线程将变量改变了，这时候条件变量不满足了，所以这次唤醒是虚假的。 当某个条件满足的时候（即wait端中while中的条件），之后就进入挂起状态，用if语句那么挂起状态结束以后，就会继续往下，但是这个时候条件不一定满足（虚假唤醒时），所以应该利用while，这样可以进行第二次判断，这样就不会因为虚假唤醒的情况而被唤醒。 Function pointer12345678910111213141516171819202122232425262728293031int addInt(int n, int m) { return n+m;}int (*functionPtr)(int,int); // DeclarefunctionPtr = &amp;addInt; // Assigmentint sum = (*functionPtr)(2, 3); // usage: sum == 5// As a parameterint add2to3(int (*functionPtr)(int, int)) { return (*functionPtr)(2, 3);}// this is a function called functionFactory which receives parameter n// and returns a pointer to another function which receives two ints// and it returns another intint (*functionFactory(int n))(int, int) { printf(\"Got parameter %d\", n); int (*functionPtr)(int,int) = &amp;addInt; return functionPtr;}// note that the typedef name is indeed myFuncDef// Confused here ???????typedef int (*myFuncDef)(int, int);myFuncDef functionFactory(int n) { printf(\"Got parameter %d\", n); myFuncDef functionPtr = &amp;addInt; return functionPtr;} 12345678int addInt(int n, int m) { return n+m;}int (*functionPtr)(int,int); // DeclarefunctionPtr = &amp;addInt; // Assigmentcout &lt;&lt; addInt &lt;&lt; endl; // Return 1 cout 打印函数返回1的原因：C++调用非静态的成员函数时，采用的是一种 __thiscall 的函数调用方式。采用这种调用方式，编译器在编译的时候，会在调用的函数形参表中增加一个指向调用该成员函数的指针，也就是我们经常说的this指针。调用的形式类似于Base::f1(Base* this, otherparam…)，在函数体中，涉及到对象的成员变量或者其他成员函数，都会通过这个this指针来调用，从而达到在成员函数中处理调用对象所对应的数据，而不会错误处理其他对象的数据。可见，虽然我们必须通过对象来调用动态函数，但是其实我们访问的都是同一个成员函数。所以我们采用&amp;Base::f1来获取成员函数地址是没错的，动态函数同样是跟类绑定而不是跟对象绑定的。 出错的原因是，输出操作符&lt;&lt;没有对void(__thiscall A:: *)()类型重载，编译器将这种类型转换为bool类型，所以输出了1； 对于静态函数，其调用方式并非thiscall，&lt;&lt;有对它的重载，因此类的静态函数可以直接用cout输出函数地址。我们可以用printf输出，因为他可以接收任意类型的参数，包括thiscall类型 Upcasting123456789class A { void func1(); }class B : A{ void func1(); }A a; B b;// b = a; // Downcastinga = b; // Upcasting. 派生类成员变量将会被舍去，只保留基类成员变量// 对象之间的赋值不会影响成员函数，也不会影响 this 指针a.func1(); // 调用的是A中的函数。 这种转换关系是不可逆的，只能 用派生类对象给基类对象赋值，而 不能用基类对象给派生类对象赋值。理由很简单，基类不包含派生类的成员变量，无法对派生类的成员变量赋值。同理，同一基类的不同派生类对象之间也不能赋值。(如果多出数据，编译器会舍弃，但是少数据了，那么编译器就不知道如何填充剩下的内存了) 将派生类指针赋值给基类指针 将派生类指针赋值给基类指针时，通过基类指针只能使用派生类的成员变量，但不能使用派生类的成员函数. 编译器通过指针访问成员变量，但是不会通过指针访问成员函数，而是通过指针类型来访问。所以，当指针变化的时候，改变的只是指向的内存，也就是对应的类成员变量存储的位置变成了赋值类中的成员变量。 MMAP 传统IO 整个过程发生了4次用户态和内核态的上下文切换和4次拷贝(1.用户发起read，2.读缓存拷贝到用户缓存，3.用户发起write，4.拷贝到网卡) DMA拷贝 IO操作，都是通过CPU发出对应的指令来完成，但是相比CPU来说，IO的速度太慢了，CPU有大量的时间处于等待IO的状态。因此就产生了DMA（Direct Memory Access)直接内存访问技术，本质上来说他就是一块 主板上独立的芯片，通过它来进行内存和IO设备的数据传输，从而减少CPU的等待时间。 零拷贝 计算机执行操作时，CPU不需要先将数据从某处内存复制到另一个特定区域，这种技术通常用于通过网络传输文件时节省CPU周期和内存带宽。 减少用户态和内核态的切换次数以及CPU拷贝的次数。 常见的几种零拷贝技术 mmap + write 使用 mmap替换了read+write中的read操作，减少了一次CPU的拷贝。 mmap主要实现方式是将读缓冲区的地址和用户缓冲区的地址进行映射 4次用户态和内核态的上下文切换和3次拷贝（1.mmap调用，2.mmap返回，3.用户调用write，4.拷贝到网卡） mmap的方式节省了一次CPU拷贝，同时由于用户进程中的内存是虚拟的，只是映射到内核的读缓冲区，所以可以节省一半的内存空间，比较适合大文件的传输。 sendfile Linux2.1内核版本后引入的一个系统调用函数，通过使用 sendfile数据可以直接在内核空间进行传输，因此避免了用户空间和内核空间的拷贝 2次用户态和内核态的上下文切换和3次拷贝 sendfile方法IO数据对用户空间完全不可见，所以只能适用于完全不需要用户空间处理的情况，比如静态文件服务器。 sendfile + DMA Scatter/Gather 对 sendfile做了进一步优化，通过引入新的硬件支持，这个方式叫做DMA Scatter/Gather 分散/收集功能。 2次用户态和内核态的上下文切换和 2次拷贝 ，其中更重要的是完全没有CPU拷贝 **## 惊群效应 应用程序是通过 socket 和协议栈交互的，socket 隔离了应用程序和协议栈，socket 是两者之间的接口，对于应用程序，它代表协议栈；而对于协议栈，它又代表应用程序 一个典型的accept惊群现象，及解决措施 inux 内核通过睡眠队列来组织所有等待某个事件的 task，而wakeup 机制则可以异步唤醒整个睡眠队列上的 task 在唤醒睡眠队列的时候，会遍历队列链表上的每一个节点，并调用对应的callback，这样一个connect到达的时候，会将队列中所有的线程唤醒，但只有一个返回task，其他返回-1(EAGAIN: Resource temporarily unavailable) 添加了一个 WQ_FLAG_EXCLUSIVE 标记告诉内核进行排他性的唤醒，即唤醒一个进程后即退出唤醒的过程 select/poll/Epoll “惊群”现象 某一时刻多个进程(线程)阻塞在 select/poll/epoll_wait 系统调用上，当一个请求上来的时候，多个进程都会被 select/poll/epoll_wait 唤醒去 accept，但只有一个是有效的。 Niginx的解决方法 一次仅允许一个进程将 listen fd 放入自己的 epoll 来监听其 READ 事件的方式来达到 listen fd”惊群”避免 同一时刻仅允许一个 worker 进程监听 listen fd 的可读事件的方式 Epoll”惊群”之 LT(水平触发模式)、ET(边沿触发模式) 被Poll的fd, 必须在实现上支持内核的Poll技术，比如fd是某个字符设备,或者是个socket, 它必须实现file_operations中的poll操作, 给自己分配有一个等待队列头wait_queue_head_t，主动poll fd的某个进程task必须分配一个等待队列成员, 添加到fd的等待队列里面去, 并指定资源ready时的回调函数，用socket做例子, 它必须有实现一个poll操作, 这个Poll是发起轮询的代码必须主动调用的, 该函数中必须调用poll_wait(),poll_wait会将发起者作为等待队列成员加入到socket的等待队列中去，这样socket发生事件时可以通过队列头逐个通知所有关心它的进程。 简易版本 出现场景 accept 多线程中的accept函数同时监听一个listenfd，当这个fd可读的时候，等待队列中的所有进程就会被唤醒 解决：当内核接受到一个连接之后，只会唤醒等待队列上的第一个线程 epoll 使用多线程epoll对同一个fd进行监控的时候，当fd事件到来时，内核会把所有epoll线程唤醒 由于当事件来临的时候，不清楚需要几个线程，所以只能将所有线程唤醒（而在accept中，已知只会需要一个线程） 解决：多个进程将listenfd加入到epoll之前，首先尝试获取一个全局的accept_mutex互斥锁，只有获得该锁的进程才可以把listenfd加入到epoll中 线程池 当我们往任务队列中放入任务时，需要唤醒等待的线程来处理任务，如果我们使用C++标准库中的函数notify_all()来唤醒线程，则会将所有的线程都唤醒 解决方案：对于只需要唤醒一个线程的情况，我们需要使用notify_one()函数代替notify_all()只唤醒一个线程，从而避免惊群问题。 CPU调度算法QUIC 0-RTT 不用看：env_monitor、moses 启动：tool_chain_config.py","link":"/2022/11/29/Basic_must_known/"},{"title":"6.S081lab1","text":"杂项使用Tmux在一个终端中创建多个窗口12345tmux # 进入新建的会话中Ctrl + B , % # 垂直分割（左右）Ctrl + B , “ # 水平分割（上下）Ctrl + B , 方向键 # 在不同的终端中切换exit # 退出会话 启动qemu的gdb模式在第一个窗口运行 make CPUS=1 qemu-gdb, 第二个窗口运行 gdb-multiarch，开启gdb模式。 如果lient端没有连接到server，那么需要在 /root 创建 .gdbinit 文件, 加上： 1add-auto-load-safe-path /root/xv6-labs-2022/.gdbinit # xv6 directory gdb的使用方法首先是链接文件 1file fileName 常见的命令 12345r = runc = continue # 让暂停的程序继续运行n = next # 运行到下一行s = step # 单步执行，遇到函数会进入p = print # 打印变量或寄存器 实验一预备知识： pid_t wait(int *wstatus)：等待（阻塞状态）子进程状态发生变化（子进程终结、子进程被信号停止或恢复）。如果子进程是被终结，那么wait能够允许系统释放子进程的资源。如果wait没有得到执行，那么终结的子进程就会变成“僵尸”状态。exit(0)表示等待所有的子进程退出。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include \"kernel/types.h\"#include \"user/user.h\"#define RD 0 //pipe的read端#define WR 1 //pipe的write端int main(int argc, char const *argv[]) { char buf = 'P'; //用于传送的字节 int fd_c2p[2]; //子进程-&gt;父进程 int fd_p2c[2]; //父进程-&gt;子进程 pipe(fd_c2p); pipe(fd_p2c); int pid = fork(); int exit_status = 0; if (pid &lt; 0) { fprintf(2, \"fork() error!\\n\"); close(fd_c2p[RD]); close(fd_c2p[WR]); close(fd_p2c[RD]); close(fd_p2c[WR]); exit(1); } else if (pid == 0) { //子进程 close(fd_p2c[WR]); close(fd_c2p[RD]); if (read(fd_p2c[RD], &amp;buf, sizeof(char)) != sizeof(char)) { fprintf(2, \"child read() error!\\n\"); exit_status = 1; //标记出错 } else { fprintf(1, \"%d: received ping\\n\", getpid()); } if (write(fd_c2p[WR], &amp;buf, sizeof(char)) != sizeof(char)) { fprintf(2, \"child write() error!\\n\"); exit_status = 1; } close(fd_p2c[RD]); close(fd_c2p[WR]); exit(exit_status); } else { //父进程 close(fd_p2c[RD]); close(fd_c2p[WR]); if (write(fd_p2c[WR], &amp;buf, sizeof(char)) != sizeof(char)) { fprintf(2, \"parent write() error!\\n\"); exit_status = 1; } if (read(fd_c2p[RD], &amp;buf, sizeof(char)) != sizeof(char)) { fprintf(2, \"parent read() error!\\n\"); exit_status = 1; //标记出错 } else { fprintf(1, \"%d: received pong\\n\", getpid()); } close(fd_p2c[WR]); close(fd_c2p[RD]); exit(exit_status); } find 0、1、2是文件描述符（分别对应stdin、stdout、stderr） 1234567891011121314int fprintf(FILE *stream, const char *format, ...)// C 库函数发送格式化输出到流 stream 中。// -----------------------------------------------------------struct dirent{ long d_ino; /* inode number 索引节点号 */ off_t d_off; /* offset to this dirent 在目录文件中的偏移 */ unsigned short d_reclen; /* length of this d_name 文件名长 */ unsigned char d_type; /* the type of d_name 文件类型 */ char d_name [NAME_MAX+1]; /* file name (null-terminated) 文件名，最长255字符 */}// -----------------------------------------------------------// 从 str2 复制 n 个字符到 str1，但是在重叠内存块这方面，memmove() 是比 memcpy() 更安全的方法void *memmove(void *str1, const void *str2, size_t n); 实验二traceTODO: 理清楚整个调用的过程 xv6系统调用的过程，这里以fork为例:","link":"/2022/10/21/6_S081lab1/"},{"title":"C++ primer","text":"TODO：总结各种初始化方法 temp p407：内置类型或组合类型的对象的值将是未定义的，而类对象将用默认构造函数进行初始化1234567891011string *ps = new string; // empty stringint *pi = new int; // uninitialized int// 值初始化int *pi2 = new int(); // initialized as 0// 拷贝构造也可以这样auto p1 = new auto(p2);// 动态分配const 对象const int *pci = new const int(1024); 有一个很容易出错的点，当函数返回一个指向动态内存的指针的时候，调用者需要自行删除内存。还有在内存被释放之后，应该将指针空，这样可以防止使用被释放了的内存。当同一块内存释放两次，可能会对自由空间造成破坏。 接受指针参数的只能智能指针的构造函数是explicit的，所以不能将一个内置的指针隐式地转换成智能指针 12345678910111213141516shared_ptr&lt;int&gt; p1 = new int(1024); // Error!shared_ptr&lt;int&gt;p2(new int(42));// 同样函数作为返回值的时候也是不能进行隐式转换的shared_ptr&lt;int&gt; clone(int p){ // return new int(p); // Error! return shared_ptr&lt;int&gt;(new int (p));}// 在利用智能指针进行传参的时候，不能直接传入一个内置的指针void process(shared_ptr&lt;int&gt; ptr){ // 智能指针的引用+1，在函数中的引用不会小于2 ....}// 离开作用域之后，ptr所指向的内存不会被销毁// 你需要使用一个临时变量进行传参shared_ptr&lt;int&gt; p(new int(42));process(p); // 离开作用域之后p这个临时变量就会被销毁 利用get函数能够获得智慧指针的内置指针。 永远不要get初始化另一个智能指针或者为另一个智能指针赋值。他们会指向相同的内存12shared_ptr&lt;int&gt; p(new int(42));int *q = p.get(); 其他操作12345678910// 检查p是不是指向该内存的唯一指针，是则重置并分配指针if(!p.unique())p.reset(new string(*p));void smart(){ auto p = new int(); auto sp = shared_ptr&lt;int&gt;(p); cout &lt;&lt; \"address of p: \" &lt;&lt; p &lt;&lt; \"\\n addresss of sp:\" &lt;&lt; sp // p与sp的地址相同 &lt;&lt; \"\\n Count:\" &lt;&lt; sp.use_count() &lt;&lt; endl; // 1} unique_ptr 这种指针只能指向一个给定的对象，不支持普通的拷贝或者赋值操作，没有类似make_shared的标准库函数返回一个这样的指针，只能通过绑定到一个new返回的指针上12345// 转移unique_ptr&lt;int&gt;p1(p2.release());// 或者.reset释放了p1指向的内存p1.reset(p2.release());p2.release(); // Error!要释放p2指向的内存 知识点 当结构体很大且需要将结构体作为指针传入到函数中的时候，这时候最好是转入一个结构体指针 C++的函数名表示函数指针，你可以使用这个函数名作为函数的输入参数 C++中不允许main()调用自己，而在C语言中可以 存在递归的函数不能设置为内联函数 应该将默认参数全部放在参数的最后。 使用别名传参（引用传参）的时候，传入的变量会可能会被修改，其效果和传址的方式类似。 12345void swap (int &amp;a, int &amp;b);// 调用swap (a, b);//这个时候函数体内的变量和传入的变量是同一个变量 重载解析(Overload Resolution)： 编译器选择哪一个版本的函数的过程（函数可能经过重载等会有多个同名函数） Object-Oriented Programming 在类中定义的任何函数在默认情况下都会被认为是内联函数（内联函数只能在定义它的文件当中使用，但是一些编译器有智能链接器，可以让内联函数在其他文件当中被使用）p517最后一段不是很理解 重写逻辑（Rewriting Rule）： 其实类的使用与client-sever模型很相似 如果有一种更好的实现方法，那么你应该仅修改函数的具体实现细节，而不是对应的接口 构造函数： 如果没有构造函数，你不能直接对类进行初始化，因为这些数据是仅能进行私有访问的，所以你需要一个能够访问这些私有变量的函数，也就是构造函数。 构造函数不需要返回值类型，名称应该与类名一致，并且构造函数还会在类被定义的时候自动被调用，同时为了避免混淆，构造函数中的参数名称不能与成员变量的名称一致，对于成员变量可以在变量名称前面加上m_或者在名称后面加上_ 构造函数不能直接通过对象直接访问，当构造函数完成它的任务之后，这个对象的构造函数就消失了。 关于构造函数的使用 123456789Stock food = Stock(\"World Cabbage\", 250, 1.25);Stock garment(\"Furry Mason\", 50, 2.5);Stock pstock* = new Stock(\"Electroshock Games\", 19, 19.0);// List InitializationStock hot_tip = {\"Derivative Plus Plus\", 100, 45.0};Stock hot_tip{\"Derivative Plus Plus\", 100, 45.0}Stock temp{}; 在对一个以赋值的类变量进行赋值的时候，编译器会先构造一个临时的变量，然后将内容转移到另一个类变量中，这时候再删除这个变量。一些编译器会让这个临时变量存在一段时间，之后再调用析构函数。下面是一个关于这方面的例子，首先利用一个构造函数创建一个变量，然后对这个变量进行一个重新赋值，这时候，就需要上面的临时变量了。12Stock stock2 = Stock(\"Boffo Objects\", 2, 2.0); // Constructor calledstock2 = Stock(\"Nifty Foods\", 10, 50.0); // The constructor and destructor for temporary variable will be called所以可以看出，利用第一种方法直接对变量初始化是一种更加高效的方法（防止临时变量的出现）。 当程序退出的时候，先声明的变量的构造器会最后被调用，因为这些变量都是存放在一个栈中的。 const 成员函数 (静态成员变量)：有时候用一个const关键字修饰了一个类变量，这个变量应该是不能被修改的，但是对于一些函数不能保证不修改这个变量，所以可以在函数后面加上一个const关键字，声明这个函数是不修改静态变量的。1void show() const; // Promises not to change invoking objectTIPS：当你声明的成员函数不修改变量的时候，你最好在后面加上一个const关键字。 对象列表你可以对列表中的每一个元素分别使用构造函数：1234567const int STKS = 4;Stock stocks[STKS] = { Stock(\"NanoSmart\", 12.5, 20), Stock(\"Boffo Objects\", 200, 2.0), Stock(\"Monolithic Obelisks\", 130, 3.25), Stock(\"Fleep Enterprises\", 60, 6.5)}; this 指针一个指向类自己的指针，当一个函数访问私有变量的时候，实际上就是在使用this这个类来访问。12345678// A member functionvoid show(){ cout &lt;&lt; val&lt;&lt;endl;}// C-typevoid show(const Stock*this){ cout &lt;&lt; this-&gt;val&lt;&lt;endl;} Class Scope Constants属于这个类的常量。1234class test{private: enum {Months=12};}这种声明不会创建类数据成员。 第二种定义类内常量的方式——使用关键词static12345class Bakery{private: static const int Months = 12; ....} 拥有类作用域的枚举类型（C++11）在通常的枚举类型中，其中的枚举变量的名称不能一致，因为两个不同的枚举变量之间的作用域是一致的，但是在C++11中，提供了一种拥有类作用域的枚举类型12enum class egg{Small, Medium, Large, Jumbo};egg choice = egg::Larger;但是不像传统的枚举类型，类枚举类型不能进行隐式类型转换。12345678910111213141516enum egg_old {Small, Medium, Large, Jumbo}; // unscopedenum class t_shirt {Small, Medium, Large, Xlarge}; // scopedegg_old one = Medium; // unscopedt_shirt rolf = t_shirt::Large; // scopedint king = one; // implicit type conversion for unscopedint ring = rolf; // not allowed, no implicit type conversionif (king &lt; Jumbo) // allowedstd::cout &lt;&lt; \"Jumbo converted to int before comparison.\\n\";if (king &lt; t_shirt::Medium) // not allowedstd::cout &lt;&lt; \"Not allowed: &lt; not defined for scoped enum.\\n\";// 但是可以进行显示类型转换int Frodo = int(t_shirt::Small);//可以指定其中变量的类型enum class : short pizza {Small, Medium, Large, XLarge}; 输入输出方面的命令1234567getline(cin, string_var); // 读取整行，包括前导和嵌入的空格（应该是遇到\"\\n\"时结束）cin &gt;&gt; char_variable; // 从第一个非空格开始阅读，当读取到下一个空白字符时，停止读取cin.get(); // cin对象的内置函数，获取一个字符，并返回（赋值的方式）/*对于这个函数，可以用于暂停程序的一个方法（按下回车以继续）*/// What are the differences they make ? Separate Compilation在编写大型程序的时候，最好将程序放在三个文件当中。 一个是头文件，这个用于存储函数头和一些结构体的声明，但是不能定义一些具体的变量，因为这个头文件可能会被不同的程序文件所包含，这使得头文件可能会被反复编译，这可能会导致重定义的问题。 一个是用于定义函数的文件。 一个是主程序文件，这个文件中包含main文件。 守卫：为了防止一些变量被反复编译，C++中定义了守卫1234# ifndefine FUNCTION_NAME# define FUNCTION_NAME....// Your code# endif当存在多个程序文件的时候，程序就会进行联合编译。在window中直接运行即可，但是在UNIX系统中需要指定联合编译的文件。(在Linux系统中只需要执行其中一个文件即可，这是用include语句包含了对应的文件)123CC file1.cpp file2.cppg++ file1.cpp file2.cpp 在包含文件的时候，不同的标点符号会使得程序查找文件的范围顺序有所差异12# include &lt;file&gt; //在系统文件中寻找# include \"file\" // 优先在当前路径下查找文件 Storage Duration, Scope, and LinkageC++中的常见变量的生命周期： Automatic storage duration ： 在函数中定义的变量，当函数结束的时候，变量会被释放 Static storage duration： 在函数外或者其他地方定义的变量，当程序结束的时候被释放 Thread storage duration (C++11) ： 生命周期局限于某一个线程 Dynamic storage duration ： 由关键字new申请的空间，生命周期由操作者确定，或者在程序结束的时候被释放 变量的作用域（Scope）123456789101112int main() { using namespace std; int outter = 100; if(true){ int outter = 10; cout &lt;&lt; \"The inner = \" &lt;&lt; outter &lt;&lt; endl; // 这里的outter与外部的无关 } cout &lt;&lt; \"The outer = \" &lt;&lt; outter &lt;&lt; endl;}/* The inner = 10The outer = 100*/ 在函数内部出现与全局变量一致的变量，这个时候函数内的这个变量会是局部变量，想要访问全局变量需要使用作用域解析运算符::123456double warming = 10;void local (){ double warming = 5; cout &lt;&lt; \"Local = \"&lt;&lt; warming&lt;&lt;\"\\n\"; cout &lt;&lt; \"Global = \"&lt;&lt; :: warming &lt;&lt; endl; // 访问全局变量}编译器是通过利用栈将这些变量的优先级进行调整的，当进入一个函数的时候，声明的变量会出现在栈顶端，这时候条用这个变量的时候就会优先调用这个函数内的局部变量。全局变量应该仅仅被使用于一些通用的变量123456789101112const char * const months[12] ={\"January\", \"February\", \"March\", \"April\", \"May\",\"June\", \"July\", \"August\", \"September\", \"October\",\"November\", \"December\"};/*这里第二个const是为了保证数组不被改变，第一个是为了使得数组内的指针所指向的元素不会发生改变这样理解：第一个const实际上是得到一个类型const char* 这代表数组元素，第二个修饰数组*/const关键词实际上就是在表明变量的内存一旦确定之后在之后就不应该被改变了在联合编译的时候，一个文件中定义的全局变量会在另外一个文件中被访问到，这时候可以使用static关键词，这使得这个变量仅仅存在于当前文件中。 在Ubuntu上面没有办法成功编译！ 在函数内定义变量时加上这个关键词，则可以使得这个变量在整个文件中都能够被访问到。当这个关键词被加上之后，这个变量当且仅当被定义的时候初始化为0，其余的时候这其中的值不会被初始化。 volatile关键词当一个变量多次被使用的时候，编译器会将这个变量放到寄存器中，也就是说编译器会为了系统的优化改动定义的变量存储的地址。如果加上volatile关键词，那么这种改动就不会发生 mutable在一个const修饰的变量中，被mutable修饰的成员变量还是能够被修改.1234567struct data{ mutable int data; float value;}data d = {10, 10.23}d.data = 20; // Allowd.value = 10.20; // Disallow externextern 修饰的变量不能直接初始化。但是如果想用常量作为具有外部链接的变量，那么可以使用const重载这个修辞1const extern int con = 10; Functions and Linkage由于C++中不允许一个函数在另外一个函数中定义，所以，所有的函数的作用域都是静态存储的周期（当程序结束时被释放）。但是你可以在函数原型前面加上一些关键词来指定函数的作用域（像extern、static等）在默认的情况下，函数都是有外部链接的，也就是说联合编译中，其他文件是可以调用不同文件中的函数的。但是要调用其他文件中的函数还是需要包含所使用函数的函数原型。编译器查找的方式是根据函数原型的作用域确定查找范围的。如果你在文件中定义了一个与外部函数有相同名称的函数，那么最终的这个内部链接的函数还覆盖外部链接的函数。 Language Linking编译器在链接的过程中需要为每一个不同的函数找一个不同的符号名称（symbolic name）。在C语言中，因为函数不允许重载，所以可以在函数名称前面简单地加上一个下划线即可，但是由于在C++中存在函数的重载，所以需要正在这个符号语言中加上函数的参数信息。例如1spiff(double, double) to _spiff_d_d如果我们需要在C++中使用C语言中的函数，我们可以显式地指定这种符号名称的类型123extern \"C\" void spiff(int); // use C protocol for name look-upextern void spoff(int); // use C++ protocol for name look-upextern \"C++\" void spaff(int); // use C++ protocol for name look-up Storage Schemes and Dynamic Allocation编译器会为不同的变量划分出三个不同的内存，分别是：静态变量区、局部变量区（automatic variable）、动态变量区。但是，编译器会适应静态变量存储区或者局部变量区的内存跟踪动态变量区的变量（也就是指针）。 虽然说动态生成的数据的存储空间在程序结束的时候会自动被释放掉，但是对于一些健壮性不是很好的操作系统，这个自动过程可能不会自动执行，所以还是最好使用delete将new出来的变量删掉。 动态变量的初始化：12345int *a = new int (10);struct name{int x; int y; int z};name* n = new name{1,2,3}; // 初始化结构体new、delete是可以被替换的，所以你可以根据自己的需求对这两个函数进行调整。你可以指定申请变量的存储的地址12345# include&lt;new&gt;char buffer[100]; // 在静态变量区申请的内存int* a = new (buffer) double [10]; // 申请的变量会被存储在指定的内存区域// 但是最终不能使用delete删除，这会导致错误。这是因为变量申请的空间是在静态变量空间中，而delete只能删除动态变量空间传统的new会存储之前可用的内存的位置，或者搜索可用的内存，但是可替换的new不会检查当前的内存是否被占用，也不存储之前可用的内存的位置信息。实际上可替换的new只是简单地将传入的地址的类型转换成void*使得输出的地址能够分配给任意类型的指针。 名字域在每一个定义区域中各个变量之间的定义不会发生冲突。 作用域，指的是在变量定义之后的区域，也就是程序中可以使用这个变量的区域。不同的定义区域中的变量的作用域不会发生冲突。 使用关键字namespace定义自己的名字域,这些名字域中可以包含函数或者其他名字域，也可以自己在里面定义一个名字域。由于为了防止直接导入一些不需要的变量可能导致的问题，你可以使用名字域解析运算符或者指定导入变量的方式。也可以自定义一个名字域，在其中放入自己常用的函数或变量。 将名字域导入到当前的定义域中的方法123456789101112131415161718192021222324252627282930namespace Name{ int age = 20; string first; string second; string Concatenate(string a, string b){ return a + b; } using std::out; using std::endl; namespace life{};}// 给名字域起一个别名namespace n = Name::lifevoid func(){ // using declaration using Name::first; //这种方式就是将这个变量导入到当前的定义域中，这时候first不能再次被定义 // 有时候利用这种方式导入，可能会导致冲突，编译器会避免这种导入}int age = 25;void func2(){ // using directive using namespace Name; // 导入到当前定义域，其他的定义域中不能使用这个名字域 int age = 10; cout &lt;&lt; age &lt;&lt; Name::age &lt;&lt; ::age; // 10 20 25 //这种方式导入，当前的定义域可以直接使用名字域中所有的变量，但是其中的变量没有局部作用域，所以可以被覆写} 对于名字域的定义不一定需要指定名字。1234567namespace { int count;}// 接下来的代码都能够使用这里的变量// 等价于static int count; 注意一点，静态变量不是不能修改，而是只会初始化一次。之后在遇到初始化的语句就会直接被忽略。 函数模板 在使用模板的时候，如果出现比较，那么比较的东西可能会与预期的不太一致。还有在赋值的时候可能会出现数值和地址之间的冲突。1T c = a*b // 这时候c可能会被赋予一个新的地址 当你想要对模板类型进行具体化的时候，可以采用以下策略：1234template&lt;typename T&gt;T maxn(T arr[], int n){}template &lt;&gt; char* maxn&lt;char*&gt;(char* arr[], int n){} // &lt;char*&gt;是可以忽略的 在对模板类型进行具体化的时候，这个过程称为Implicit Instantiation,但是C++提供了显示初始化Explicit Instantiation.12template void Swap&lt;int&gt;(int &amp;, int &amp;);template void Swap(int &amp;, int &amp;); 当输入的变量类型不一致的时候，使用模板的函数可能会报错，这时候需要显示实例化12345template &lt;class T&gt;T Add(T a, T b) return a + b;int m = 6;double x = 10.2;cout &lt;&lt; Add&lt;double&gt;(x,m) &lt;&lt; endl; // 不实例化会导致报错 p429 上述概念的使用场景： 隐式具体化—-模板类型的自动推断 显示具体化—-自定义类型的参数必须使用（？） 显示实例化—-实例化参数1234567891011121314151617 template &lt;class T&gt;void Swap (T &amp;, T &amp;); // template prototypetemplate &lt;&gt; void Swap&lt;job&gt;(job &amp;, job &amp;); // explicit specialization for jobint main(void){template void Swap&lt;char&gt;(char &amp;, char &amp;); // explicit instantiation for charshort a, b;...Swap(a,b); // implicit template instantiation for shortjob n, m;...Swap(n, m); // use explicit specialization for jobchar g, h;...Swap(g, h); // use explicit template instantiation for char...} 函数指针我们想让一个函数能够调用其他函数。这需要完成以下三个步骤： 获取函数的地址 12process(think()) // 将函数的返回值作为传入参数process(think) // 将函数的地址作为参数 定义指向函数的指针 函数签名（function’s signature）: 函数的参数列表C++中的函数签名(function signature)：包含了一个函数的信息，包括函数名、参数类型、参数个数、顺序以及它所在的类和命名空间。（这是为了帮助编译器准确地找到想要访问的函数） 12345678double pam(int); // Function Prototypedouble (*pf) (int); // 指针pf指向一个输入参数为int，输出为double的函数/*本质上就是将函数名用(*pf)进行代替了，这里还利用了括号的具有更高优先级的特性，指明这里是一个指针，如果pf没有括号，那么就变成一个函数了*/void estimate(int lines, double(*pf)(int)); 在函数中使用函数指针可以通过函数名或者函数指针访问函数。12double x = pam(4); // Preferdouble x = (*pf)(5); 函数指针可能遇到的问题定义以下函数的函数指针会不会重名？123const double * f1(const double ar[], int n);const double * f2(const double [], int);const double * f3(const double *, int); 向函数中传入一个数组和传入一个指针是等价的. 在函数原型中，参数的名称是可以忽略的，“const double []”就是忽略了数组的名称所以上述的三个函数是一致的 在对函数指针进行初始化的时候，可以利用C++11的新特性，auto自动推断对应的类型123const double * (*p1)(const double *, int) = f1;// Equivelent toauto p2 = f2; 定义一个函数指针数组1const double * (*pa[3])(const double *, int) = {f1, f2, f3};分析中括号的作用： 因为中括号的优先级比较高，所以中括号优先指明这个名称是个数组 Automatic type deduction works with a single initializer value, not an initialization list.也就是说这里前面的指针定义不能用auto代替（因为初始化的是一个数组）。但是我们能够用auto推断数组指针类型1auto pb = pa;数组名a表示的是数组的第一个元素的地址，&amp;a表示的所有数组所有元素的地址，&amp;a+1就表示下一个数组（是不是一个保存数组每一个元素的地址的数组？）1234567891011 int a[3]{ 1,2,3 }; cout &lt;&lt; \"a:\" &lt;&lt; a &lt;&lt; \"\\t&amp;a:\" &lt;&lt; &amp;a &lt;&lt; endl; cout &lt;&lt; \"size of a:\" &lt;&lt; sizeof(a) &lt;&lt; \"\\tsize of &amp;a:\" &lt;&lt; sizeof(&amp;a) &lt;&lt; endl; cout &lt;&lt; \"a + 1:\" &lt;&lt; a + 1 &lt;&lt; \"\\t&amp;a+1\" &lt;&lt; &amp;a + 1 &lt;&lt; endl; /*a:00AFFCA4 &amp;a:00AFFCA4size of a:12 size of &amp;a:4a + 1:00AFFCA8 &amp;a+1:00AFFCB0 这里增加了C，也就是12*/// 可见","link":"/2022/10/12/C-primer/"},{"title":"Clickhouse源码阅读日记","text":"源码列（Columns）字段（Field） src\\Core\\Field.h 字段实现是一个联合类， std::aligned_union_t，而一行数据在此文件当中定义为using Row = std::vector&lt;Field&gt;; Field 中并没有足够的关于一个表（table）的特定数据类型的信息。比如，UInt8、UInt16、UInt32 和 UInt64 在 Field 中均表示为 UInt64。 在代码当中，createConcrete 是一个模板函数，用于在给定的存储空间中创建一个具体的对象。小类型可能会被存储为更宽的类型，例如 char 可能会被存储为 UInt64。 块（Block） If we have a Block, we have data (in the IColumn object), we have information about its type (in IDataType) that tells us how to deal with that column, and we have the column name. 这个类的成员变量当中有一个由IColumn指针组成的向量，还有一个由map组成的索引，用于存储列名到列索引的映射。同时还包含一个块信息的结构体。 MaterializedViewMaterializedView是一种特殊的表，它根据预定义的SELECT查询语句存储数据。当插入新数据到源表时，这些数据也会被插入到MaterializedView中。 MaterializedView的主要用途是预计算复杂的查询。例如，你可能有一个包含大量数据的表，你需要对这个表进行一些复杂的聚合查询。如果每次需要结果时都运行这些查询，可能会非常慢。相反，你可以创建一个MaterializedView，它根据你的查询预先计算结果。然后，你可以直接查询MaterializedView，这通常会比直接查询原始表快得多。 编程范式// NOLINT在代码中添加 NOLINT 注释是一种指示，通常用于告诉静态代码分析工具或代码审查工具不要对特定行或块发出警告或错误报告。 例如在使用reinterpret_cast的时候 类名称：*Helper通常是一个模板类的特化，可以是一个中间表示，其中实现了*（类名）的一些功能，作为统一的处理方式 例如：template &lt;typename T&gt; class ColumnVectorHelper; 类名称：*Dummy在C++编程中，如果一个类被命名为含有”Dummy”的名称，比如IColumnDummy，这通常意味着该类是一个占位符类（Placeholder Class）或者是一个模拟类（Mock Class）。 例如：class IColumnDummy : public IColumn; 在数组第一个元素前预留一个空间（-1th）这个设计在将偏移量数组转换为大小数组时提供了性能优势。在处理这种转换时，通常需要计算当前元素的大小，即下一个元素的偏移量减去当前元素的偏移量。有了额外的 0 值的 -1th 元素，计算第一个元素的大小时，可以直接用 0 减去第一个元素的偏移量，而不需要特殊处理。这样简化了代码，减少了条件分支，并可能提高计算速度。 在链表插入的过程中使用dummy_header也是类似的设计 1.在高性能计算或大数据处理中，避免条件分支可以显著提高循环的效率，因为现代处理器对分支预测有困难，尤其是在分支密集的情况下。2.在处理向量数据或使用单指令多数据（SIMD）指令时，if 语句可能导致向量操作的分裂3.分支惩罚 对于 String 列和 Array 列，则由两个向量组成：其中一个向量连续存储所有的 String 或数组元素，另一个存储每一个 String 或 Array 的起始元素在第一个向量中的偏移。 在这种场景下，偏移数组可能需要转换成大小数组，这个时候可以利用到这种优化 概念loop vectorization(循环向量化)循环向量化是一种编译器优化技术，用于将循环转换为向量化指令，以便在单个指令中处理多个数据元素。这种技术可以提高程序的性能，因为它可以利用现代处理器的SIMD指令集，同时减少循环的迭代次数。 例如：for (int i = 0; i &lt; n; ++i) { c[i] = a[i] + b[i]; } 语言/语法C++11 using 引入构造函数123456789101112#define DEFINE_FIELD_VECTOR(X) \\struct X : public FieldVector \\{ \\ using FieldVector::FieldVector; \\}'''using FieldVector::FieldVector;：这是 C++11 引入的 using 声明，它引入了基类（FieldVector）的构造函数到派生类（X）的作用域中。(第一个FieldVector是类名，第二个是构造函数的函数名称，这引入了所有的构造函数)这意味着 X 类可以使用 FieldVector 的所有构造函数，而无需重复定义。这有助于避免构造函数的代码重复，并保持代码简洁。'''","link":"/2024/05/29/Clickhouse%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E6%97%A5%E8%AE%B0/"},{"title":"C++标准11-14","text":"1.演进、环境与资源C++1.0 : C++ 98C++2.0: C++11 12//查看支持的版本cout &lt;&lt; __cplusplus &lt;&lt; enl; 2. Variadic Templates + 1~21数量不定的模板参数12345678910void print(){} // 处理最后的情况，没有参数被传入，这个作为函数出口// 这样可以传入任意个数任意类型的参数template&lt;typename T, typename... Types&gt;void print(const T&amp; firstArg, const Types&amp;... args){ cout &lt;&lt; firstArg &lt;&lt; endl; print(args...)； // 传入后不断被分开（这实际上是一个包）n = (n - 1) + 1}sizeof...(args); // 查看包中的参数个数...: 实际上就是一个所谓的包 1234567891011121314151617181920212223// 利用\"...\" 实现递归继承template&lt;typename... Values&gt; class tuple; // 这种数据结构可以方任意个数以及任意类型的数据template&lt;&gt; class tuple&lt;&gt;{};template&lt;typename Head, typename... Tail&gt;class tuple&lt;Head, Tail...&gt; : private tuple&lt;Tail...&gt;{ typedef tuple&lt;Tail...&gt; inherited;public: tuple(){} tuple(Head v, Tail... vtail) : m_head(v), inherited(vtail...){} // 这是个初始化列表 // 获得变量类型 // typename Head::type head() {return m_head;} // 这样写会报错，因为像int这样的类型没有无法调用type auto head()-&gt;decltype(m_head){return m_head;} // 或者 // Head head() {return m_head; } inherited&amp; tail() {return *this;}protected: Head m_head;}; 谁更特化，就优先调用谁。12345678910// 这个版本更加特化template&lt;typename T, typename... Types&gt;void print(const T&amp; firstArg, const Types&amp;... args){ cout &lt;&lt; firstArg &lt;&lt; endl; print(args...)； // 传入后不断被分开（这实际上是一个包）n = (n - 1) + 1 }// 与上面的函数共存的话，这个函数永远不会被调用template&lt;typename... Types&gt;void printX(const Types&amp;... args){/**********/}一些应用实例123456// 在多个参数中找到最大值。这一点也可以通过初始化列表直接调用标准库中的max函数:max({1,3,2,5})int maximum(int n) return n;template&lt;typename... Args&gt;int maximum(int n, Args... args) return std::max(n, maximum(args...));// 标准库中的max函数只能接收两个参数，这里这样调用就像是一个栈 递归复合12345678910111213141516171819template&lt;typename... Values&gt;class tup;template&lt;&gt;class tup&lt;&gt;{ };template&lt;typename Head, typename... Tail&gt;class tup&lt;Head, Tail&gt;{ typedef tup&lt;Tail...&gt;composited;protected: composited m_tail; Head m_head;public: tup(){ } tup(Head v, Tail... vtail) : m_tail(vtail...), m_head(v) { } Head head() {return m_head;} composited&amp; tail(){return m_tail;}} 3空指针： nullptr 还可以用0或者NULL定义空指针.但是在传递参数的时候可能会存在歧义1234void f(int);void f(void*);f(nullptr); // call void f(void*) auto: 尽量当类型比较长或者复杂的时候才使用，或者需要写lambda的类型 4.Uniform Initialization12345// 初始化对象的方法className c = {...};className c(...);className c{...}; // Uniform Initialization 直接在变量后面的大括号中写初始化的数值int values[] {...}; 当编译器遇到{}时，会创建一个 initializer_list\\，然后关联到array,然后由此传给构造函数（分解之后，变成构造函数接收的形式） 4，5、Initializer_list1234567891011121314151617int i; // 未定义int i{}; // 初始化为0class P{public: P(int a, int b){...} P(initializer_list&lt;list&gt; initlist){ ...}}P p(1, 2); P q{77, 5}; // 如果第二个构造函数不存在，那么编译器会将这两个数拆解，找到接收对应数目的参数的构造函数P r{1, 2, 3}; // 如果第二个构造函数不存在，则会报错，因为不存在接收三个参数的构造函数// 可以利用初始化列表和max函数在三个或以上的数据中找到最大值max({1,2,9}); 7. Explicit for constructor taking more than one argument这个关键字存在时，构造函数不会被隐式调用。12Complex c1(12, 5);Complex c2 = c1 + 5; // 5会被隐式地转换成complex类型，如果构造函数被加上了explicit 则会报错 8. range-based for statement1234// 这个循环中会有一个赋值地动作，所以可能会出现类型转换for (decl : coll) { statement;} 9. =default, =delete只能用于构造函数和析构函数，以及赋值重载的函数中。普通的函数没有这种性质。 什么时候需要自己定义Big-Three 呢？大多数时候，当类中有指针的需要写。123456789class Foo{public: Foo(int i) : _i(i) { } Foo() =default;// 保留默认的构造函数 ~Foo() = delete;// 删除默认的析构函数 ~Foo(typename arg);} 10.Alias Template1234567template &lt;typename T&gt;using Vec = std::vector&lt;T, MyAlloc&lt;T&gt;&gt;; // 设置化名// 注意不能对别名进行特化或者偏特化Vec&lt;int&gt; coll; // 等价于 std::vector&lt;int, MyAlloc&lt;int&gt;&gt; coll; // 注意使用define是无法达到相同的效果的，define仅仅会将指定的内容原封不动套入 12345678910111213//传入任意类型的数据, 这里借助容器的萃取机来获取数值类型template&lt;typename Container&gt;void test_moveable(Container c){ typerdef typername iterator_traits&lt;typename Container::iterator&gt;::value_type Valtype; for(long i = 0; i &lt; SIZE; ++i) c.insert(c.end(), Valtype()); output_static_data(*(c.begin()); Container c1(c); Container c2(std::move(c)); c1.swap(c2);} 11.template template parameter化名模板123456789101112131415161718192021template&lt;typename T, template&lt;class&gt; class Container&gt;class XCls{private: Container&lt;T&gt; c;public: XCls(){ for(long i = 0; i &lt; SIZE; ++i) c.insert(c.end, T()); output_static_data(T()); Container&lt;T&gt;c1(c); Container&lt;T&gt;c2(std::move(c)); c1.swap(c2); }};// 想要声明变量，你需要定义alias templatetemplate&lt;typename T&gt; // 这个不能在function body之中声明using Vec = vector&lt;T, allocator&lt;T&gt;&gt;;XCls&lt;MyString, Vec&gt;c1; 12.Type Alias, noexcept, override, finalType Alias:1234567891011121314using func = void(*)(int, int); // 这时候就是一个函数指针void example(int, int){}func fn = example;// 可以使用类型化名隐藏模板参数template &lt;class CharT&gt; using mystring = std::basic_string&lt;CahrT, std::char_traits&lt;CahrT&gt;&gt;;mystring&lt;char&gt;std;//放到结构体中template&lt;typename T&gt;struct Container{ using value_type = T;}; noexcept:不抛出异常，需要在vector的构造函数上使用，使得vector在增长的时候能够调用构造函数12345void foo() noexcept; // void foo() noexcept(true);void swap(Type&amp; x, Type&amp; y) noexcept (noexcept (x.swap(y))){ x.swap(y);} Override:\\覆写需要签名一致，但是如果不一致编译器不会报错，这会产生一个新的函数，加上关键字override会让函数抛出异常。1234struct Derived2:Base{ virtual void vfunc(int) override {} virtual void vfunc(float) override{}}; final: 无法被继承 13. decltype找出表达式的类型，相当于typeof。123456789101112131415161718192021map&lt;string, float&gt;coll;decltype(coll)::value_type elem;// 定义返回类型template &lt;typename T1, typename T2&gt;decltype(x+y) add(T1 x, T2 y); // 在C++11之前不可实现，因为对象在这个范围内还没有引入template&lt;typename T1, typename T2&gt;auto add(T1 x, T2 y)-&gt;decltype(x+y);typedef typename decltype(obj)::iterator iType; // 等价于typedef typename T::iterator iType;// 将decltype used to pass the type of a lambdaauto cmp = [](const Person&amp; p1, const Person&amp; p2){ return p1.lastname() &lt; p2.lastname() || (p1.lastname() == p2.lastname() &amp;&amp; p1.firstname() &lt; p2.firstname());};std::set&lt;Person, decltype(cmp)&gt; coll(cmp); lambdas12345678910111213141516171819auto f = [id] mutable { // 不加mutable就没有办法修改id std::cout &lt;&lt; id &lt;&lt; std::endl; ++id;};// 等价形式class Functor{private: int id;public: void operator() (){ std::cout &lt;&lt; id &lt;&lt; std::endl; }};Functor f;// 写法举例[x, y](int n) {return x &lt; n &amp;&amp; n &lt; y; } lambda没有默认构造函数和赋值操作。 第二讲：标准库23. Rvalue refernces and Move Semantics 临时对象就是一种右值（对于自定义的类（例如string）可以，int等类型不可以） 右值不可以放在左边 右值在被使用之后，应该被销毁，因为对于它的操作实际上就是改变指针指向，原先的右值的指针会被删除，这样这个右值也需要被删除 24. Perfect Forwarding（完美传递）12345678910111213// 传入左值的版本void process(int&amp; i){ ......}// 传入右值的版本void process(int&amp;&amp; i){ ......}int a = 0;process(a); // 变量被视为左值process(1); // 临时对象被视为右值process(move(a)); // 强制将a由左值转换成右值 不完美传递：在参数传递过程中，参数的左值右值可能会发生变化。这个问题可以使用标准库中的forward函数避免。 25. 写一个move-aware class12345678910111213// 复制构造 MyString(const Mystring&amp; str) : _len(str._len){ _init_data(str._data);}// &amp;&amp;：右值引用; 这个是移动构造MyString(MyString&amp;&amp; str) noexcept : _data(str._data), _len(str._len){ str._len = 0; str._data = NULL; // 因为传入的如果是临时变量，这个变量的生命周期只在这个函数中，如果这个指针还是指向原先的地址，那么在这个变量生命周期结束的时候，原先地址的数据也会被删除。 // 有那么一瞬间，复制对象和这个临时对象之间指向的是同一个地址 } 26.Move-aware class 对容器的效能测试似乎只对vector的影响很大。（两种不同的构造函数）12345678M c1(c); // 如果是vector的话，在内存拓展的时候，需要一个个调用构造函数vector(const vector&amp; __x) : _Base(....){....} // 调用的构造函数 M c2(std::move(c)); // 将c当成右值(这样只是交换了指针)； 往下c就不能再用了，指针被修改了// 调用的构造函数vector(vector&amp;&amp; __x) noexcept : _Base(std::move(__x)) {} 30.Hash function 对于整数（数字，long也行），其哈希值就是其本身 对于字符串，用一个哈希函数，得到一个尽可能乱的哈希值 补充动态内存（C++ Primer chapter12） 分配在静态或栈内存中的对象由编译器自动创建和销毁","link":"/2022/10/12/C-%E6%A0%87%E5%87%8611-14/"},{"title":"Database","text":"杂项 SQL therefore treats as unknown the result of any comparison involving a null value 我们通过DBMS访问数据库 NTILE 函数 将排序分区中的行划分为特定数量的组。从每个组分配一个从一开始的桶号。对于每一行，NTILE()函数返回一个桶号，表示行所属的组。 条件语句 if 语句 IF(condition, value_if_true, value_if_false) 1update salary set sex = if(sex = 'm', 'f', 'm'); IFNULL(expression_1,expression_2) 如果 expression_1不为 NULL，则 IFNULL函数返回 expression_1; 否则返回 expression_2的结果。 ```sqlselect ifNull((select distinct salary from employee order by salary desc limit 1, 1 ), null) as SecondHighestSalary;1234567891011- case ```sql update salary set sex=(case sex when 'm' then 'f' else 'm' end); &lt;!-- 通式 --&gt; CASE WHEN condition1 THEN result1 WHEN condition2 THEN result2 WHEN conditionN THEN resultN ELSE result END; 字符串 substr: substr(string,pos,end)这个函数不填入end就是取pos位置及其之后所有的字符 LEFT(str, n): 获得字符串左边n个字符（right同理） length(str): 获得字符串的大小 CONCAT(str1, str2, ...)：合并字符串函数 group_concat() concatenate data from multiple rows into one field. 1234SELECT col1, col2, ..., colNGROUP_CONCAT ( [DISTINCT] col_name1 [ORDER BY clause] [SEPARATOR str_val] ) FROM table_name GROUP BY col_name2; 时间 datediff(date1, date2): 如果date1比date2大，结果为正；如果date1比date2小，结果为负。 timestampdiff(时间类型, 日期1, 日期2): 这个函数和 diffdate的正、负号规则刚好相反。日期1大于日期2，结果为负，日期1小于日期2，结果为正。 通过添加“day”, “hour”, “second”等关键词，来规定计算天数差、小时数差、还是分钟数差 1select timestampdiff(day, '2019-01-01', '2019-01-03') as dayInterval; --计算天数差 DATE_SUB(date,INTERVAL expr type): 从日期减去指定的时间间隔。 ```sqlwhere activity_date &gt; date_sub(‘2019-07-27’, interval 30 day)123456789 - `year(time)`: 获取时间中的年份**from CMU**```sql-- 窗口函数, 按照指定的分组操作函数（将每一个分组数据作为一个函数的统计对象）select row_number() over (partition by cid) from titles;-- Common Table Expressionswith cteName(n1, n2) as (select 1, 2) select n1 + n2 from ctenName; 基本命令 limit 20 offset 10; 123select distinct vend_id from products; --只返回不同值select prod_name from products limit 5; --返回不多于5行select prod_name from products limit 5, 6; --从第5行开始的6行（编号从一开始） 排序命令1234-- 排序select prod_name from products order by prod_name, prod_price; --排序select prod_name from products order by prod_name, prod_price DESC; --降序排序select prod_name from products order by prod_price DESC, prod_name; --仅价格降序排序（多个列上进行排序，则需要在列名后面都加上这样的关键字，ASC:升序） 过滤数据1234567891011121314151617181920-- 过滤数据 --select prod_name, prod_price from products where prod_price=2.50; -- 使用where关键字进行条件筛选。与order by 共用的时候，应该放在where之后-- 几个where的子句符号. &lt;&gt;, !=:不等于； BETWEEN:在指定的两个值之间-- 单引号用于限定字符串，当值与字符串进行比较，需要使用单引号select prod_name, prod_price from products where prod_name = 'fuses';~ where prod_price between 5 and 10; -- ~表示与前面语句一致，下同-- 检查NULL值.这在匹配过滤或者不匹配过滤时候不会返回。~ where prod_price is NULL;-- 次序计算，AND的优先级要更高，但是最好还是利用圆括号将操作符分开select prod_name, prod_price from products where (vend_id = 1002 or vend_id = 1003) AND prod_price &gt;= 10; -- IN 操作符指定条件范围select prod_name, prod_price from products where vend_id in (1002, 1003) order by prod_name;-- NOT操作符~ where vend_id NOT IN (1002, 1003) ~ 利用通配符进行过滤通配符(wildcard)：用来匹配值的一部分特殊字符 12345-- %: 表示任意长度的字符串，但是不包含NULLselect prod_id, prod_name from products where prod_name like 'jet%'; -- 搜索以'jet'开头的词-- _: 只匹配单个字符~ like '_ to anvil'; 通配符搜索的处理一般要比前面讨论的其他搜索所花时间更长。如果不是必要不要使用，使用的时候最好不要放在搜索的开始（搜索量太大）。 利用正则表达式进行搜索只需要将原先的 LIKE关键词转换成 REGEXP。注意前者是匹配文本在是这个，后者是存在这个，也就是后者只需要这个模式在文本中有出现即可，而前者需要全部一致。 12345678910111213141516-- '.'：表示能够匹配任意的字符select prod_name from products where prod_name REGEXP '.000' order by prod_name; -- 正则表达式默认不区分大小写，如果需要则要加上binary关键词~ where prod_name REGEXP binary 'JetPack .000';-- OR 匹配~ regexp '1000|2000' ~;-- 匹配几个字符之一~ REGEXP '[123] Ton' ~; -- 1 Ton、 2 Ton都行'1|2|3 Ton' -- 等价于~ regexp '[1-5] Ton'; -- 范围匹配~ where vend_name regexp '\\\\.'; -- 匹配特殊字符，用\\\\ 作为前导（转义）-- 空白元字符： \\\\f----换页； \\\\n---换行 。。。。-- 匹配字符类 匹配多个实例可以利用重复元字符对目标字符中的某一个字符进行指定的性质匹配。 12345select prod_name from products where prod_name regexp '\\\\([0-9] sticks?\\\\)'order by prod_name; -- 最后匹配的是stick 或者 sticks，最后？表示s是可选的匹配字符串-- [:digit:]: 匹配数字； 第二个[]是为了指明{4} 的作用域~ where prod_name regexp '[[:digit:]]{4}'; -- 匹配连续一起的四个数字 定位符 123-- 找到以数字开头（包括小数点）~ where prod_name regexp '[0-9\\\\.]'; -- 这样不行，这会在文本的任意位置查找匹配~ where prod_name regexp '^[0-9\\\\.]'; -- 仅仅从开头开始查找匹配 创建计算字符串拼接字符串使用 Concat()将值联结到一起构成单个值。 （使用sum，计算值的和） 12-- sum 与 case结合的实例sum(case when operation='buy' then -price else price end) 多数DBMS使用 +或者 ||来实现拼接(sqlite中用 ||实现)，但是在MySQL中使用 Concat()函数来实现 12345678910select concat(vend_name, '(', vend_country, ')') from vendors ...;-- 删除右侧多余空格来整理数据（RTrim() 函数， LTrim()去掉左侧空格）select concat(RTrim(vend_name), '(', RTrim(vend_country), ')')...;-- 为拼接的字段取名select concat(vend_name, '(', vend_country, ')') from vendors as vend_title...;-- 执行算数运算的结果作为一个项select prod_id, quantity*item_price as expanded_price from ...; 使用数据处理函数 函数没有SQL的可移植性强， 如果你决定使用函数，应该保证做好代码注释，以便以后你（或其他人）能确切地知道所编写SQL代码的含义。 .png) Soundex():会匹配与搜索字符串读音相似的字符串 1select vend_name, Upper(vend_name) as vend_name_upcase ...; 日期和时间处理函数 使用 WHERE进行筛选，对应的日期格式为：yyyy-mm-dd 123456789-- Date()函数得到的仅仅是日期，Time() 函数得到的是时间-- 下面这段语句不适用Date函数，将会匹配失败，因为where是整个列值进行比较的select cust_id, order_num from orders where Date(order_date) = '2005-09-01';-- 时间段进行筛选~ where Date(order_data) between '2005-09-01' and '2005-9-30';-- 获取时间中的月份或者年份信息year(order_date), month(order_date); 数值处理函数 汇总数据获取表中的汇总信息。 123-- 返回特定供应商提供的产品的平均价格-- 不允许使用count(distinct)select avg(distinct prod_price) from products where vend_id = 1003; 分组数据分组数据以便能汇总内容的子集, 将数据按照指定的分组进行统计。 1select vend_id, count(*) as num_prods from products group by vend_id; 过滤分组使用 having,这个子句支持所有 where操作符。(对分组数据进行筛选) 12345-- 这里直接使用where无法实现相同的目的~ group by cust_id having count(*) &gt;= 2;-- 过去12个月具有两个或以上的订单，且价格为10以上select vend_id, count(*) as num_prods from products where prod_price &gt;= 10 group by vend_id having count(*) &gt;= 2; group by &amp; order by 不要忘记ORDER BY 一般在使用GROUP BY子句时，应该也给出ORDER BY子句。这是保证数据正确排序的唯一方法。千万不要仅依赖GROUP BY排序数据。 子查询语句在select语句中嵌套select语句, in 或者 not in 12345select cust_idfrom orderswhere order_num in(select order_num from orderitems where prod_id = 'TNT2'); 联结表在联结两个表时，实际上就是将第一个表中的每一行与第二个表中的每一行进行匹配。Note: left join可以用于数据的剔除（Not in的效果） Ref: Database System Concepts 7ed(Abraham Silberschatz, Henry F. Korth etc.) &gt; some: greater than at least one&gt; all: greater than all. &lt;&gt; all: not in 12345select namefrom instructorwhere salary &gt; some (select salaryfrom instructorwhere dept name = 'Biology'); cross join 先将两个表进行笛卡尔积，然后利用后面的on对联结表进行筛选12345select a.Idfrom weather as a cross join weather as bon datediff(a.recordDate, b.recordDate) = 1 -- 这里就是筛选的条件了where a.temperature &gt; b.temperature; 内部联结 1.... from ...(列名) inner join ... on ....(condition); 高级联结自联结：利用别名对同一个表中的条件进行筛选 123select p1.id, p1.name from product as p1, product as p2 -- 对同一个表给予两个不同的别名where p1.id = p2.id and p2.id = 'DTNTR'; -- 这样就得到了id为'DTNTR'的名称了 使用场景： 删除表中重复的元素.仅保留id较小的元素 12delete p1 from person as p1, person as p2where p1.email=p2.email and p1.Id &gt; p2.id; 外部联结：联结包含了那些在相关表中没有关联行的行。使用关键字 LEFT OUTER JOIN（左外部联结） 创建组合查询使用关键字 Union将两个子句的结果进行组合。 UNION中的每个查询必须包含相同的列、表达式或聚集函数自动去除重复的行（使用 Union all保留所有的行）末尾的 order by不会是对单一语句的排序，而是对返回的所有的结果进行排序的。 union 和 union all都可以起到关联结果集的作用,union 会自动去除关联的两个结果集中的重复数据union all 不会主动去除两个结果集中的重复数据,会展示所有的数据 使用全文本搜索在建表的时候， 添加 FULLEXT(...).在检索的时候，会根据这个指示进行检索 CREATE TABLE语句接受FULLTEXT子句，它给出被索引列的一个逗号分隔的列表。在索引之后，使用两个函数Match()和Against()执行全文本搜索，其中Match()指定被搜索的列，Against()指定要使用的搜索表达式。(Match中的值与FULLEXT中定义的相同)。 这种方法，当匹配词出现在更前面的时候，输出的优先级要高一些。 1select ... where Match(note_text) Against('rabbit'); 查询拓展将包含目标词的语句中的词的语句也同样输出来。(with query expansion) 1... where match(note_text) Against('anvils' with query expansion); 布尔文本搜索MySQL支持全文本搜索的另外一种形式，称为布尔方式（boolean mode）。 全文本搜索布尔操作符-和，-排除一个词，而是截断操作符（可想象为用于词尾的一个通配符） 12... where match(..) against('...' in boolean mode);... where match(..) against('... -rope*' in boolean mode); -- 匹配包含...但不包含任意以rope开始的词的行 插入完整的行需要指定表名，以及表下所有的对应的列的信息。 12345-- insert 插入一行到一个表中insert into Customers values(list_infomation); --虽然这种语法很简单，但并不安全，应该尽量避免使用insert into Custormers(cust_name, cust_address,....) values(list_infomation);insert into Custormers(cust_name, cust_address,....) values(list_infomation1)， (list_infomation2); -- 插入两行到一个表中insert into Custormers(cust_name, cust_address,....) select cust_name, cust_address,.... from custnew; -- 利用select语句进行填充 更新与删除数据更新使用关键词 update MySQL没有撤销（undo）按钮。应该非常小心地使用UPDATE和DELETE. 123update customers set cust_name = '..', cust_email = ',,' where cust_id = 1002; -- 可以一次性更新多个信息-- 为了删除某个列的值，可设置它为NULL（假如表定义允许NULL值）。-- 替换的新的值可以使用if语句 删除数据使用关键词 delete 1delete from customers where cust_id = 1006; -- DELETE不需要列名或通配符。DELETE删除整行而不是删除列。为了删除指定的列，请使用UPDATE语句 创建和操纵表123456789101112131415161718192021create table tableName( -- AUTO_INCREMENT：本列每当增加一行时自动增量， 每个表只允许一个AUTO_INCREMENT列，而且它必须被索引 -- 与大多数DBMS不一样，MySQL不允许使用函数作为默认值，它只支持常量 cust_id int NOT NULL AUTO_INCREMENT default 1,-- 列名 类型 是否允许NULL 未给出值的时候，默认为1 -- 主键中只能使用不允许NULL值的列 primary key (cust_id))ENGINE=InnoDB;-- 引擎类型，如果省略ENGINE=语句，则使用默认引擎（很可能是MyISAM）。 外键不能跨引擎-- 修改, 给表添加一个列alter table table_name add vendor char(20); alter table table_name drop column vendor; -- 删除alter table table_name add constraint .... -- etc-- 删除表（删除整个表而不是其内容）drop table table_name;--重命名表rename table t to t1; 使用视图视图本身不包含数据，因此它们返回的数据是从其他表中检索出来的(实际上就是将一个sql语句进行封装) 视图用 CREATE VIEW语句来创建。 使用 SHOW CREATE VIEW viewname；来查看创建视图的语句。 用DROP删除视图，其语法为 DROP VIEW viewname;。 更新视图时，可以先用DROP再用CREATE，也可以直接用 CREATE OR REPLACE VIEW。如果要更新的视图不存在，则第2条更新语句会创建一个视图；如果要更新的视图存在，则第2条更新语句会替换原有视图 并非所有视图都是可更新的。基本上可以说，如果MySQL不能正确地确定被更新的基数据，则不允许更新（包括插入和删除） 1create view view_name as select .....;","link":"/2022/10/21/Database/"},{"title":"Java学习笔记","text":"Java学习学习[廖雪峰博客](https://www.liaoxuefeng.com/wiki/1252599548343744)笔记 基本运算符逻辑运算符||：短路或；&amp;&amp;：短路与（一些非法的语句会被忽略）；！：逻辑非 其中逻辑运算符只能操作布尔型数据。（注意一点，在Java中不能用1、0来代替True、False，因为前者是整型后者是布尔型）逻辑运算与短路运算的结果是一致的123456789boolean x = true; boolean y = false; short z = 42; //if(y == true) if (( z++==42 ) &amp;&amp; ( y = true )) z++;//注意z++是先进行判断之后才自增的！！，所以本语句是可以被执行的 if (( x = false) || (++z == 45 )) z++; System.out.println(\"z=\" + z); //Output:46 位运算符左移相当于*2，但是有限度（最左边的数为1的时候，结果会变成负数）右移前右边的位根据数字的符号决定（1的话就用1来填，否则就用0来填）&gt;&gt;&gt;：无符号位移操作 最高效的方式计算2 * 8：2&lt;&lt;3 or 8 &lt;&lt; 1 位运算符:&amp;(and)、 |(or)、 ^(xor)、 ~(not) 交换两变量的值方式一：定义一个临时变量方式二：先将两数合并，然后再分离 （:可能超出存储范围；有局限性）123num1 = num1 + num2;num2 = num1 - num2;num1 = num1 - num2;方式三：（运用位运算符关系：m = k ^ n = (m ^ n) ^ n）123num1 = num1 ^ num2;num2 = num1 ^ num2;num1 = num1 ^ num2; 三目运算符表达式1和表达式2要求是一致的，二者能够统一成一个类型（因为它的结果是会被赋值给单个变量的） 流程控制输入需要包含三点：12345678910111213//1.导入对应的类（utility）import java.util.Scanner;//注意最后的分号public class IO{ public static void main(String[] args){ //2.创建scanner变量 Scanner scanner = new Scanner(System.in);//创建scanner传入：System.in、System.out分别代表标准输入和输出。 System.out.println(\"Input Your name: \"); //3.访问输入变量中的成员 String name = scanner.nextLine();//传入的是字符串类型，注意这种类型转换是自动的 System.out.println(\"Input Your age: \"); int age = scanner.nextInt();//传入的是整型（注意next之后的语句） System.out.printf(\"Hi, %s,you are %d\\n\",name,age); 条件判断语句判等语句”==“： 这种判断运算符可以用来判断了两个值类型的变量是否相等，但是对于引用型变量就变成判断两个变量是否指向同一个对象。要判断引用类型的变量内容是否相等需要使用equals（）方法（注意这是变量类型String下面的一种方法） 12345678910 public class IO { public static void main(String[] args){ String s1 = null; //注意当s1为null时，直接调用equals方法会导致NullPointException错误， //为了避免这种情况，就利用短路运算，规避这种错误 if (s1 != null &amp;&amp; s1.equals(\"hello\")){ System.out.println((\"hello\")); } }} switch语句1234567891011121314151617181920//注意switch语句具有穿透性，所以每一项都需要以break结尾，且不能有大括号，判断语句也可以是字符串，是比较其中的内容是否相等switch（option）{case 3: ... break;case 2: .... break; case 3: ... break;default: .... break; //java12 case \"***\" -&gt; ....;//当具有多条语句的时候，需要用大括号括起来，其不需要break //还可以直接返回参数 int opt = switch(fruit){......} yield code;//这个是switch语句的返回值，作为默认返回的方式 for 语句 esp.（for each 循环） eg： 123int[] ns = {...};//数组初始化for(int n : ns){....}//数组遍历//但是这种方式没有办法拿到数组的索引 数组操作数组的遍历java标准库提供了Arrays.toString()，可以用来快速打印数组内容 数组的排序调用Java的内置排序功能 import java.util.Arrays;Arrays.sort(Arrays_name);//排序算法的调用 注意一点，数组的第一个元素就是指向该数组的指针 访问多维数组初始化的方式与C语言的一致，利用Java标准库输出： Arrays.deepToString 注意一点，在多维数组中，.length表示的多为数组中的数组的个数 命令行参数NULL 面对对象编程面对对象基础 简单来说就是我们都是一类（class）人，但是每个我们都是不同的实例（instance），各有各的性格特点 123456789//创建一个类class Class_Name{ public member_name;//public表示外部可以访问;这些是类的字段（Field）}//创建实例Class_Name instanceName = new Class_Name();//访问实例的字段instanceName.field; 类方法：private 方法为了避免外部代码直接去访问field，可以用private修饰field，这样可以拒绝外部的访问。但是外部代码想要访问，就需要借助方法（method） 12345678910111213141516171819202122232425262728293031323334353637 class Person{ private String name;//实例（instance） private int age; private String nickName； //下面是private的方法 //访问内部字段 public String getName{ return this.name; } public void getAge(){ return this.age; } //同时可以检查输入的值是否合法 public void setName(String name){//这里是方法参数 //发现违法输入，抛出异常 if(name == null || name.isBlank()){ throw IllegalArgumentException(\"Invalid name\"); } this.name = name; //如果没有冲突，则可以忽略this，如：return name； } //下面是可变参数的一个示例。（类型...） public void setNickName(String... names){//参数也可以写成：String[] names this.nickName = names; } //调用方式:varianName.setNickName(\" *** \" ,\" **** \"); /*注意：前几个方法的参数是以复制后形式传入的，而这个方法的参数若是数组 的话，就是以引用的方式传入的，所以在外部代码中，之前传入的数组的会导 致内部数组的变化（类似于传值、传址） **引用类型参数的传递，调用放的变量，和接受方的变量，指向的是同一个对象。双方任意一方修改这个对象都会影响对方** 之前的复制参数的传递方式成为参数绑定机制 */}//第一private相当于对变量进行了封装，而public这作为外部的接口。//这里注意一下this指针的运用，用于在类内部指代内部本身。（屋子内的物品分布的地图） 构造方法 之前些的这部分写得太烂了，这部分最后是重写的（我终于知道在代码中加太多注释的话，在复习的会哭的） 在类定义的时候定义一个构造方法，这可以在创建实例的时候顺便将字段都初始化了 12345678910111213141516//在类中，定义一个与类名相同的方法public ClassName (type instanceName1, type instanceName2);//参变量是需要初始化的变量//定义的同时初始化className varianName = new className(initialValue1,initialValue2);//Java的构造函数与C语言类似（几乎一致）//默认构造函数public ClassName//没有初始化的字段：引用类型-&gt;null; 数值类型-&gt;默认值，int-&gt;0;boolean -&gt;false;//可以在类定义当中定义多个构造方法，调用的时候会根据传入的参数的个数匹配至相应的构造方法new ClassName();//这个时候就会调用默认的构造方法//一种方法可以调用另一种方法，这里用到this指针//在类定义的内部：public Person(String name){ this(name,18);//这里调用了另外一个方法} &lt;hr style=” border:solid; width:100px; height:1px;” color=#000000 size=1”&gt;构造方法就是为了能够在定义变量的时候方便初始化。作用就像是C++中的结构体的构造函数，但是Java中的构造方法与C++中的有一些不同。 和普通方法相比，构造方法没有返回值（也没有void），调用构造方法，必须用new操作符。 下面是运用实例123456789101112131415161718192021222324class Person { private String name; private int age; //构造方法 public Person(String name, int age) { this.name = name; this.age = age; } //默认构造函数 public Person(){}; public String getName() { return this.name; } public int getAge() { return this.age; }}//调用：直接初始化了成员变量Person p = new Person(\"Xiao Ming\", 15); 方法重载（Overload）（同名但拥有不同的参数类型的方法）允许出现同名但拥有不同的参数类型的方法，但是这些方法的返回值应该具有相同的返回值。这样使得调用变得更加方便。注意重载的方法应该完成相似的功能。12345678//继续之前的案例public setName(String name){ this.name = name;}//方法重载public steName(String name, String familyName){ this.name = name + \" \" + familyName;} 继承继承就是在原有的类的字段和方法上进行拓展，形成一个新的类，Java中运用关键字extends来实现继承。12345//定义一个类class Person{...}//超类（super class）、父类（parent class）、基类（base class）//对原先的类进行继承class Student extends person{...}//子类（subclass）、拓展类（extended class）//注意子类中不能定义父类中重名的字段！ 继承树这类的继承结构就像是树的结构，所有定义的类都有对应的父类，上例中，Person的父类就是Object（这个类就相当于树中的头节点，没有父类），同样与树类似，每一个类只有一个父节点（除了Object），及只能继承自一个类。 protected（仅能被继承树中的成员所访问的变量）父类中private的字段是没有办法被子类访问的，但是protected的字段可以被所有的子类所访问（继承树内部）。 super(子类构造方法时使用)当在子类中引用父类的字段时，就可以用super指代（联想到this是指代自己，super是指代父类）一般情况下，super.name、this.name、name(name 为父类中的一个字段)都是一样的，编译器会自动定位字段的位置。但是在子类中需要生成构造函数的时候，情况就发生变化了。123456789101112131415/*在Java中任何类的构造方法必须是调用父类的构造方法，在没有明确调用父类的构造方法时候，会默认一个super（），但是父类中并没有无参数的构造方法，这时候就会报错。*/Class Student extends Person{ protected int score; public Student(String name,int age,int score){ super()；//自动调用父类的构造方法,出错 //这个时候只需要调用父类中已经定义的构造方法即可 this.score = score; }}/*所以当父类没有默认的构造方法时，必须写明调用super（），以便定位到合适的构造方法中。（回忆之前所的，当自己定义一个构造方法时，原有的默认构造方法就被覆盖了）*/还有一点，子类是不会继承父类的任何构造方法。 阻止继承（sealed）只要一个class没有final修饰符，任何类都可以从该类中继承。但是为了防止继承被滥用，Java15中允许使用 sealed类型，通过permits明确可以继承的子类名称1public sealed class Shape permits Rect, Circle{...}//permits之后时允许继承的子类 sealed类在Java 15中目前是预览状态，要启用它，必须使用参数—enable-preview和—source 15 向上转型&amp;向下转型这种向上向下的关系是针对继承树的，总的来说，字符/方法少的不能向字符/方法多的转型，否则Java虚拟机就会报ClassCastException.12345//向下转型实例Person p1 = new Student()//Person类型p1指向Students实例Student s1 = (Student) p1;//向下转型,出现错误，因为原先的类中可能不存在子类中的方法//向上转型实例Person p = new Student();//向下转型为了避免在向下转型的过程中出现错误，可以用instanceof实现判断一个变量所指向的实例是否是指定类型，或者是这个类型的子类。（A is instance of ClassName?True or False?）12345678910Person p = new Student(); if(p instanceof Student){ Student s = (Student) p; } //在java14中可以在判断语句中直接转型为制定变量（预览功能，启用需要参数） //这样写更加整洁 if(p instanceof Student s){ System.out.println(s.getname); }}最后在使用继承的时候要注意逻辑的一致性，继承的双方应该是包含和被包含的关系，而不是有交集的关系。 多态覆写父类的方法可以被子类的完全相同的方法所覆写（修改相应方法的功能）1234567891011121314151617181920212223242526//父类的方法class Person{ public void run(){ System.out.println(\" \"); }}//子类对父类方法进行覆写class Student extends Person{ @override//帮助检查是否正确进行了覆写（非必须） public void run (){ System.out.println(\"***\"); }}//重载（overload）：对一个方法进行补充性修改，名称一致，但是参数、功能可以发生变化//覆写(override):对一个方法的功能进行修改，相应的功能名称都应该相同/*注意一点，Java调用方法的过程中，调用的是所指向的类的对应的方法，这意味着所调用的方法与所对应的父类无关这样在定义一个函数的时候，由于传入的参数类型不确定，这就导致所调用的方法也是不确定的。（Java中定义的类型和所指向的类型可以是不一致的）*/public void Run(Person p){ //这时候无法确定是Person的方法还是Student的方法 p.run();}//利用这个特点，可以通过传入不同类型的参数，以实现调用不同的功能的方法//的目的,这样就实现了功能的拓展，而又不需要修改基于父类的代码 所有的类都最终继承自Object，这就意味着在必要情况下可以覆写Object的方法。其有一下几个重要方法： toString():将instance输出为String equals():判断两个instance是否逻辑相等 hashCode():计算一个instance的哈希值 在子类中，想要调用父类的方法，可以用super来调用1234567891011121314151617Student extends Person{ @override public String hello(){ return super.hello()+\"!\"; } //当一个方法不想让子类进行覆写的时候，在方法前加上final关键字 public final String hello_1(){ return \"Hello, \"+name; }//子类进行覆写会导致编译错误}//不希望被继承的类final class ClassName{...}//不希望被修改的字段,常出现在构造方法中public final String name = \"***\";//提一下：在方法的参数当中出现三个英文句号，代表参数个数不确定，依照输入参数的个数来确定public static double totalTax(Income... incomes){...} 抽象类&amp;接口12345678//当父类方法只是定义方法签名，本身没有实际的意义，这时候应该将父类方法声明为抽象方法class Person{ public abstract void run();}//这样的类运行时会报错，需要将类本身也声明为抽象类型,此类方法无法被实例化（无法用于定义变量）abstract class Person{ public abstract void run();} 面向抽象编程上层类只是定义规范，对于方法的实现并不关心，这相当于对方法的实现过程进行了封装。实现方法就是用抽象类型去引用具体子类的实例。1Person s = new Student(); 接口当一个抽象类中没有字段，所有的方法都是抽象类，这个时候应该将将这个类定义为接口：Interface在接口中所有的方法都是默认是public abstract，所以这两个修饰符在定义方法的时候都不写出来，当一个类去实现接口的时候需要使用implements关键字。123456interface Person{...}//定义一个接口，接口中不能有字段class Student implements Person{...}//实现一个接口//在Java中一个类只能继承自唯一的一个类，但是可以实现多个方法class Person implements Run,Walk{...}//实现两个接口//一个接口还可以继承自另一个接口，这就相当于拓展了接口的方法interface Teacher extends Person{....} 当实现一个接口的时候，需要覆写接口中所有的方法，但是可以不用覆写default方法，这实际上就是一种默认的方法功能，可以“不初始化”。 123interface Person{ default void run(){...}//无法访问字段} 静态字段和静态方法静态字段用static修饰，独立于实例，在任何一个实例当中修改都会修改静态字段的值，这就是说所有实例中的同一个静态字段都是同一个字段（在同一个存储空间当中）。所以在访问静态字段的时候，最好是使用类名来访问：类名.静态字段 静态方法调用静态方法不需要实例变量，直接通过类名即可。 静态方法属于类而不属于实例，所以在静态方法内部是无法访问this变量，也无法访问实例字段，只能访问静态字段 接口的静态字段接口的静态字段必须是final类型的，又因为接口的字段只能是public static final类型的，所以这样的修饰符是可以省略的。 包为了避免因为类名相同的而导致的冲突，在Java中定义了一种名字空间，成为包（package），一个类的完成类名是：包名.类名，没有写包名的类会使用默认包，这样容易造成名字冲突，所以建议将包名写出来。（注意，包没有父子关系，这也就是说com.apache和com.apache.abc是不同的包） 包的作用域位于同一个包的类可以访问包的作用域的字段和方法（允许访问package的没有public、private修饰的class、以及没有public、protected、private修饰的字段和方法。注意这里的意思是能访问，不是只能访问，public修饰的方法在同一个包情况下当然可以被访问） 调用其他的class：importpackage_sample└─ bin ├─ hong │ └─ Person.class │ ming │ └─ Person.class └─ mr └─ jun └─ Arrays.class 假设一个包的结构如上图。12345678//调用方法①:直接完成写出类名mr.jun.Arrays arrays = new mr.jun.Arrays();//调用方法②：用import语句,导入对应的包import mr.jun.Arrays;//导入这个包下的Arrays类import mr.jun.*;//导入这个包下的所有的类（不推荐，可能引起混乱）//导入一个类的静态字段和静态方法import static java.lang.System.*;//导入system类中的所有静态方法out.println(\"...\");//可用√在编译器遇到一个类名称的时候，按照一下顺序查找这个类1234graph LRA[是否是完整的类名]--是--&gt;B(直接根据完整类名查找这个类)A--否--&gt;C(查找当前package是否存在这个类名)C--&gt;D(查找import的包)--&gt;E(查找java.lang包)如果没有找到最后就报错。在编写class 的时候，编译器会自动import两个包：导入当前包的其他class、默认：import java.lang.*.导入的包的名称不能相同，如有重名，另一个应该到写入完整的类名。为了避免冲突，要注意能和java.lang和JDK常用类的类名重名12345678910111213//这个语句应该就是在声明包的位置package com.itranswarp.sample;//导入包，写明包的具体位置import com.itranswarp.world.Person;public class Main { public static void main(String[] args) { Person p1 = new Person(\"小明\"); System.out.println(p1.hello()); }} 作用域 名称 作用范围 补充 public 只要有class的访问权限，定义位public的方法和字段就可以被访问 相当于一个对外的接口 private 无法被其他类访问，但是可以通过嵌套类（nested class）访问 用方法内的public方法访问private方法，使外部可以访问方法内部的private方法 protected 字段和方法能被子类及其子类访问 限制访问范围只能在继承树中才访问 package 同一个包内能访问对应的方法字段 有点像名字空间 局部变量 在方法内部定义的变量成为局部变量 在范围之外就会失效，像形参之类的 final class：防止被继承字段：防止被重新赋值局部变量：防止重新赋值方法：防止被覆写 就相当于静态变量 注意事项： 1.尽可能少地对外暴露字段和方法，也就是说要尽可能减少public地使用2.将方法定义位package有利于测试，测试类和被测试类只要在同一个包中，测试代码就可以访问被测试类的权限方法3.一个.java类只能有一个public类，且文件名和public类必须相同。 内部类在其他类中定义的类称为内部类。①：Inner Class（内部类）：依托于外部类，能够访问外部类的private字段和方法。创建方法：Outer.Inner inner = outer.new Inner();编译后：Outer编译位Outer.class,内部类编译为Outer$Inner.class ②：Anonymous Class（匿名类）在其他类的内部实例化创建方法：12345Runnable r = new Runnable(){//这里是定义了一个接口 //方法}//继承自普通类HashMap&lt;String, String&gt;map2 = new HashMap&lt;&gt;(){};编译后：main$1.class(main是public修饰的)③：Static Nested Class（静态内部类）用static修饰，无法应用Outer.this，可以访问private修饰的变量 模块模块申明了依赖关系，只有声明依赖关系之后才能将需要的类导入(While need it, learn it) Java核心类补充内容在命令行中运行Java程序可以在执行语句后面加上参数列表，在程序中将会被保存至args参数列表中，用下标索引的方式可以直接访问传入的参数。","link":"/2021/01/09/Java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"GeePRC notes","text":"项目大纲 codec.go 报文Header 消息体编码解码的接口 Codec 读取报头 读取主体 写入报头的方法 Codec的构造函数 可选用的编码方式 存储在一个map中 不同的编码方式调用不同的codec构造函数 gob.go gob结构体 GobCodec实现接口codec server.go Option 标识 Magic number 编码方式 默认的Option main.go 创建一个监听者 通过一个协程在执行 协程中的得到的地址通过管道通知主线程 确定编码方式 发送接收 创建报头 写入 cc.Write() 接收回应 cc.ReadHeader() bugday5, go run main.go:rpc server: register Foo.Sumrpc server debug path: /debug/geerpccall Foo.Sum error:rpc server: request handle timeout: expect within 10nsexit status 1 Chanllenge网络粘包执行 go test -v 会有一定概率出现测试卡死无响应的bugissue Great designs使用通道实现超时判断在goroutine中，完成一步之后往管道内传入struct {}{}这样，在goroutine外部就可以接收到这些信息，这样外部就知道goroutine内部某个函数完成了，123456789101112callChannel := make(chan struct{})go func(){ err := call(args) callChannel &lt;- struct{}{}}()select { case &lt;-time.After(timeout): // 处理超时 timeout handling case &lt;-callChannel: function finished} Knowledges如何结束一个goroutine利用管道传入一个结束信息（这里是true），然后返回函数即可12345678910111213141516quit := make(chan bool)go func() { for { select { case &lt;- quit: return default: // Do other stuff } }}()// Do stuff// Quit goroutinequit &lt;- true encoding/gob Package gob 管理 gobs 流 - 在编码器（发送器）和解码器（接收器）之间交换的二进制值 enc := gob.NewEncoder(&amp;network) // 将写入网络。 dec := gob.NewDecoder(&amp;network) // 将从网络上读取。 // Encoding（发送）一些值。 err := enc.Encode(P{3, 4, 5, \"Pythagoras\"}) // 接收 var q Q err = dec.Decode(&amp;q) 反射Context package context 主要用来在 goroutine 之间传递上下文信息，包括：取消信号、超时时间、截止时间、k-v 等。 一句话：context 用来解决 goroutine 之间 退出通知、元数据传递的功能。","link":"/2023/01/05/GeePRC-notes/"},{"title":"MIT6.S081","text":"ReadingChapter 1: Operating system interfaces the shell is a user program, and not part of the kernel Although the child has the same memory contents as the parent initially, the parent and child are executing with different memory and different registers: changing a variable in one does not affect the other. exec replaces the calling process’s memory but preserves its file table exec replaces the memory and registers of the current process with a new program I/O and File descriptors The shell ensures that it always has three file descriptors open std input, std output, std error 先close(0); 然后open, 让文件描述符与读相连接 read(fd, buf, n) write(fd, buf, n) dup system call duplicates an existing file descriptor, returning a new one that refers to the same underlying I/O object. File descriptors are a powerful abstraction, because they hide the details of what they are connected to 1.3 Pipes A pipe is a small kernel buffer exposed to processes as a pair of file descriptors, one for reading and one for writing. 命令行pipe实例： grep fork sh.c | wc -l 程序会分别为两个程序创建一个子进程，并递归地运行命令（可能会出现多管道的现象， a | b | c） 与重定向的优势 会自动清理（重定向需要小心清理临时文件） 能传入任意长的数据流（重定向需要足够的disk空间存储所有的数据） 能够并行执行（重定向只能串行） 1.4 File system chdir: change current directory mkdir creates a new directory, open with the O_CREATE flag creates a new data file, and mknod creates a new device file The link system call creates another file system name referring to the same inode as an existing file. The fstat system call retrieves information from the inode that a file descriptor refers to. It fills in a struct stat, defined in stat.h Each inode is identified by a unique inode number. The file’s inode and the disk space holding its content are only freed when the file’s link count is zero and no file descriptors refer to it(using unlink) sum-up： 文件目录变换，文件的结构和信息，文件的创建和关闭，Unix中运行文件相关命令的方法 Chapter 2: Operating system organization Thus an operating system must fulfill three requirements: multiplexing, isolation, and interaction. 2.1 Abstracting physical resources 通过函数结构访问disk的优势（让OS管理内存） 2.2 User mode, supervisor mode, and system calls Machine mode have full privilege; a CPU starts in machine mode. Machine mode is mostly intended for configuring a computer. Supervisor mode(Kernel space) the CPU is allowed to execute privileged instructions If running privileged instructions in user mode, CPU wouldn’t execute it, but switch to the supervisor mode to terminate it the kernel control the entry point for transitions to supervisor mode User mode(User space) 实现程序之间隔离的方法 2.3 Kernel organization monolithic kernel The entire operating system resides in the kernel, so that the implementations of all system calls run in supervisor mode Pros: Easy to cooperate, doesn’t have to decide which part of the operating system doesn’t need full hardware privileg Cons: 1. the interfaces between different parts of the operating system are often complex 2. a mistake is fatal, because an error in supervisor mode will often cause the kernel to fail microkernel minimize the amount of operating system code that runs in supervisor mode the kernel provides an inter-process communication mechanism to send messages from one user-mode process to another OS services running as processes are called servers. it sends a message to the file server and waits for a response. sum-up： 两种不同的内核设计方式 2.5 Process overview The unit of isolation is a process. The mechanisms used by the kernel to implement processes include the user/supervisor mode flag, address spaces, and time-slicing of threads Xv6 maintains a separate page table for each process that defines that process’s address space the trampoline page contains the code to transition in and out of the kernel mapping the trapframe is necessary to save/restore the state of the user process The xv6 kernel maintains many pieces of state for each process, which it gathers into a struct proc most important pieces of kernel state are its page table, its kernel stack, and its run state. Context switch between user space and kernel space To switch transparently between processes, the kernel suspends the currently running thread and resumes another process’s thread. Each process has two stacks: a user stack and a kernel stack (p-&gt;kstack) the kernel can execute even if a process has wrecked its user stack. ecall: change to kernel space; sret: to user space Sum-up an address space to give a process the illusion of its own memory, and, a thread, to give the process the illusion of its own CPU 如何利用进程实现隔离性的以及进程的工作方式 2.7 Security Model Safeguards Assertions, type checking, stack guard pages, etc. Chapter 3: Page tables provides each process with its own private address space and memory Xv6 performs a few tricks: mapping the same memory (a trampoline page) in several address spaces, and guarding kernel and user stacks with an unmapped page. 3.1 Paging hardware The structure of page table Address translation A page table is stored in physical memory as a three-level tree. (first nine bits is used for indexing PPN of each page directory. and etc.) If page is not found, raise page-fault exception In the common case in which large ranges of virtual addresses have no mappings, the three-level structure can omit entire page directories.(Allocate pages when they are needed) flag bits that tell the paging hardware how the associated virtual address is allowed to be used 每个PTE都包含标志位，说明虚拟地址的使用权限。 PTE_V表示 PTE 是否存在于页表中：如果未设置，那么一个对该页的引用会引发错误(也就是：不允许被使用（ validity ）)。 PTE_W控制着能否对页执行写操作； PTE_R 控制是否允许使用指令读取页。 PTE_X控制CPU是否可以将页面内容解释为指令并执行它们。 PTE_U控制着用户程序能否使用该页；如果不能，则只有内核能够使用该页。 satp: the physical address of the root pagetable page each CPU has its own satp(different CPUs can run different processes) Translation Look-aside Buffer (TLB) Motivation: To avoid the cost of loading PTEs from physical memory a potential downside of three levels is that the CPU must load three PTEs from memory to perform the translation of the virtual address in the load/store instruction to a physical address. when xv6 changes a page table, it must tell the CPU to invalidate corresponding cached TLB entries. 3.2 Kernel address space Xv6 maintains one page table per process, describing each process’s user address space, plus a single page table that describes the kernel’s address space The kernel gets at RAM and memory-mapped device registers using “direct mapping; Direct mapping simplifies kernel code that reads or writes physical memory. The guard page’s PTE is invalid (i.e.,PTE_V is not set), so that if the kernel overflows a kernel stack, it will likely cause an exception 3.4 Physical memory allocation The kernel must allocate and free physical memory at run-time for page tables, user memory, kernel stacks, and pipe buffers. Allocation consists of removing a page from the linked list; freeing consists of adding the freed page to the list. 3.6 Process address space A process’s user memory starts at virtual address zero and can grow up to MAXVA(The max bits the address can take) Xv6 maps the data, stack, and heap with the permissions PTE_R, PTE_W, and PTE_U. Avoid the program modifies the unexpected regions.(the hardware will refuse to execute the store and raises a page fault) Lecture Note Address space pagetable implemented in hardware by the processor or by unit called MMU CPU—VA—&gt;MMU—-PA—-&gt;Memory satp: In CPU, this register is used to specify where the map is(VA-&gt;PA). Each one process has unique address for the map(This is writen by the kernel for isolation) MMU: 读取内存并转换，不保存映射 The max bits of the virtual address is determined by the number of the registers paging hardware(RISC-V) xv6 virtual memory code and layout of the kernel address spaces and user address spaces 多级页表中存储PPN是44位的，末尾加上12个0，得到56位物理地址，这就是下一级页表的物理地址 多次访问耗费时间，所以使用TLB（快表）[VA, PA] mapping MMU —-hardware Chapter 4 Traps and system calls CPU Interrupt Cases system call exception device interrupt While commonality among the three trap types suggests that a kernel could handle all traps with a single code path, it turns out to be convenient to have separate code for three distinct cases: traps from user space, traps from kernel space, and timer interrupts. The usual sequence a trap forces a transfer of control into the kernel the kernel saves registers and other state the kernel restores the saved state and returns from the trap original code resumes where it left off For what isolation demands that only the kernel be allowed to use devices the kernel is a convenient mechanism with which to share devices among multiple processes 4.1 RISC-V trap machinery Each RISC-V CPU has a set of control registers that the kernel writes to tell the CPU how to handle traps, and that the kernel can read to find out about a trap that has occurred. sum-up: CPU用专用的寄存器完成上下文转换。但为了trap的效率CPU并不会将所有任务都完成，剩余的工作需要由内核软件完成 4.2 Traps from user space Occur if the user program makes a system call (ecall instruction), or does something illegal, or if a device interrupts RISC-V hardware does not switch page tables when it forces a trap Things need to do trap handling code needs to switch to the kernel page table the kernel page table must also have a mapping for the handler pointed to by stvec Trampoline page Trampoline page stores code to switch between user and kernel space. The code is mapped at the same virtual address (TRAMPOLINE) in user and kernel space so that it continues to work when it switches page tables. TRAPFRAME address of TRAPFRAME is stored in sscratch register. Saves all the user registers there, including the user’s a0, read back from sscratch. TRAPFRAME also contain the kernel information and the address of usertrap function. usertrap: The job of usertrap is to determine the cause of the trap, process it, and return Pointer as argument on system call Problems Invalid pointer kernel page table mappings are not the same as the user page table mappings so the kernel cannot use ordinary instructions to load or store from user-supplied addresses. Find PA by using user space page table and map it to the VA in the kernel space. sum-up: 在用户空间中调用trap。 4.5 Traps from kernel space 4.6 Page-fault exceptions Actions In user space: kill the faulting process In kernel space: kernel panics 内核错误 (Kernel panic )是指操作系统在监测到内部的致命错误，并无法安全处理此错误时采取的动作。 three kinds of page fault load page faults (when a load instruction cannot translate its virtual address) store page faults (when a store instruction cannot translate its virtual address) instruction page faults (when the address in the program counter doesn’t translate) The applications of page-fault exception copy-on-write fork Procedure the parent and child to initially share all physical pages, but for each to map them read-only Write to that memory will raise a page-fault exception The kernel’s trap handler responds by allocating a new page of physical memory andcopying into it the physical page that the faulted address maps to. Lazy allocation Procedure application asks for more memory by calling sbrk The kernel notes the increase in size, but does not allocate memory or create PTEs When page-fault occurs in those address, the kernel allocates a page of physical memory and maps it into the page table Since applications often ask for more memory than they need Problem The extra overhead introduced by kernel/user transition reduce this cost by allocating a batch of consecutive pages per page fault instead of one page specializing the kernel entry/exit code for such page-faults. demand paging(需求分页) Problem Since applications can be large and reading from disk is expensive, this startup cost may be noticeable to users Solution a modern kernel creates the page table for the user address space, but marks the PTEs for the pages invalid On a page fault, the kernel reads the content of the page from disk and maps it into the user address space paging to disk Problem The programs running on a computer may need more memory than the computer has RAM Solution to store only a fraction of user pages in RAM, and to store the rest on disk in a paging area. The memory stored in the paging area is set as invalid. Access paging area will incur a page fault. The kernel trap handler will allocate a page of physical RAM, read the page from disk into the RAM, and modify the relevant PTE to point to the RAM Chapter5 Interrupts and device drivers A driver is the code in an operating system that manages a particular device: it configures the device hardware tells the device to perform operations handles the resulting interrupts interacts withprocesses that may be waiting for I/O from the device. device drivers execute code in two contexts top half that runs in a process’s kernel thread ask the hardware to start an operation wait for the operation complete raise an interrupt when the code is completed a bottom half that executes at interrupt time. what operation has completed, wakes up a waiting process if appropriate tells the hardware to start work on any waiting next operation A general pattern to note is the decoupling of device activity from process activity via bufferingand interrupts. (This idea is sometimes called I/O concurrency.) This decoupling can increase performance by allowing processes to execute concurrently with device I/O 驱动程序完全禁用中断，并定期检查设备是否需要注意。这种技术被称为轮询（polling） 如果设备执行操作非常快，轮询是有意义的，但是如果设备大部分空闲，轮询会浪费CPU时间。一些驱动程序根据当前设备负载在轮询和中断之间动态切换。 程序I/O很简单，但速度太慢，无法在高数据速率下使用。需要高速移动大量数据的设备通常使用直接内存访问（DMA） DMA设备硬件直接将传入数据写入内存，并从内存中读取传出数据。 一些操作系统能够直接在用户空间缓冲区和设备硬件之间移动数据，通常带有DMA。 lock 锁的缺点是它们会扼杀性能，因为它们会串行化并发操作 竞态条件是指多个进程读写某些共享数据（至少有一个访问是写入）的情况 在内存池中，两个进程并行地释放内存，那么可能会导致释放的内存被放到同一个地址中，从而变成了覆盖 acquire和 release之间的指令序列通常被称为临界区域（critical section）。（加锁的区域） 代码在执行的时候，依托一些 不变量(相当于一些条件)，但是其他进程对这个变量的操作暂时改变了这种不变量，所以导致代码运行错误。（上面就是链表头部指针有一个时间段中不是指向链表头部的，这时候其他进程的操作就可能导致竞态） 以将锁视为串行化（serializing）并发的临界区域，以便同时只有一个进程在运行这部分代码，从而维护不变量（假设临界区域设定了正确的隔离性） 冲突 如果多个进程同时想要相同的锁或者锁经历了争用，则称之为发生冲突（conflict） 要使用多少锁，以及每个锁应该保护哪些数据和不变量 任何时候可以被一个CPU写入，同时又可以被另一个CPU读写的变量，都应该使用锁来防止两个操作重叠 锁保护不变量（invariants）：如果一个不变量涉及多个内存位置，通常所有这些位置都需要由一个锁来保护，以确保不变量不被改变。 大内核锁（big kernel lock） 如果并行性不重要，那么可以安排只拥有一个线程，而不用担心锁。一个简单的内核可以在多处理器上做到这一点，方法是拥有一个锁，这个锁必须在进入内核时获得，并在退出内核时释放 死锁和锁排序 如果在内核中执行的代码路径必须同时持有数个锁，那么所有代码路径以相同的顺序获取这些锁是很重要的（否则有死锁的风险） 全局锁获取顺序的需求意味着锁实际上是每个函数规范的一部分：调用者必须以一种使锁按照约定顺序被获取的方式调用函数。 锁和中断处理函数 一个进程中持有一个变量，在执行过程中出现了中断，而中断处理函数可能又会需要访问这个变量，这时候处理函数就会等待这个变量被释放，这时候就产生了死锁 如果一个自旋锁被中断处理程序所使用，那么CPU必须保证在启用中断的情况下永远不能持有该锁。 Re-entrant locks It might appear that some deadlocks and lock-ordering challenges could be avoided by using re-entrant locks, which are also called recursive locks. if the lock is held by a process and if that process attempts to acquire the lock again, then the kernel could just allow this 指令和内存访问顺序 规则确实允许重新排序后改变并发代码的结果，并且很容易导致多处理器上的不正确行为。CPU的排序规则称为内存模型（memory model）。 __sync_synchronize()是一个内存障碍：它告诉编译器和CPU不要跨障碍重新排序 load或 store指令。 睡眠锁 因为等待会浪费CPU时间，所以自旋锁最适合短的临界区域；睡眠锁对于冗长的操作效果很好。 调度 任何操作系统都可能运行比CPU数量更多的进程，所以需要一个进程间分时共享CPU的方案 通过将进程多路复用到硬件CPU上，使每个进程产生一种错觉，即它有自己的虚拟CPU 多路复用 情景 进程等待设备或管道I/O完成，或等待子进程退出，或在 sleep系统调用中等待时，xv6使用睡眠（sleep）和唤醒（wakeup）机制切换 xv6周期性地强制切换以处理长时间计算而不睡眠的进程。 协程 在两个线程之间进行这种样式化切换的过程有时被称为协程（coroutines） 协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。 协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程 ，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。 每个线程中运行多个协程 协程只有和异步IO结合起来才能发挥出最大的威力。 假设协程运行在线程之上，并且协程调用了一个阻塞IO操作，这时候会发生什么？实际上操作系统并不知道协程的存在，它只知道线程，因此在协程调用阻塞IO操作的时候，操作系统会让线程进入阻塞状态，当前的协程和其它绑定在该线程之上的协程都会陷入阻塞而得不到调度，这往往是不能接受的。 sleep 和 wakeup Xv6使用了一种称为 sleep和 wakeup的方法，它允许一个进程在等待事件时休眠，而另一个进程在事件发生后将其唤醒。睡眠和唤醒通常被称为序列协调（sequence coordination）或条件同步机制（conditional synchronization mechanisms）。 Sleep(chan)在任意值 chan上睡眠，称为等待通道（wait channel）。 释放CPU用于其他任务 Wakeup(chan)唤醒所有在 chan上睡眠的进程（如果有），使其 sleep调用返回。 为了防止死锁，使用 条件锁，让进程在睡眠之后释放锁 条件锁就是所谓的条件变量，某一个线程因为某个条件为满足时可以使用条件变量使该程序处于阻塞状态。一旦条件满足以“信号量”的方式唤醒一个因为该条件而被阻塞的线程。 文件 文件系统的目的是组织和存储数据 解决的问题 文件系统需要磁盘上的数据结构来表示目录和文件名称树，记录保存每个文件内容的块的标识，以及记录磁盘的哪些区域是空闲的。 文件系统必须支持崩溃恢复（crash recovery）。 文件系统代码必须协调以保持不变量（不同的进程可能在相同的文件系统上运行） 文件系统必须保持常用块的内存缓存（访问磁盘慢） 文件描述符（File descriptor） 路径名（Pathname） 目录（Directory） 索引结点（Inode） 日志（Logging） 缓冲区高速缓存（Buffer cache） 磁盘（Disk) 日志 日志驻留在超级块中指定的未知。 事务中途奔溃将导致日志头块中的计数为0，提交后奔溃将导致非零计数 NotesLecture 3: OS design Lecture Topic: OS design system calls micro/monolithic kernel First system call in xv6 OS picture apps: sh, echo, … system call interface (open, close,…)OS Goal of OS run multiple applications isolate them multiplex them share Strawman design: No OS Application directly interacts with hardware CPU cores &amp; registers DRAM chips Disk blocks … OS library perhaps abstracts some of it Strawman design not conducive to multiplexing each app periodically must give up hardware BUT, weak isolation app forgets to give up, no other app runs apps has end-less loop, no other app runs you cannot even kill the badly app from another app but used by real-time OSes “cooperative scheduling” Strawman design not conducive to memory isolation all apps share physical memory one app can overwrites another apps memory one app can overwrite OS library Unix interface conducive to OS goals abstracts the hardware in way that achieves goals processes (instead of cores): fork OS transparently allocates cores to processes Saves and restore registers Enforces that processes give them up Periodically re-allocates cores memory (instead of physical memory): exec Each process has its “own” memory OS can decide where to place app in memory OS can enforce isolation between memory of different apps OS allows storing image in file system files (instead of disk blocks) OS can provide convenient names OS can allow sharing of files between processes/users pipes (instead of shared physical mem) OS can stop sender/receiver OS must be defensive an application shouldn’t be able to crash OS an application shouldn’t be able to break out of its isolation =&gt; need strong isolation between apps and OS approach: hardware support user/kernel mode virtual memory Processors provide user/kernel mode kernel mode: can execute “privileged” instructions e.g., setting kernel/user bit e.g., reprogramming timer chip user mode: cannot execute privileged instructions Run OS in kernel mode, applications in user mode [RISC-V has also an M mode, which we mostly ignore] Processors provide virtual memory Hardware provides page tables that translate virtual address to physical Define what physical memory an application can access OS sets up page tables so that each application can access only its memory Apps must be able to communicate with kernel Write to storage device, which is shared =&gt; must be protected =&gt; in kernel Exit app … Solution: add instruction to change mode in controlled way ecall &lt;n&gt; enters kernel mode at a pre-agreed entry point Modify OS picture user / kernel (redline) app -&gt; printf() -&gt; write() -&gt; SYSTEM CALL -&gt; sys_write() -&gt; …user-level libraries are app’s private business kernel internal functions are not callable by user other way of drawing picture: syscall 1 -&gt; system call stub -&gt; kernel entry -&gt; syscall -&gt; fs syscall 2 -&gt; proc system call stub executes special instruction to enter kernelhardware switches to kernel modebut only at an entry point specified by the kernel syscall need some way to get at arguments of syscall [syscalls the topic of this week’s lab] Kernel is the Trusted Computing Base (TCB) Kernel must be “correct” Bugs in kernel could allow user apps to circumvent kernel/userHappens often in practice, because kernels are complexSee CVEs Kernel must treat user apps as suspectUser app may trick kernel to do the wrong thingKernel must check arguments carefullySetup user/kernel correctlyEtc. Kernel in charge of separating applications tooOne app may try to read/write another app’s memory=&gt; Requires a security mindsetAny bug in kernel may be a security exploit Aside: can one have process isolation WITHOUT h/w-supportedkernel/user mode and virtual memory? yes! use a strongly-typed programming language For example, see Singularity O/Sthe compiler is then the trust computing base (TCB)but h/w user/kernel mode is the most popular plan Monolothic kernelOS runs in kernel spaceXv6 does this. Linux etc. too.kernel interface == system call interfaceone big program with file system, drivers, &amp;c good: easy for subsystems to cooperateone cache shared by file system and virtual memory bad: interactions are complexleads to bugsno isolation within Microkernel design many OS services run as ordinary user programs file system in a file server kernel implements minimal mechanism to run services in user space processes with memory inter-process communication (IPC) kernel interface != system call interface good: more isolation bad: may be hard to get good performanceboth monolithic and microkernel designs widely used Xv6 case study Monolithic kernel Unix system calls == kernel interface Source code reflects OS organization (by convention) user/ apps in user mode kernel/ code in kernel mode Kernel has several parts kernel/defs.h proc fs.. Goal: read source code and understand it (without consulting book) The RISC-V computer A very simple board (e.g., no display) RISC-V processor with 4 cores RAM (128 MB) support for interrupts (PLIC, CLINT) support for UARTallows xv6 to talk to consoleallows xv6 to read from keyboard support for e1000 network card (through PCIe)Qemu emulates several RISC-V computers we use the “virt” onehttps://github.com/riscv/riscv-qemu/wiki close to the SiFive board (https://www.sifive.com/boards)but with virtio for disk Boot xv6 (under gdb) $ make CPUS=1 qemu-gdb runs xv6 under gdb (with 1 core) Qemu starts xv6 in kernel/entry.S (see kernel/kernel.ld) set breakpoint at _entry look at instruction info reg set breakpoint at main Walk through mainsingle step into userinitWalk through userinitshow kallocshow proc.hshow allocproc()show initcode.S/initcode.asmbreak forkret()walk to userretbreak syscallprint numsyscalls[num]exec “/init”points to be made:page table in userinitecall: U -&gt; Ka7: syscall #exec: defensive kernel \\text{proc.c} \\stackrel{\\text{gcc}}{\\rightarrow} \\text{proc.s} \\stackrel{\\text{assembler}}{\\rightarrow} \\text{proc.o} \\rightarrow\\text{link different .o file together} 6.S081 2020 Lecture 4: Virtual Memory======================================== plan:address spacespaging hardwarexv6 VM code Virtual memory overview today’s problem:[user/kernel diagram][memory view: diagram with user processes and kernel in memory]suppose the shell has a bug:sometimes it writes to a random memory addresshow can we keep it from wrecking the kernel?and from wrecking other processes? we want isolated address spaceseach process has its own memoryit can read and write its own memoryit cannot read or write anything elsechallenge:how to multiplex several memories over one physical memory?while maintaining isolation between memories xv6 uses RISC-V’s paging hardware to implement AS’sask questions! this material is importanttopic of next lab (and shows up in several other labs) paging provides a level of indirection for addressingCPU -&gt; MMU -&gt; RAMVA PA \\text{CPU}\\stackrel{\\text{VA}}{\\rightarrow}MMU\\stackrel{\\text{PA}}{\\rightarrow}\\text{RAM}s/w can only ld/st to virtual addresses, not physicalkernel tells MMU how to map each virtual address to a physical addressMMU essentially has a table, indexed by va, yielding pacalled a “page table”one page table per address spaceMMU can restrict what virtual addresses user code can useBy programming the MMU, the kernel has complete control over va-&gt;pa mappingAllows for many interesting OS features/tricks RISC-V maps 4-KB “pages”and aligned — start on 4 KB boundaries4 KB = 12 bitsthe RISC-V used in xv6 has 64-bit for addressesthus page table index is top 64-12 = 52 bits of VAexcept that the top 25 of the top 52 are unusedno RISC-V has that much memory nowcan grow in futureso, index is 27 bits. MMU translationsee Figure 3.1 of bookuse index bits of VA to find a page table entry (PTE)construct physical address using PPN from PTE + offset of VA what is in PTE?each PTE is 64 bits, but only 54 are usedtop 44 bits of PTE are top bits of physical address“physical page number”low 10 bits of PTE flagsPresent, Writeable, &amp;cnote: size virtual addresses != size physical addresses where is the page table stored?in RAM — MMU loads (and stores) PTEso/s can read/write PTEsread/write memory location corresponding to PTEs would it be reasonable for page table to just be an array of PTEs? how big is it?2^27 is roughly 134 million64 bits per entry134*8 MB for a full page tablewasting roughly 1GB per page tableone page table per address spaceone address space per applicationwould waste lots of memory for small programs!you only need mappings for a few hundred pagesso the rest of the million entries would be there but not needed RISC-V 64 uses a “three-level page table” to save spacesee figure 3.2 from bookpage directory page (PD)PD has 512 PTEsPTEs point to another PD or is a leafso 512512512 PTEs in totalPD entries can be invalidthose PTE pages need not existso a page table for a small address space can be small how does the mmu know where the page table is located in RAM?satp holds phys address of top PDpages can be anywhere in RAM — need not be contiguousrewrite satp when switching to another address space/application how does RISC-V paging hardware translate a va?need to find the right PTEsatp register points to PA of top/L2 PDtop 9 bits index L2 PD to get PA of L1 PDnext 9 bits index L1 PD to get PA of L0 PDnext 9 bits index L0 PD to get PA of PTEPPN from PTE + low-12 from VA flags in PTEV, R, W, X, Uxv6 uses all of them what if V bit not set? or store and W bit not set?“page fault”forces transfer to kerneltrap.c in xv6 sourcekernel can just produce error, kill processin xv6: “usertrap(): unexpected scause … pid=… sepc=… stval=…”or kernel can install a PTE, resume the processe.g. after loading the page of memory from disk indirection allows paging h/w to solve many problemse.g. phys memory doesn’t have to be contiguousavoids fragmentatione.g. lazy allocation (a lab)e.g. copy-on-write fork (another lab)many more techniquestopic of next lecture Q: why use virtual memory in kernel?it is clearly good to have page tables for user processesbut why have a page table for the kernel?could the kernel run with using only physical addresses?top-level answer: yesmost standard kernels do use virtual addresseswhy do standard kernels do so?some reasons are lame, some are better, none are fundamental the hardware makes it difficult to turn it offe.g. on entering a system call, one would have to disable VM the kernel itself can benefit from virtual addressesmark text pages X, but data not (helps tracking down bugs)unmap a page below kernel stack (helps tracking down bugs)map a page both in user and kernel (helps user/kernel transition) Virtual memory in xv6 kernel page tableSee figure 3.3 of booksimple maping mostlymap virtual to physical one-on-onenote double-mapping of trampolinenote permissionswhy map devices? each process has its own address spaceand its own page tablesee figure 3.4 of booknote: trampoline and trapframe aren’t writable by user processkernel switches page tables (i.e. sets satp) when switching processes Q: why this address space arrangement?user virtual addresses start at zeroof course user va 0 maps to different pa for each process16,777,216 GB for user heap to grow contiguouslybut needn’t have contiguous phys mem — no fragmentation problemboth kernel and user map trampoline and trapframe pageeases transition user -&gt; kernel and backkernel doesn’t map user applicationsnot easy for kernel to r/w user memoryneed translate user virtual address to kernel virtual addressgood for isolation (see spectre attacks)easy for kernel to r/w physical memorypa x mapped at va x Q: does the kernel have to map all of phys mem into its virtual address space? Code walk through setup of kernel address spacekvmmap()Q: what is address 0x10000000 (256M)Q: how much address space does 1 L2 entry cover? (1G)Q: how much address space does 1 L1 entry cover? (2MB)Q: how much address space does 1 L0 entry cover? (4096)print kernel page tableQ: what is size of address space? (512G)Q: how much memory is used to represent it after 1rst kvmmap()? (3 pages)Q: how many entries is CLINT? (16 pages)Q: how many entries is PLIC? (1024 pages, two level 1 PDs)Q: how many pages is kernel text (8 pages)Q: how many pages is kernel total (128M = 64 * 2MB)Q: Is trampoline mapped twice? (yes, last entry and direct-mapped, entry [2, 3, 7])kvminithart();Q: after executing w_satp() why will the next instruction be sfence_vma()? mappages() in vm.carguments are top PD, va, size, pa, permadds mappings from a range of va’s to corresponding pa’srounds b/c some uses pass in non-page-aligned addressesfor each page-aligned address in the rangecall walkpgdir to find address of PTEneed the PTE’s address (not just content) b/c we want to modifyput the desired pa into the PTEmark PTE as valid w/ PTE_P walk() in vm.cmimics how the paging h/w finds the PTE for an addressPX extracts the 9 bits at Level level&amp;pagetable[PX(level, va)] is the address of the relevant PTEif PTE_Vthe relevant page-table page already existsPTE2PA extracts the PPN from the PDEif not PTE_Valloc a page-table pagefill in pte with PPN (using PA2PTE)now the PTE we want is in the page-table page procinit() in proc.calloc a page for each kernel stack with a guard page setup user address spaceallocproc(): allocates empty top-level page tablefork(): uvmcopy()exec(): replace proc’s page table with a new oneuvmallocloadsegprint user page table for shQ: what is entry 2? a process calls sbrk(n) to ask for n more bytes of heap memoryuser/umalloc.c calls sbrk() to get memory for the allocatoreach process has a sizekernel adds new memory at process’s end, increases sizesbrk() allocates physical memory (RAM)maps it into the process’s page tablereturns the starting address of the new memory growproc() in proc.cproc-&gt;sz is the process’s current sizeuvmalloc() does most of the workwhen switching to user space satp will be loaded with updated page table uvmalloc() in vm.cwhy PGROUNDUP?arguments to mappages()…","link":"/2022/12/16/MIT6-S081/"},{"title":"MML ch 10 主成分分析降维（Dimensionality Reduction with Principal Component Analysis）","text":"@[toc]对于一些高维的数据，分析难度大，而且想要对这些数据进行可视化几乎是不可能的，并且想要存储这些数据的代价也是及其昂贵的，所以我们想要找到一种能够将数据的维度降低的方法。这其中，主成分分析法（principal component analysis (PCA)）是最常用的方法之一。 问题设置（Problem Setting）在PCA中，我们希望能够找到一个一个向量的投影向量,与原向量尽可能相近。对于一个独立均匀分布的数据集,它的均值为0， 对应的数据方差矩阵为： S=\\frac 1N \\sum^N_{n=1}x_nx^\\top压缩之后表示为： z_n = B^\\top x_n\\in \\mathbb R^M其中，B为投影矩阵，定义为： B := [b_1,\\cdots,b_M]\\in \\mathbb R^{D\\times M}假设为正交规范基，则.我们希望找到一个M维的子空间,向其中的投影的向量与原先的向量最相似，因为压缩造成的损失最小。我们将投影的数据表示为,对应的坐标为(基向量为)PCA的目标是最小化平方重构误差（the Squared Reconstruction Error）.从数据压缩的角度来看，我们先是将源数据压缩到一个更低维度的空间中，对应下图的，然后将压缩的信息复原，对应下图中的; 控制着多少信息能够从到.在PCA中，我们考虑原始数据与低维数据之间的线性关系，所以有以下关系：。将PCA看成是一个数据压缩的过程，所以可以认为第一个箭头是编码器(encoder)，第二个箭头是解码器(decoder) Graphical illustration of PCA. In PCA, we find a compressed version z of original data x. The compressed data can be reconstructed into , which lives in the original data space, but has an intrinsic lower-dimensional representation than . 最大化方差的角度看PCA（Maximum Variance Perspective）在下图中，我们丢弃了数据关于的信息，这样做能够达到降维的效果，而且使得数据的损失最小化，是源数据与降维之后的数据尽可能相似。假设忽略的信息，则得到的数据就很不相似了，也就是说这个降维操作导致了很多的信息损失。通过观察可以发现，数据在两个维度上的分散程度不一样。当数据在一个维度上越分散，说明这个维度上所包含的信息也就越多，而方差可以表示数据分散程度的大小，所以从方差的角度理解PCA就是找到低维空间中数据方差最大的维度。为了运算方便，我们对数据进行一个均值归一化（Mean Normalization）,因为我们要研究的是方差，而对数据整体的几何运算并不会影响数据的方差 \\mathbb V_z[z]=\\mathbb V_x[B^\\top(x-\\mu)]=\\mathbb V_x[B^\\top x - B^\\top \\mu]=\\mathbb V_x[B^\\top x]这时候对应的低维空间的数据的均值也是0:。 是投影矩阵，将源数据投影到主成分上，从而实现降维。 最大方差的方向（Direction with Maximal Variance）为了找到数据在低维空间中的最大的方差，我们先找到一个向量,数据在这个向量上的投影的方差最大,也就是要最大化中第一个坐标的方差： V_1 := \\mathbb V[z_1]=\\frac1N\\sum^N_{n=1}z^2_{1n}我们将表示为数据()在低维空间（）的第一个坐标。的第一个成分为： z_{1n}=b_1^\\top x_n这是在张成的一维子空间中的正交投影，将上面二式联立： V_1=\\frac1N\\sum^N_{n=1}(b_1^\\top x_n)^2=\\frac 1N \\sum^N_{n=1}b_1^\\top x_n x_n^\\top b_1=b_1^\\top\\begin{pmatrix}\\frac 1N\\sum\\limits^N_{n=1}x_nx_n^\\top \\end{pmatrix}b_1=b_1^\\top Sb_1其中， S为数据协方差矩阵。由上式可知，正交基（）会对最终的方差的结果产生影响,所以这里要求这些基向量为规范正交基（），这样问题就转换成一个约束问题： \\max_{b_1}b_1^\\top Sb_1,\\quad s.t.\\ \\|b_1\\|^2 = 1利用拉格朗日方法： \\mathfrak L(b_1,\\lambda)=b_1^\\top Sb_1+\\lambda_1(1-b_1^\\top b_1)对上式分别求偏导： \\frac{\\partial \\mathfrak L}{\\partial b_1}=2b_1^\\top S-2\\lambda_1 b_1^\\top,\\quad \\frac{\\partial \\mathfrak L}{\\partial \\lambda_1}=1-b_1^\\top b_1令偏微分的结果为0： \\begin{aligned}Sb_1&=\\lambda_1 b_1 \\\\b_1^\\top b_1 &= 1\\end{aligned}由上式可以知道，是方差S的一个特征值，是一个特征向量，利用这个式子，我们可以将问题转化成： V_1=b_1^\\top Sb_1 = \\lambda_1b_1^\\top b_1 = \\lambda_1所以我们需要找到一个特征值最大的特征向量,这样源数据在投影之后的方差最大，这个特征向量称为主成分（Principal Component）我们可以得到投影数据点： \\tilde x_n=b_1 z_{1n}=b_1b_1^\\top x_n\\in \\mathbb R^D注意这里的投影点上的数据是高纬度空间中的数据，但是实际上存储的时候只需要用低纬度的空间信息就可以表示了。 M维子空间下的最大方差（M-dimensional Subspace with Maximal Variance）个主成分对应的是的个特征向量，这些特征向量对应着最大的个特征值。由于,所以S是一个对称矩阵，所以由谱定理可以得知，这些特征向量能够形成空间下的维子空间的正交规范特征基。想要找到这些正交基，可以使用向量减法： \\tilde X := X=\\sum^{m-1}_{i=1}b_ib_i^\\top X=X-B_{m-1}X其中，数据点的列向量(这里使用列向量是为了计算方便),投影矩阵所以想要找到第m个主成分，我们需要最大化方差; V_m=\\mathbb V[z_m]=\\frac1N \\sum^N_{n=1}(b^\\top_m \\hat x_n)^2=b^\\top_m \\hat Sb_m,\\quad s.t. \\ \\|b_m\\|^2=1其中，表示为数据集在正交变换之后（Missing argument for \\mathcal\\hat\\mathcal X）的方差.假设我们已经知道了的特征向量，设为S的特征向量： \\begin{aligned}\\hat Sb_i &= \\frac 1N \\hat X \\hat X^\\top b_i=\\frac1N(X-B_{m-1}X)(X-B_{m-1}X)^\\top b_i\\\\&=(S-SB_{m-1}-B_{m-1}S+B_{m-1}SB_{m-1})b_i,\\end{aligned}\\quad (*)由于都是这个子空间下的规范正交基（ONB），所以： \\boldsymbol B_{m-1}\\boldsymbol b_i=\\left\\{ \\begin{aligned} \\boldsymbol b_i, \\quad i< m \\\\ \\boldsymbol0, \\quad i\\ge m \\end{aligned} \\right.\\\\当时，说明是子空间下的一个正交基，由于是规范正交基，所以与其他基向量的乘积为0，与自身相乘仍为自身。当时，说明不是子空间下的正交基，这时候，这与其他的所有的正交基相互垂直，所以与他们的乘积也就为0.由上面的关系可以得到： \\hat S b_i=(S-B_{m-1}S)b_i=Sb_i=\\lambda_ib_i\\\\\\hat Sb_m = Sb_m=\\lambda_mb_m这可以知道正交投影之后的向量的特征向量的是一致的。当时，的关系式带入到（*）中： \\hat{\\boldsymbol{S}} b_{i}=\\left(\\boldsymbol{S}-\\boldsymbol{S} \\boldsymbol{B}_{m-1}-\\boldsymbol{B}_{m-1} \\boldsymbol{S}+\\boldsymbol{B}_{m-1} \\boldsymbol{S} \\boldsymbol{B}_{m-1}\\right) \\boldsymbol{b}_{i}=\\mathbf{0}=0 \\boldsymbol{b}_{i}所以可以发现张成于的零空间由和,可以得到数据在m维上的正交投影的方差为： V_m=b_m^\\top S b_m=\\lambda_mb^\\top_mb_m=\\lambda_m由上式可以看到数据方差于对应的特征值之间的关系。由上表可知，在200 个特征值中，仅有少数的特征值是显著大于0的，所以方差只存在于少数的主成分之中。为了评估PCA造成的信息损失，我们有以下标准：M个主成分所能包含的最大方差： V_m=\\sum^M_{m=1}\\lambda_m其中的是前M个最大的特征值因数据压缩导致的方差损失： J_m:=\\sum^D_{j=M+1}\\lambda_i=V_D-V_m或者使用相对方差捕获率（the relative variance captured），或者是压缩方差损失 投影的角度看待PCA(Projection Perspective)我们可以将PCA理解为找到一个子空间，源数据在上面的正交投影与源数据最为相似，也就是正交投影的数据与源数据的欧几里得距离最小。 问题设置和问题目标（Setting and Objective）假设一个规范正交基,所以在这个空间中的所有的向量都可以看成是这些正交基的线性组合： x=\\sum_{d=1}^D\\zeta_db_d=\\sum^M_{m=1}\\zeta_mb_m+\\sum^D_{j=M+1}\\zeta_jb_j,\\quad \\zeta \\in \\mathbb R在一个低维的子空间中(): \\tilde x = \\sum^M_{m=1}z_mb_m\\in U\\in\\mathbb R^D我们的目标就是最小化两种向量之间的欧几里得距离,这个最小化的向量所在的空间被称为主子空间（Principal Subspace）,标记为： \\tilde x_n:=\\sum^M_{m=1}z_{mn}b_m=Bz_n\\in \\mathbb R^D,\\quad z_n := [z_{1n},\\cdots,z_{Mn}]^\\top\\in \\mathbb R^M为投影矩阵的坐标。描述PCA之后的损失的量度为重构误差（Reconstruction Error）: J_m:=\\frac 1N \\sum^N_{n=1}\\| x_n-\\tilde x_n\\|^2找到最优化坐标（Finding Optimal Coordinates）想要找到最优化的坐标，需要找到原向量在基向量空间中的正交映射.如下图所示，我的目标也可以理解为找到最小的,由图中可以知道最小的时候是向量正交投影到基向量上的时候。接下来我们从数学的角度理解这个结论。对于一个规范正交基,假设最优的坐标为,对应投影。为了找到各个维度（坐标）下的最佳的坐标，我们需要将目标函数对坐标进行求导 \\begin{aligned}&\\frac {\\partial J_M}{\\partial z_{in}}=\\frac{\\partial J_M}{\\partial\\tilde x_n}\\frac{\\partial \\tilde x_n}{\\partial z_{in}} \\\\ &\\frac{\\partial J_M}{\\partial \\tilde x_n}-\\frac{2}{N}(x_n-\\tilde x_n)^\\top\\in \\mathbb R^{1\\times D}\\end {aligned}因为： \\tilde x_n:=\\sum^M_{m=1}z_{mn}b_m=Bz_n\\in \\mathbb R^D所以有： \\frac {\\partial J_M}{\\partial z_{in}}=-\\frac 2N(x_n-\\tilde x_n)^\\top b_i=-\\frac 2N (x_n-\\sum_{m=1}^Mz_{mn}b_m)^\\top b_i\\overset{b_ib_j=0}{=}-\\frac{2}{N}(x_n^\\top b_i-z_{in}b^\\top_ib_i)=-\\frac2N(x_n^\\top b_i-z_{in})将上面的偏微分设为0，可以得到最优情况下的坐标： z_{in}=x_n^\\top b_i=b_i^\\top x_n,\\quad i=1\\cdots M,n=1,\\cdots ,N这就说明最优坐标就是将原始数据做正交投影到目标向量空间中的坐标。 现在我们稍微复习一下向基向量的正交投影：一个向量向正交基进行正交投影 \\tilde x=b_j(\\underbrace{ b_j^\\top b_j}_{ONB,=I})^{-1}b_j^\\top x=b_j b_j^\\top x \\in \\mathbb R^D其中，是正交投影之后的坐标 在新的坐标系下，虽然，但是我们只需要用前M个坐标，因为在这个坐标系下剩下的坐标都是0. 找到主子空间的基向量（Finding the Basis of the Principal Subspace）为了找到主子空间的基向量，我们需要对原先的代价函数的形式进行一些改造。： \\tilde x _n = \\sum_{m=1}^Mz_{mn}b_m=\\sum _{m=1}^M(x_n^\\top b_m)b_m根据点积的对称性： \\tilde x _n=(\\sum^M_{m=1}b_mb_m^\\top)x_n 补充（原因） 原先提到原始数据可以用基向量线性组合表示，所以(这里可以理解为将原向量分解为投影向量和位移向量) \\begin{aligned} \\boldsymbol{x}_{n} &=\\sum_{d=1}^{D} z_{d n} \\boldsymbol{b}_{d} \\stackrel{(10.32)}{=} \\sum_{d=1}^{D}\\left(\\boldsymbol{x}_{n}^{\\top} \\boldsymbol{b}_{d}\\right) \\boldsymbol{b}_{d}=\\left(\\sum_{d=1}^{D} b_{d} \\boldsymbol{b}_{d}^{\\top}\\right) \\boldsymbol{x}_{n} \\\\ &=\\left(\\sum_{m=1}^{M} \\boldsymbol{b}_{m} \\boldsymbol{b}_{m}^{\\top}\\right) \\boldsymbol{x}_{n}+\\left(\\sum_{j=M+1}^{D} \\boldsymbol{b}_{j} \\boldsymbol{b}_{j}^{\\top}\\right) \\boldsymbol{x}_{n} \\end{aligned}所以位移向量（displacement vector）为： \\begin{aligned} x_n-\\tilde x_n&=(\\sum_{j=M+1}^Db_jb_j^\\top)x_n\\\\&=\\sum^D_{j=M+1}(x_n^\\top b_j)b_j\\end{aligned}其中，为投影矩阵。 这里可以看出，位移矩阵是在垂直于主子空间的空间中。 低秩近似（(Low-Rank Approximation）：由之前的讨论得知，投影矩阵为: \\sum_{m=1}^Mb_mb^\\top_m=BB^\\top由此，原先的平均平方重构误差可以写为： \\frac 1N\\sum^N_{n=1}\\|x_n-\\tilde x\\|^2=\\frac 1N \\sum_{n=1}^N\\|x_n-BB^\\top x_n\\|^2=\\frac 1N \\sum^N_{n=1}\\|(I-BB^\\top)x_n\\|^2所以可以将PCA理解为找到与单位矩阵最接近的的秩逼近。 现在我们能够重构损失函数： J_M=\\frac 1N\\sum^N_{n=1}\\|x_n-\\tilde x_n\\|^2=\\frac 1N \\sum^N_{n=1}\\Vert\\sum_{j=M+1}^D(b_j^\\top x_n)b_j\\|^2我们将平方范数展开，并结合是来源于规范正交基，可以得到下式： J_M=\\frac 1N \\sum^N_{n=1}\\sum^D_{j=M+1}(b_j^\\top x_n)^2=\\frac {1}{N}\\sum^N_{n=1}\\sum_{j=M+1}^D b_j^\\top x_nb^\\top_j x_n=\\frac 1N \\sum^N_{n=1}\\sum^D_{j=M+1}b_j^\\top x_n x_n^\\top b_j 补充推导过程 由于点乘的对称性，我们可以知道,带入上式： \\begin{aligned} J_{M} &=\\sum_{j=M+1}^{D} \\boldsymbol{b}_{j}^{\\top} \\underbrace{\\left(\\frac{1}{N} \\sum_{n=1}^{N} \\boldsymbol{x}_{n} \\boldsymbol{x}_{n}^{\\top}\\right)}_{=: \\boldsymbol{S}} \\boldsymbol{b}_{j}=\\sum_{j=M+1}^{D} \\boldsymbol{b}_{j}^{\\top} \\boldsymbol{S} \\boldsymbol{b}_{j} \\\\ &=\\sum_{j=M+1}^{D} \\operatorname{tr}\\left(\\boldsymbol{b}_{j}^{\\top} \\boldsymbol{S} \\boldsymbol{b}_{j}\\right)=\\sum_{j=M+1}^{D} \\operatorname{tr}\\left(\\boldsymbol{S} \\boldsymbol{b}_{j} \\boldsymbol{b}_{j}^{\\top}\\right)=\\operatorname{tr}(\\underbrace{\\left(\\sum_{j=M+1}^{D} \\boldsymbol{b}_{j} \\boldsymbol{b}_{j}^{\\top}\\right)}_{\\text {projection matrix }} \\boldsymbol{S}) \\end{aligned}由上可知，损失函数可以被理解为源数据在主子空间的正交补上的方差。这也对应这主成分分析是在最小化我们忽略的维度上的误差。等价的来说也就是我们需要保留方差最大的那几个维度。所以当我们投影到M维主子空间的时候，所对应的重构误差为： J_M=\\sum^D_{j=M+1}\\lambda_j 为什么是这个？ 其中的数据协方差的奇异值。所以想要最小化这个重构误差，就需要选择个最小的特征值，这些特征值对应的是主子空间的正交基的特征向量。这也就是说，主子空间所对应的特征向量的特征值是协方差矩阵中的最大的M个特征值。 这一节有很多问题，待补充。。。 特征向量计算以及低秩逼近（Eigenvector Computation and Low-Rank Approximations）为了计算方差矩阵的特征值，我们可以采用特征值分解或者是奇异值分解，前者可以直接计算出矩阵的特征值和特征向量。而使用SVD的可行性，是因为方差矩阵是对称并且能够分解为所以，方差矩阵的特征值就是的奇异值的平方。 S=\\frac 1N \\sum^N_{n=1}x_nx_n^\\top = \\frac 1N XX^\\top,\\quad X=[x_1,\\cdots , x_N]\\in \\mathbb R^{D\\times N}矩阵对应的SVD为： \\underbrace X_{D\\times N}=\\underbrace U_{D\\times D}\\underbrace\\Sigma_{D\\times N}\\underbrace {V^\\top}_{N\\times N}其中U和V都是正交矩阵，为对角矩阵，主对角线上的元素为奇异值.将这个式子带入到方差矩阵中： S=\\frac 1N XX^\\top=\\frac 1NU\\Sigma\\underbrace{V^\\top V}_{=I_N}\\Sigma^\\top U^\\top=\\frac 1N U\\Sigma\\Sigma^\\top U^\\top SVD分解之后的两端的矩阵是酉矩阵（）：Specifically, the singular value decomposition of an m\\times n complex matrix M is a factorization of the form , where U is an complex unitary matrix, is an rectangular diagonal matrix with non-negative real numbers on the diagonal, and V is an complex unitary matrix(酉矩阵). 所以U的列向量是的特征向量，也是方差矩阵的特征向量。其中特征值与奇异值的关系为： \\lambda_d=\\frac{\\sigma^2_d}{N}S的特征值和X的奇异值的关系对应的是原先的最大方差视角和奇异值分解之间的关系。 如何理解？ 用低秩逼近的PCA(PCA Using Low-Rank Matrix Approximations)PCA需要找出前N个最大特征值所对应的特征向量，实现这个目标可以采用低秩逼近的方式。 Eckart-Young theorem:就是评估低秩逼近之后造成的损失 由Eckart-Young theorem： \\tilde X_M:=\\operatorname{argmin}_{\\operatorname{rk(A)\\le M}}\\|X-A\\|_2\\in \\mathbb R^{D\\times N}所以，对应的低秩逼近就是找出前M大的奇异值： \\tilde X_M=\\underbrace {U_M}_{D\\times M}\\underbrace{\\Sigma_M}_{M\\times M}\\underbrace{V_M^\\top}_{M\\times N}\\in \\mathbb R^{D\\times N}其中，包含X的前M个最大的奇异值。 实际方面（Practical Aspects）我们可以直接采用特征多项式求解出特征值和特征多项式，但是由Abel-Ruffini theorem，五阶或者五阶以上的多项式方程没有几何解。所以在解决大于的矩阵的时候会遇到这个问题。由于在主成分分析中，我们会只需要前M大的特征向量和特征多项式，所以计算出所有的特征向量和特征值然后再舍弃一些特征值是很没有必要的。在一些极端的情况下，我们只需要第一个特征向量，这时候使用幂迭代（Power iteration）效率会非常高。 幂迭代首先先随机选取一个不在S的零空间的向量,然后按照下式进行迭代： x_{k+1}=\\frac{Sx_k}{\\|Sx_k\\|},\\quad k=0,1,\\cdots这个式子总是有,最终这个式子会收敛于最大的特征值所对应的特征向量。当S为不可逆的时候，应该保证In mathematics, power iteration (also known as the power method) is an eigenvalue algorithm: given a diagonalizable matrix A, the algorithm will produce a number \\lambda , which is the greatest (in absolute value) eigenvalue of A, and a nonzero vector v, which is a corresponding eigenvector of , that is, . The algorithm is also known as the Von Mises iteration.Power iteration is a very simple algorithm, but it may converge slowly. The most time-consuming operation of the algorithm is the multiplication of matrix A by a vector, so it is effective for a very large sparse matrix with appropriate implementation. 高维PCA（PCA in High Dimensions）想要对数据使用PCA，需要求解出数据的协方差矩阵，对于一个D维的数据，如果使用特征多项式（）的时间复杂度为.所以需要找到一种更加高效的方法解决这个问题。下面我们讨论数据的个数远小于数据维度的情况，即假设一组中心化（均值为0）的数据集，对应的协方差矩阵为： S=\\frac 1N XX^\\top\\in\\mathbb R^{D\\times D},\\quad X=[x_1,\\cdots,x_N]\\in\\mathbb R^{D\\times N}由于我们假设所以数据点的数量远小于数据的维度，也就是说数据的秩为N，则有个特征值为0，接下来我们探究将D维协方差矩阵转换成N维，且对应的特征值都是正数。所以有特征向量的等式： Sb_m=\\lambda_m b_m,\\quad m=1,\\cdots M其中b是主子空间的基向量，现在将S的定义带入： Sb_m =\\frac 1N XX^\\top b_m=\\lambda_m b_m现在等式两边同时乘以 \\frac 1N \\underbrace {X^\\top X}_{N\\times N}\\underbrace{X^\\top b_m}_{=:c_m}=\\lambda_m X^\\top b_m\\Leftrightarrow\\frac 1N X^\\top Xc_m=\\lambda_mc_m所以可以发现协方差矩阵的特征值为对应的特征向量为 印证原先提到的：的非零特征值等于的非零特征值 现在我们得到了映射之后的特征值和特征向量，现在我们需要找到源数据的特征值和特征向量。现在对上式两边同时左乘： \\underbrace{\\frac 1NXX^\\top}_SXc_m=\\lambda_mXc_m这样我们得到了源数据(X是酉矩阵？)，这仍旧是S的特征向量。 PCA在实践中的关键步骤(Key Steps of PCA in Practice) 减去数据均值（Key Steps of PCA in Practice） 这一步将所有数据减去数据的均值，使得处理后的数据的均值为0，这一步不是必须的，但是减小遇到数值问题的风险。 规范化（Standardization）： 将数据除以数据的标准偏差 协方差矩阵的特征值分解（Eigendecomposition of the covariance matrix） 由于协方差是对称的，根据谱定理，我们能够找到特征向量的规范正交基 投影（Projection） 将数据点投影到主子空间中： x^{(d)}\\leftarrow\\frac{x_*^{(d)}-\\mu_d}{\\sigma_d}\\quad d = 1,\\cdots,D10.其中，$x^{(d)}_代表的是x_$的第d个成分，所以对应的投影为：\\tilde x_*=BB^\\top x_*对应的坐标为：z_*=B^\\top x_*其中B由数据协方差矩阵最大的几个特征值所对应的特征向量组成。注意PCA返回的是坐标，而不是投影向量。要得到原始数据的投影，我们需要将投影之后的数据进行“反规范化”：\\tilde x^{(d)}_*\\leftarrow \\tilde x^{(d)}_*\\sigma_d+\\mu_d,\\quad d= 1,\\cdots, D MNIST数字：重构（MNIST Digits: Reconstruction）由下图可知，当主成分为一的时候，图像就是一个可以识别的数字了，随着主成分的增加，图像变得清晰了些下图中展示了图像信息损失和主成分数量之间的关系： \\frac 1N \\sum^N_{n=1}\\|x_n-\\tilde x_n\\|^2=\\sum^D_{i=M+1}\\lambda_i这也印证之前提到的，大多数的信息只存在于少量的主成分之中。 用潜变量看待PCA(Latent Variable Perspective)原先讨论PCA的时候没有使用概率方面的理论，这样能够帮助我们避开一些由概率论引起的数学上的困难，但是用概率论的能够帮助我们更好地理解PCA，而且在处理带有噪音的数据的时候，概率论中的似然函数提供了分析方式。 Observational Noise. The error between the true value in a system and its observed value due to imprecision in measurement. Also called Measurement Noise.观测噪音（Observation Noise）实际上就是我们所说的测量误差，由仪器等因素导致的于真实值的偏差。 通过介绍连续的潜变量, 我们能够将PCA用概率潜变量模型(probabilistic latent-variable model)来描述，这被称为概率主成分分析（probabilistic PCA ， PPCA） 生成过程及概率模型（Generative Process and Probabilistic Model）我们考虑一个线性降维，对于一个连续随机变量以及一个标准正态先验, 潜变量以及观测值之间的关系为： x=Bz+\\mu+\\epsilon\\in \\mathbb R^D其中为高斯观测噪音，而是潜变量到观测变量的线性/仿射映射。所以，潜变量于观测值之间的联系方式为： p(x|z,B,\\mu,\\sigma^2)=\\mathcal N(x|Bz+\\mu, \\sigma^2I)整体来说，PPCA的生成过程为： \\begin{aligned} z&\\sim \\mathcal N(z|0,I)\\\\ x_n|z_n&\\sim\\mathcal N(x|Bz_n+\\mu,\\sigma^2I)\\end{aligned}想要得到获得这些参数，需要一些典型数据，想要得到这样的数据可以使用祖先抽样（Ancestral sampling） Ancestral sampling 实际上就是通过采样解决条件概率问题。 在这里，先采样得到潜变量,然后再从潜变量中采样得到预测数据。于是，上面的生辰过程可以写成: p(x,z|B,\\mu,\\sigma^2)=p(x|z,B,\\mu,\\sigma^2)p(x)对应的图模型： Graphical model for probabilistic PCA. The observations explicitly depend on corresponding latent variables The model parameters and the likelihood parameter are shared across the dataset.可以将潜变量用于生成新的数据（补充理解） 似然以及联合分布（Likelihood and Joint Distribution）由原先的概率论部分，我们知道可以采用积分将潜变量消掉： p(x|B,\\mu,\\sigma^2)=\\int p(x|z,B,\\mu,\\sigma^2)p(z)dz=\\int \\mathcal N(x|Bz+\\mu,\\sigma^2I)\\mathcal N(z|0,I)dz还是由原先的知识，我们可以知道这个积分的结果是高斯分布，其均值及方差为： \\begin{aligned}\\mathbb E_x[x]&=\\mathbb E_z[Bz+\\mu]+\\mathbb E_\\epsilon[\\epsilon]=\\mu \\\\ \\mathbb V[x]&=\\mathbb V_z[Bz+\\mu]+\\mathbb V_\\epsilon[\\epsilon]=\\mathbb V_z[Bz]+\\sigma^2I\\\\&=B\\mathbb V_z[z]B^\\top+\\sigma^2I=BB^\\top+\\sigma^2I\\end{aligned}先前我们不适用条件概率分布的原因是极大似然估计以及极大似然后验估计需要的似然函数可以是数据以及模型参数的函数，但是不能是潜变量的函数，这里是用积分消去潜变量之后才用的。潜变量以及模型参数的关系（需要补充） 因为潜变量的线性/仿射变换是联合高斯分布，现在已知一些边际概率分布:.所以对应交叉协方差（cross-covariance）为： \\operatorname{Cov}[x,z]=\\operatorname{Cov}_z[Bz+\\mu]=B\\operatorname{Cov}_z[z,z]=B所以潜变量以及观测到的随机变量之间的联合分布为： p\\left(\\boldsymbol{x}, \\boldsymbol{z} \\mid \\boldsymbol{B}, \\boldsymbol{\\mu}, \\sigma^{2}\\right)=\\mathcal{N}\\left(\\left[\\begin{array}{l} \\boldsymbol{x} \\\\ \\boldsymbol{z} \\end{array}\\right] \\mid\\left[\\begin{array}{l} \\boldsymbol{\\mu} \\\\ \\mathbf{0} \\end{array}\\right],\\left[\\begin{array}{cc} \\boldsymbol{B} \\boldsymbol{B}^{\\top}+\\sigma^{2} \\boldsymbol{I} & \\boldsymbol{B} \\\\ \\boldsymbol{B}^{\\top} & \\boldsymbol{I} \\end{array}\\right]\\right)其中均值向量的长度为,协方差矩阵的大小为 后验分布（Posterior Distibution）由前面提到的联合概率分布可以求得后验分布(参数求解方式在概率论那一章有提及) \\begin{aligned} p(\\boldsymbol{z} \\mid \\boldsymbol{x}) &=\\mathcal{N}(\\boldsymbol{z} \\mid \\boldsymbol{m}, \\boldsymbol{C}) \\\\ \\boldsymbol{m} &=\\boldsymbol{B}^{\\top}\\left(\\boldsymbol{B} \\boldsymbol{B}^{\\top}+\\sigma^{2} \\boldsymbol{I}\\right)^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu}) \\\\ \\boldsymbol{C} &=\\boldsymbol{I}-\\boldsymbol{B}^{\\top}\\left(\\boldsymbol{B} \\boldsymbol{B}^{\\top}+\\sigma^{2} \\boldsymbol{I}\\right)^{-1} \\boldsymbol{B} \\end{aligned}注意后验协方差与数据无关，协方差矩阵C告诉我们（？）嵌入的可信度（？p343）我们可以利用这个后验分布得到数据对应的潜变量，然后再利用潜变量得到重构向量$\\tilde x_\\sim p(x|z_,B,\\mu,\\sigma^2)$.将这个过程重复多次，我们能够得到潜变量的后验分布以及其暗含的观测数据 拓展阅读现在我们想想之前做了什么。我们使用两个角度看待PCA，一个是投影的角度（最小化重构误差），一个是最大化方差的角度，除此之外还有其他的角度。我们先将高维数据用矩阵转换成用低维表示的数据,其中B由协方差矩阵的最大的特征值所对应的特征向量组成。得到低阶矩阵之后，我们可以利用投影矩阵将数据复原到源数据的维度:.当然我们还将PCA看成一个线性自动编码机(Linear Auto-encoder)由此可以得到重构误差： \\frac 1N \\sum^N_{n=1}\\|x_n-\\tilde x_n\\|^2=\\frac 1N\\sum^N_{n=1}\\|x_n-BB^\\top x_n\\|如果我们将线性映射转换成非线性映射，我们就会得到非线性自动编码机。当编码器是神经网络的时候，这个被称为认知网络或推理网络（recognition network or inference network），编码器称为生成器(Generator)。还有一种对PCA的理解涉及到信息论（information theory），就是将编码当成原始数据的压缩版本。当我们将压缩的信息还原，这并不能得到与原始一摸一样的数据，我们称这个压缩过程为有损失的。所以我们的目标就是尽可能将原始数据与压缩数据之间的相关性最大化。这种关系称为交互信息（the mutual information）。在讨论PPCA的时候，我们默认模型的参数（,似然参数）都是已知的，这些参数为：（我们将维数据投影到维子空间中） \\begin{aligned}\\mu_{Ml} &=\\frac 1N \\sum^N_{n=1}x_n\\\\ B_{ML}&=T(\\Lambda-\\sigma^2I)^{\\frac 12}R\\\\ \\sigma^2_{ML}&=\\frac{1}{D-M}\\sum^D_{j=M+1}\\lambda_j\\end{aligned}其中，包含协方差矩阵的M个特征向量，是一个对角矩阵，包含主子空间所对应的特征向量所对应的特征值。是一个随意的正交矩阵。是极大似然的解。是主子空间的正交补上的平均方差，可以认为是正交映射之后造成的损失。当处理一个无噪音的数据的时候，也就是,这时候PPCA与PCA得到的结构是一致的。由于协方差矩阵是对称的，所以可以被正交化，所以存在一个矩阵T包含S的特征向量： S=T\\Lambda T^{-1}数据的协方差矩阵就是高斯似然函数（）的协方差矩阵,也就是。当时，两种PCA的数据方差相等，所以有： \\operatorname{Cov}[\\mathcal X]=T\\Lambda T^{-1}=BB^\\top\\Leftrightarrow B=T\\Lambda^{\\frac 12}R所以实际上，这些PCA都是在对数据的协方差矩阵进行分解。 接触下来的内容难度较大，理解不够透彻，后续补充 iterative expectation maximization (EM) algorithm Bayesian PCA Markov chain Monte Carlo /variational inference. independent component analysis blind-source separation deep auto-encoder Gaussian process latent-variable model (GP-LVM)","link":"/2021/07/02/MML-ch-10-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%E9%99%8D%E7%BB%B4%EF%BC%88Dimensionality-Reduction-with-Principal-Component-Analysis%EF%BC%89/"},{"title":"STL和泛型编程","text":"1. 认识header、版本、重要资源头文件命名形式： C++标准库header files 不带（.h） 新型的C头文件不带.h 原先的C头文件(带有.h)的，仍旧可以使用（但是最好还是使用最新的形式） 所有的新式headers都在名字域“std”中 旧式的头文件不被包含在“std”中 2.STL体系结构基础介绍STL的六大部件： 容器 分配器 算法 迭代器 适配器 仿函数(Functors) 123456789101112131415161718192021222324# include&lt;vector&gt; // 与容器同名# include&lt;algorithm&gt;# include&lt;functional&gt;# include&lt;iostream&gt;using namespace std;int main(){ int ia[6] = {27, 210, 12, 47, 109, 83}; vector&lt;int, allocator&lt;int&gt;&gt; vi(ia, ia+6);// 分配器用于分配内存（一般默认） /* count_if: algorithm; not1: function adapter(negator); bind2nd: 绑定第二参数，function adapter(binder) less: function object */ cout &lt;&lt; count_if(vi.begin(), vi.end(), not1(bind2nd(less&lt;int&gt;(), 40))); // 大于等于40 return 0;} 标准库中的容器都是前开后闭的。但是容器的end()方法指向的是容器最后的元素的下一个元素，所以直接将这个指针解引用出来，得到的是一个未知的东西。12345678910Container&lt;T&gt; c;....Container&lt;T&gt;::iterator ite = c.begin();for(; ite != c.end(); ++ite)...// C++11for(auto&amp; elem : c){ ...} 3~6. 容器分类与各种测试标准库中的集合和map一般用红黑树实现。 代码习惯：测试程序放在名字域中，对应的库放在对应的名字域中，对应的定义变量需要的时候再写，为了注明，定义变量不会进行缩进。 vector： 对于空间扩充是呈现两倍增长的。这个增长是通过找到一个新的内存，然后将原先的元素全部复制到这个新的空间中，所以这个增长的过程实际上是比较缓慢的。 deque : 分段，但是逻辑上是连续的。没有自己的sort 关联式容器查找都非常快 multiset:内部是红黑树实现的,可以包含重复元素1multiset&lt;string&gt;c;multimap:不可以使用[]作为插入123multimap&lt;long, string&gt;c;c.insert(pair&lt;long, string&gt;(i, buf));// 访问需要使用first &amp; secondunordered_multiset:散列表实现的（哈希表） set: 不会出现重复的元素 map: 底层实现是红黑树， 可以使用[]添加元素，key不重复，value是有重复的 7. 分配器测试分配器用于内存分配1234int* p;__gnu_cxx::malloc_allocator&lt;int&gt; alloc;p = alloc.allocate(1);alloc.deallocate(p, 1); // 不建议使用，需要记住申请的内存的大小（用于空间释放） 8.源代码分布9. OOP &amp; 泛化编程泛化编程是将数据和方法分开来了。容器与算法（方法）之间通过迭代器相互关联。 为什么list不能使用::sort()?\\因为::sort()中使用的迭代器指针需要是能够随机访问的（能前能后），但是在list中，这种性质不满足。 特化\\模板在特定类型的时候使用特定的方法（更优的）1234567891011121314151617181920212223242526272829303132333435// 泛化template &lt;class type&gt;struct __type_traits{ ....};//特化template&lt;&gt; struct __type_traits&lt;int&gt;{ ....};//特化template&lt;&gt; struct __type_traits&lt;double&gt;{ ....};// 偏特化，如果传入的是一个指针（范围上的偏特化）template&lt;class type&gt; struct __type_traits&lt;type*&gt;{ ....};// 泛化template &lt;class T, class Alloc = alloc&gt;class vector{ ....};// 偏特化：仅将其中一个模板参数进行特化（数量上的局部）template &lt;class Alloc&gt;class vector&lt;bool, Alloc&gt;{ ....}; 11.分配器malloc申请内存的时候是有额外的开销的（其中包括了申请的空间的大小）。当申请的空间比较小的时候，这种开销占比比较大\\在VC6的allocator中知识以::operator new 和 ::operator delete 完成allocate() 和 deallocate() 没有特殊设计。12345678910111213141516171819202122232425262728293031323334#ifndef _FARQ #define _FARQ #define _PDFT ptrdiff_t #define _SIZT size_t# endif# define _POINTER_X(T, A) T_FARQ*# define _REFFERENCE_X(T, A) T_FARQ&amp;template&lt;class _Ty&gt; inline_Ty _FARQ* _Allocate(_PDFT _N, _Ty _FARQ*){ if(_N &lt; 0) _N = 0; return ((_Ty _FARQ*) operator new((_SIZT)_N*sizeof(_Ty)));}template&lt;class _Ty&gt;class allocator{public: typedef _SIZT size_type; typedef _PDFT difference_type; typedef _Ty _FARQ * pointer; typedef _Ty value_type; pointer allocate(size_type _N, const void*) // 第二个是任意参数 { return (_Allocate((difference_type) _N, (pointer)0)); } void deallocate(void _FARQ *_P, size_type) { operator delete(_P); }};// 分配512 intsint* p = allocator&lt;int&gt;().allocate(512, (int*0));allocator&lt;int&gt;().deallocate(p, 512); // 用临时变量调用类方法这种方式可能会导致太大的额外开销，所以，一些改进的方法是一次申请固定倍数大小的空间，这样可以减少malloc的使用（与vector中的空间拓展思想类似） 13、14. list源代码 i++ 和 ++i\\因为符号一样，所以给后置版本加一个int形参作为区分，这个形参是0，但是在函数体中是用不到的，只是为了区分前置后置。12self operator++(int) { ... } // i++self operator++() { ... } // ++i （可以认为i作为参数已经传入了）另外整数不能连续进行两次后连加，可以前加（++++i √，i++++ × ） 为了满足容器前闭后开的性质，在list链表中会有一个空白的头节点，这个就是end指针指向的节点，其内部实际上是一个环形双向链表。 15. Iterator 必须提供的5种相关类别 iterator_category value_type pointer reference difference_type 123456789template&lt;class I&gt;struct iterator_traits{ typedef typename I::iterator_category; typedef typename I::value_type; typedef typename I::difference_type; typedef typename I::pointer; typedef typename I::reference;}; 萃取机（iterator_traits）: 用于分离class iterator 和 non-class iterator。这是用过偏特化实现的12345678910111213141516171819202122232425262728293031323334template &lt;calss I&gt;struct iterator_traits{ typedef typename I::value_type value_type;};// 两种偏特化template&lt;class T&gt;struct iterator_traits&lt;T*&gt;{ typedef T value_type;};template&lt;class T&gt;struct iterator_traits&lt;const T*&gt;{ typedef T value_type; // 不能用const T，因为这样声明的变量无法赋值};// 获取I的value_typetemplate&lt;typename I, ...&gt;void algorithmn(...){ typename iterator_traits&lt;I&gt;::value_type v1;}// 一个实例template&lt;class T&gt;struct iterator_traits&lt;T*&gt;{ typedef random_access_iterator_tag iterator_category; typedef T value_type; typedef ptrdiff_t difference_type; typedef T* pointer; typedef T&amp; reference;}; 16.vector深度探索 在进行扩充的时候，需要重新申请空间，并且原先的空间将会被销毁，这使得这个过程中需要调用大量的构造函数和析构函数。 如果是连续空间，那么这个容器的迭代器就可以单纯地使用指针来表现。 17. array、forward_list 深度探索在特化array的时候，需要指明大小，这是因为array的大小是固定的，它没有构造器和析构器。12345678array&lt;int, 10&gt; myArray;// 定义数组int a[100]; // √//int[100] a; // ×typedef int T[100];T c; // √ 18，19. deque、queue和stack深度探索deque：这个容器的地址是由几个内存段产生的，用一个向量存储每一个内存段的首地址。对于迭代器，是由一个类组成，其中包含当前内存块的边界，当前指针指向的元素，以及当前内存块在地址向量中的位置 1234567891011121314151617181920212223242526272829303132333435// 这里会找到离边界最近的方向移动元素iterator insert(iterator position, const value_type&amp; x){ if(position.cur == start.cur){ // 是否是在开头 push_front(x); return start; } else if(position.cur == finish.cur){// 是否是在尾部 push_back(x); iterator tmp = finish; --tmp; return tmp; } else{ return insert_aux(position, x); }}template &lt;class T, class Alloc, size_t BufSize&gt;typename deque&lt;T, Alloc, BufSize&gt;::iteratordeque&lt;T, Alloc, BufSize&gt;::insert_aux(iterator pos, const value_type){ difference_type index = pos - start; value_type x_copy = x; if(index &lt; size()/2){ // 检查是否小于中点 push_front(front()); //复制第一个元素 ... copy(front2, pos1, front1); // 全部往前移动 } else{ push_back(back()); .... copy_backward(pos, back2, back1); } *pos = x_copy; return pos;} 模拟连续空间，累加，[]，向前移动元素 在stack和queue中，默认一个deque。 这两者可选择list或deque作为底层结构。二者不可用set或map作为底层结构。转调用的时候，一些函数不满容器特性。这二者不允许遍历，也不提供iterator，这种操作会干扰容器的特性（FIFO 或 FILO） 二者不同的是，queue 不可选择vector作为底层结构，stack可以。 123456789template&lt;class T, class Sequence=deque&lt;T&gt;&gt;class queue{ ....protected: Sequence c;// 底层容器 ...};stack&lt;string, llist&lt;string&gt;&gt;c; RB-tree关联式容器。RB-tree：平衡二叉搜索树。有利于search和insert。rb_tree 的迭代器不应该用于修改元素，但是未被禁止这种操作，因为它为set和map服务，而map允许data被修改，只有key不可以被修改，此时，红黑树是根据map的key进行排序的。红黑树提供两种insertion操作：insert_unique(), insert_equal前者key是要求独一无二的，后者可以有重复123456789101112131415template&lt;class Key, class Value, class KeyOfValue, class Compare, class Alloc=alloc&gt;class rb_tree{protected: typedef __rb_tree_node&lt;Value&gt; rb_tree_node; ...public: typedef rb_tree_node* link_type; ...protected: // 大小为9，但是为了内存对齐，这里实际上占用的内存为12 size_type node_count; // 节点个数 link_type header; Compare key_compare; // key的大小比较准则，是一个函数对象.理论上是0，但是实现为1 ...} 21.set &amp; multiset 一个元素不可重复，一个可以重复。 无法使用二者的iterator改变元素值，这些容器中的key有其固定的排列规则，这种iterator底层是RB tree的const iterator 元素特性是key就是value， value就是key 在实现中，set都是在调用rb tree中的操作，所以可以说set是一个容器的适配器 22.map &amp; multimap 与之前不同的是，这里的value被分为key和data 其他的性质与22中提到的类似 multimap 不可使用[], map可以，如果找到，则返回值，如果没有就将键值插入到map中。1234567// 调用逻辑map&lt;int, string&gt;my_map;map&lt;int, string, less&lt;int&gt;, alloc&gt;my_map;// selectlst: 获取键值，第一个元素template &lt;int, pair&lt;const int, string&gt;, selectlst&lt;pair&lt;const int, string&gt;&gt;, less&lt;int&gt;, alloc&gt;class rb_tree; 23，24、hash table 直接使用原始数字作为键值需要大量的空间，所以通常采用原始数据与一个素数的余数作为键值，这个素数可以被成为“篮子”(扩充大小实际上时固定的，根据不同的版本存在不同) 当元素个数大于篮子的数时，需要rehashing，重新规划篮子的大小（选下一个素数作为篮子大小，这样所有的元素都要重新计算）。 26.unodered容器概念C++之后，将原先的hash_set、hash_miltiset、hash_map、hash_miltimap中的hash编程unordered 27.算法形式算法的所需的一切信息都由迭代器取得 28. 迭代器的分类随机访问迭代器、双向迭代器、单向迭代器random_access_iterator, bidirectional_iterator, forward_iterator.123456// 特殊的迭代器display_category(istream_iterator&lt;int&gt;()); // input_iteratordisplay_category(ostream_iterator&lt;int&gt;(cout, \"\")); // output_iterator#include&lt;typeinfo&gt;typeid(itr).name(); // 查看变量类型 29. 迭代器分类对算法的影响如果是随机访问迭代器，那么迭代器可以直接到达指定的位置，如果是input_iterator，迭代器只能一个个加到指定的位置，这种功能可以通过偏特化实现（特化迭代器的类型） 对于output iterator是write-only，无法像forward iterator那样可以read， 所以不可以使用*运算符进行读取 30.算法源码剖析accumulate123456789101112131415161718192021222324252627282930313233# include&lt;iostream&gt;# include&lt;functional&gt;# include&lt;numeric&gt;namespace jj34{ using namespace std; int myfunc(int x, int y){ return x + 2 * y } struct myclass{ int operator()(int x, int y){ return x + 3 * y; } }myobj; void test_accumlate() { int init = 100; int nums[] = {10, 20, 30}; // default cout &lt;&lt; accumulate(nums, nums + 3, init); // 160 // using functional's minus cout &lt;&lt; accumulate(nums, nums + 3, init, minus&lt;int&gt;()); //40 // Using self-defined function cout &lt;&lt; accumulate(nums, nums + 3, init, myobj); // /* init = binary_op(init, *first) // binary_op 就是传入的函数，可以传入函数或者仿函数（重载括号运算符） */ }} for_each replace, replace_if, replace_copy1.替换元素，2。在给定条件下替换 3.不删除被替换元素，将其复制到其他位置 count， count_if find, find_iffind:循序查找 sort：传入迭代器范围12sort(vec.begin(), vec.begin() + 3); // 默认从小到大， i &lt; jvec.rbegin() = vec.end(); // 一个反向的迭代器 binary_search 仿函数和函数对象binder2nd12// 这里的less&lt;int&gt;() 不是在调用，这是一个对象count_if(v.begin(), v.end(), not(bind2nd(less&lt;int&gt;(), 40))); 仿函数可被适配的条件1234567891011121314151617181920template&lt;class Arg, class Result&gt;struct unary_function{ typedef Arg argument_type; typedef Result result_type;};template &lt;class Arg1, class Arg2, class Result&gt;struct binary_function{ typedef Arg1 first_argument_type; typedef Arg2 second_argument_type; typedef Result result_type;};// 每一个可适配的函数都会继承上面的结构体，因为需要向Function adapter提供上面结构体定义的信息template&lt;class T&gt;struct less : public binary_function&lt;T, T, bool&gt;{ bool operator()(const T&amp; x, const T&amp; y)const {return x &lt; y;}};新型适配器bind上述适配器已被弃用。 34. not135.bind （C++11）可以绑定： functions function object member function (_1需要是地址) data member(_1需要是地址) 1234567891011121314151617181920212223242526272829double my_divide(double x, double y) { return x/y; }struct MyPair{ double a, b; double multiply(){return a*b;}};using namespace std::placeholder; // adds visibility of _1, _2 ....auto fn_five = bind(my_divide, 10, 2);cout &lt;&lt; fn_five() ; // 5auto fn_five = bind(my_divide, _1, 2); // _1 占位符cout &lt;&lt; fn_five(10) ; // 5auto fn_five = bind(my_divide, _2, _1); // _2 第二个占位符cout &lt;&lt; fn_five(10, 2) ; // 5// 指定return type 为intauto fn_five = bind&lt;int&gt;(my_divide, _2, _1); // _2 第二个占位符cout &lt;&lt; fn_five(10, 2) ; // 5MyPair ten_two{10, 2};auto bound_memfn = bind(&amp;MyPair::multiply, _1);cout &lt;&lt; vound_memfn(ten_two); // 20// 本质上就是将函数中的一个参数绑定一个固定的值// ps： cbegin：表示constant","link":"/2022/10/12/STL%E5%92%8C%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B/"},{"title":"Wireshark Lab: HTTP","text":"Wireshark Lab: HTTP预备知识 坚持型连接&amp;非坚持型连接：是否在同一个TCP连接上完成所有的请求/应答报文的传输？Y：坚持型，N:非坚持型。 #### HTTP的非坚持型连接 现在来看看当你点击一个超链接的时候会发生什么。 1.客户机会对超链接的服务器通过80端口（TCP默认端口号）发起一个TCP连接 2.客户机通过套接字向服务器发送HTTP请求报文 3.服务器收到报文之后，从自己的内存（RAM or disk）中获取被请求的对象，并将这些对象封装至HTTP请求报文（HTLM）中，然后通过套接字发送给客户机。 4.HTTP服务器请求关闭TCP连接 5.客户机获取请求的对象，TCP连接彻底关闭。客户机从恢复报文中获取文件 6.获取其他的对象，继续循环上面的步骤 由此可见，每当一个对象被正确接收的时候，之前的建立的TCP连接都会被关闭。一般情况下，浏览器会建立5到10个并行TCP连接，这样的平行连接可以减短响应时间。 ![HTLM相应时间](https://img-blog.csdnimg.cn/20210102200933336.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70#pic_center) 由上图，非坚持型下的HTLM的相应时间为： #### HTTP的坚持型连接 非坚持型连接有以下几个缺点： 1.每一个请求对象都需要建立一次TCP连接，这样会导致额外的内存消耗 &gt; For each of these connections, TCP buffers must be allocated and TCP variables must be kept in both the client and server. 2.每一个对象的递交过程会导致两个RTT的时间消耗 ##### 坚持型HTTP连接的断开 在HTTP1.1中，当TCP连接建立之后，剩余的对象都通过这个TCP连接递交。当递交结束之后，当这条TCP连接在一定的时间(a configurable timeout interval)没有被使用时，这条连接会自动关闭。 &gt; HTTP/2 builds on HTTP 1.1 by allowing multiple requests and replies to be interleaved in the same connection, and a mechanism for prioritizing HTTP message requests and replies within this connection. （存疑） ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210102184014664.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70#pic_center) #### HTTP的报文格式 ###### 请求报文 1234567//一个例子//The great majority of HTTP request messages use the GET method.GET /somedir/page.html HTTP/1.1 //the method field, the URL field, and the HTTP version field.Host: www.someschool.edu //对象所在的主机地址（Web代理缓存中需要）Connection: close//表示非坚持型User-agent: Mozilla/5.0 //浏览器的类型Accept-language: fr//许多协商首部(negotiation header)中的一种 ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210102204106878.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70#pic_center) 注意到上图出现的实体（Entity Body）部分，在GET方法中是空的，他在POST方法中，例如当用户提供搜索关键词的时候，POST仍然是向服务器请求获取网页，但是是网页特定的内容。 但是HTML表单（HTML form）通常用GET方法，并在URL（统一资源定位器）中加上输入的文本，就像这样： 12//当你在某个网站上面搜索“monkeys” 和“bananas”的时候，URL会变成下面这个样子 www.somesite.com/animalsearch?monkeys&amp;bananas ###### 应答报文 123456789//一个例子HTTP/1.1 200 OK//the protocol version field, a status code（状态码：请求结果）, and a corresponding status message.Connection: close//非坚持型Date: Tue, 18 Aug 2015 15:44:04 GMT//服务器从自己的文件系统中获取被请求对象，并将它插入到回应报文中，后将它发送给客户机时的时间Server: Apache/2.2.3 (CentOS)//服务器类型Last-Modified: Tue, 18 Aug 2015 15:11:03 GMT// It is critical for object caching, both in the local client and in network cache servers (also known as proxy servers).Content-Length: 6821//被发送对象的比特数Content-Type: text/html//发送主题的类型（HTML 文本）(The object type is officially indicated by the Content-Type: header and not by the file extension.)(data data data data data ...)//报文核心部分（the meat of message）包含被请求的对象 报文请求结果类型： &gt; &gt; **200 OK**: Request succeeded and the information is returned in the response. **301 Moved Permanently**: Requested object has been permanently moved; the new URL is specified in Location : header of the response message. The client software will automatically retrieve the new URL. **400 Bad Request**: This is a generic error code indicating that the request could not be understood by the server **404 Not Found**: The requested document does not exist on this server. **505 HTTP Version Not Supported**: The requested HTTP protocol version is not supported by the server. ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210102210031696.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxNTY1Ng==,size_16,color_FFFFFF,t_70#pic_center) 状态行（state line） 表头行（header line） (待续....) &lt;hr style=” border:solid; width:100px; height:1px;” color=#000000 size=1”&gt; 总结问题：1.HTTP/2？（unsolved）","link":"/2021/01/03/Wireshark-Lab-HTTP/"},{"title":"Wireshark Lab:Getting Started","text":"Wireshark Lab:Getting Started《计算机网络自顶向下方法7e》实验 前言第一次实验主要就是介绍Wireshark应该怎么用，还有大致讲了Wireshark的工作原理。 一、How Wireshark Works?包嗅探器（Packet Sniffer）其本身不主动运行，只是观察应用发送和接收的数据包，并保存这些数据包的一个备份。 嗅探（Sniffers）是一种黑客的窃听手段，一般是指使用嗅探器对数据流的数据截获与封包分析（Packet analysis）。 包捕捉器：接受数据链路层的帧，因为在这一层，数据包是最完整的（发送来的数据报没有被解封装，发送的数据报在这一层完成了所有的封装）。包分析器：能够识别数据包的协议，以便将各层的协议部分从下一层的数据报中分离出来。 二、Wireshark的界面介绍 三、实验过程i）运行Wireshark，然后在浏览器中访问http://gaia.cs.umass.edu/wireshark-labs/INTRO-wireshark-file1.htmlii）停止Wireshak，在过滤器中输入http。 在对应层可以看到对应协议的一些信息，例如在IP层可以看到数据包的发送者和接收者的IP地址。 总结How long did it take from when the HTTP GET message was sent until the HTTPOK reply was received?（Unsolved）","link":"/2021/01/02/Wireshark-Lab-Getting-Started/"},{"title":"Q&amp;A","text":"右值引用的用法12// 引用右值，避免生成新对象Foo&amp;&amp; foo2 = FooFactory(); 关于std::move函数 std::move移动不了什么，唯一的功能是把左值强制转化为右值，让右值引用可以指向左值。其实现等同于一个类型转换：static_cast(lvalue)。 所以，单纯的std::move(xxx)不会有性能提升. move返回值如果有名称就是左值（被赋值给一个变量），没有名称就是右值。 使用建议：可移动对象在&lt;需要拷贝且被拷贝者之后不再被需要&gt;的场景，建议使用std::move触发移动语义，提升性能。（类似于 push_back等的函数）。 对于 unique_ptr只能进行移动构造函数，所以可以使用 move实现赋值构造std::unique_ptr&lt;A&gt; ptr = std::move(ptr_a);. 完美转发 std::forward std::forward &lt;T&gt;(u)有两个参数：T与 u。 a. 当T为左值引用类型时，u将被转换为T类型的左值； b. 否则u将被转换为T类型右值。 const右值引用传入的参数可以被修改，而const左值传入的则不可以修改。 C++为什么不推荐使用vector\\vector&lt; bool&gt;不是一个标准容器，就是因为它不能支持一些容器该有的基本操作，诸如取地址给指针初始化操作. 12vector&lt;bool&gt; c{false, false};bool b = c[0]; // 这里有一个隐式的类型转换 冷不命中(cold miss)缓存会在断电之后清空，那么是不是意味着在刚开机的时候，电脑运行的速度会相对较慢？ ssh命令传输方式为什么会因为网络波动而导致无法输入的情况 杂项 为什么在Xftp中删除文件那么慢，而直接使用rm会快很多？ 写入空白和覆盖哪个速度更快？ 为什么这么写？while(-1 != (opt = getopt(argc, argv, “x:y:”))) 防止将==写成=，此时，如果写成a=1编译会通过，如果写成1=a编译不会通过，这样做也可减少这种隐形的bug的出现 函数指针（typedef） 123456789// note that the typedef name is indeed myFuncDef// Confused here ???????typedef int (*myFuncDef)(int, int);myFuncDef functionFactory(int n) { printf(\"Got parameter %d\", n); myFuncDef functionPtr = &amp;addInt; return functionPtr;} void (*0)( ) ：是⼀个返回值为void，参数为空的函数指针0 (这里的意思是函数名为0吗？) 为什么在Linux下不能同时安装多个软件，但是在Windows下可以？（并行和串行的优劣？） 在fork之后，父进程和子进程的运行有先后顺序吗？ 函数名是不是就是函数指针？(是，那么为什么不需要解引用，直接可以调用？)我可以通过函数名调用函数，那可不可以认为这个函数名就是一个句柄？如何理解句柄？异常表中存储就是各种异常处理函数的句柄？能不能理解为一个整数到一个指针的映射？ 为什么要用 handle，而不直接用指针呢？ 指针作用太强，可做的事情太多。可做的事情越多，就会越危险。接口设计中，功能刚刚好就够了，并非越多权限越好的。 handle 通常只是个整数，实现被隐藏起来，假如直接暴露了指针，也就暴露了指针类型（有时也可以暴露 void* 指针作为某种 handle）。用户看到越多细节，其代码就越有可能依赖这些细节。将来情况有变，但又要兼容用户代码，库内部改起来就更麻烦。 资源在内部管理，通过 handle 作为中间层，可以有效判断 handle 是否合法，也可以通过权限检查防止某种危险操作。 handle 通常只是个整数，所有的语言都有整数这种类型，但并非所有语言都有指针。接口只出现整数，方便同一实现绑定到各种语言。 在编写信号处理器的时候，最好调用异步信号安全性函数，那为什么不能再执行函数的时候阻塞所有的信号，这样不能保证函数的原子性吗？ printf 和cout混用会有什么后果吗？ free 或者delete掉malloc 或 new 出来的内存会发生什么？ csapp p588: 在32位模式中， malloc返回的块的地址总是8的倍数，64位模式中，总是16的倍数。 这是为什么？ 双字对齐的约束下，块的大小总是为8的倍数，且块大小的最低三位总是为0（这样才能是8的倍数，这里双字表示8字节） csapp: 练习题9.6中的块大小的计算方法(get) docker &amp; virtual machine 之间有什么区别？ 向上转型：子类除继承父类数据成员，并且还会有自己的数据成员，但是在向上转型后子类的数据成员会被舍弃 转型之后的指针为什么可以通过子类的共有方法调用子类成员变量？ 多线程：如何理解多线程代码的执行过程，虚假唤醒 代码哲学 为什么说各个编程语言之间粒度不同呢？在什么方面体现？ 如果相应的库被实现了，那么这个语言的粒度会不会改变？ 短期内形成对方案的评估的能力，能够知晓方案的可行性、难点的能力，这种能力叫什么？如何训练（在刷算法题的时候，往往在完成过程中才能知晓这些，可能的原因有考虑不充分等） 见到一种技术，如何从技术实现得到技术的类型？ 将碎片知识进行体系化 解决一个算法问题的过程 为什么说计算机领域最难的两个问题是变量命名和缓存不命中？","link":"/2022/11/23/Q-A/"},{"title":"test","text":"这是一篇测试文章 这里的图片放在\\source\\images目录下","link":"/2022/10/11/test/"},{"title":"python学习笔记","text":"因为未来研究方向的需要，现在需要我抛开挚爱的C语言学习python。整篇博客记录的学习的内容，所以会比较长。这是个人笔记，所以有些地方你可能看的不是很明白，如有什么不恰当的地方，劳烦批评指正。@[toc] Python 基础输入输出12print(\"输出内容\"， 变量) #中间会出现一个空格，\"+\"用于连接两个字符串，中间没有空格input(\"提示语\") 数据类型和变量python在不需要提前声明变量类型，这一类的语言就是动态语言,反之，则为动态语言。两种除法符号,:代表的是浮点数除法，：代表的是向下整除 字符串和编码因为计算机只能处理数字，所有想要处理字符串，需要将对应的字符转换成数字，可以将每一个数字对应一个字符，于是就有了ASCII码（美国信息交换标准代码： American Standard Code for Information Interchange），这种编码使用一个字节，可以表示255个字符。但是世界各国语言不同，需要其他的位来表示本国的语言，为了统一，于是有了万国码(Unicode)，现在最常用的是UCS-16编码，用两个字节表示一个字符。但是这样会使原先一些用更少位就能存储的字符花费更多的位来存储，所以为了节约期间，出现了，可变长的编码——UTF-8。在编码英文字符的时候，可用更少的位存储（转换成类似ASCII）。在计算机内存中，统一使用Unicode，当存储或者转发的时候，才转换成UTF-8 在python中，字符串是以Unicode编码的，因此可以支持多种语言。下面是几个相关的函数。1234567&gt;&gt;&gt;ord('A') # 65 -&gt;ASCII&gt;&gt;&gt;ord('中') # 20013 -&gt;Unicode&gt;&gt;&gt;chr(66) # 'B' -&gt; char&gt;&gt;&gt;'\\u2e2d\\u6587' # '中文' &lt;- Unicode (Hex)&gt;&gt;&gt; x = b'ABC' # bytes 类型，每个字符只占一个字节&gt;&gt;&gt; b'ABC'.decode('ascii', errors = 'ignore') # 'ABC' parameter can also be 'utf-8'&gt;&gt;&gt; len('ABC') #3 calculating how many characters in string 格式化输出直接上例子,三种格式化的方式：123456789101112&gt;&gt;&gt;'%s is %d years old' % ('Tom', 30)# Tom is 30 years old# %% 表示 % 的转义#用format语句, 占字符会用{0}{1}...表示&gt;&gt;&gt; '{0} is {1: .1f} years old'.format('Tom', 30.112)#用f-string， 这会将字符串中的变量转换成相应的值name = 'Tom'age = '30'print(f'{name} is {age} years old')占字符的常见类型 list &amp; tuplelist 是一种有序集合，能够随时添加和删除其中的元素。与c++中的向量类似。下面是list的常用的操作：1234567891011121314151617181920#Creating a listlistName = [\"elem1\",elem2]#Get length of a listlen(listName)#Get a element in a list by index.#If the index is out of boundary you will get an error informationlistName[1] #return \"elem1\"listName[-1] # The last element#Add an element into the end of the listlistName.append(\"elem3\")#Add an element to a specific index listName.insert(index,\"elem4\")#Delete the last one elementlistName.pop()#Specific positionlistName.pop(1) #The second one will be deleted#change itlistName[1] = \"elem5\" # The second one will be replaced by \"elem5\"在list中可以是不同的类型的变量，也可以是一个其他的数组 tuple是一种初始化之后不能修改的有序列表，成为元组。它在定义的时候与list不同的是前者使用的”()”,而后者时候的”()”1234567891011#Definet = (1,2)#Empty tuplet = ()t = (1) #The tuple's size is 1t = (1,) #t has only one element that is 1#Changeable tuplet = (\"a\", [A, B])t[1][1] = A #It could be done 条件判断语句123456789101112# Formif condition1: exe1.elif condition2: exe2.else: exe3.# About inputvar = input(\"Mention_Info\") #input will return strvar2 = int (var) #Turning the str into int#If you input an non-number variable you'll get an error 循环for语句123456789# Formfor var in varList: exe.while break_condition: exe.# break &amp; continue have same functions as C# Useful functionrange(5) #Forming an serial number for 0 to 5尽量减少break和continue语句的使用，这会导致代码执行的逻辑分叉过多，容易出错。 dict &amp; setdict按照键-值存储， 能快速进行查找。1234567#Formdic = {key1:value1, key2:value2}dic[key1] # Return value1dic.get(key1) # Return value1dic.get(key3, -1) # Return -1, if the -1 is None instead of -1, it will output nothing key2 in dic # Whether the key is in the dic or not set是一个元素不重合的有序集合，初始化之后，会自动删除重复的元素。，集合之间的逻辑运算还可以模拟集合的交集和并集。集合是不能通过下标访问的，只能进行交集等运算，想要利用下标进行访问需要将集合转换成list12345s = set(list) # Like set(range(5)) likewise:list(range(5)) it will change into a lists1 &amp; s2 # 交集s1 | s2 # 并集s.add(key) # Add an elements.remove(key) # Add an element 总结一下，上面两种的结构，检索速度快，但是需要消耗大量的空间。是因为这些结构式采用哈希表实现的，也就是用键计算出对应的哈希值，这个哈希值就是值存储的位置，这也就是一个键对应一个值的原因，因为在这个位置上存储的位置式唯一的。而且这个地址只与键相关，与字典中的其他的键值无关，所以字典的检索速度不会因为字典的中的元素增多而受到影响。而list和tuple本质上就是链表，所以检索速度会受到链表中的元素的多少的影响。 关于不变性，这个不变性与C语言中的左值有点类似，一些不变对象进过一些操作之后变成了其他的对象，似乎是对原先的不变对象的修改，但是想象一下，你对2执行加法运算之后，得到了一个其他的结果，你能说是对数字2进行了改变吗？这时候也就是对原先的不变对象的拷贝进行的一些操作。同时不变对象因为在定义之后不能被修改，所以可以同时被访问，而不需要加锁，不必担心被修改的问题。所以，当一个对象可以被设计成不变对象的时候，尽量设置成不变对象。 函数函数调用注意一点，因为在定义函数的时候的没有加上大括号，所以不能借此作为函数的定界符，所以，一个函数当中的所有的语句的缩进一定要一致（DOS中使用快速双击ENTRE退出函数定义）12345678910111213# Formdef func_name(parameter): if(condition1): exe. # if it's \"pass\", it will do nothing. return # Return value else: exe_1. return x, y # you can return muti resultsx, y = func_name(para.) #It actually return a tuple, and several varians can recieve the tuple #Import from outer filefrom file_name import func_name # file_name.py#return的缩进要严格对应？ 函数的参数python中有默认参数，但是最好是指向不变量，否则会导致意想不到的错误。123def add_end(L = []): L.append(\"End\") return L上面这个函数，当使用默认函数的时候，L就会指向”[ ]”, 于是会返回[“End”]，当再次使用默认参数的时候，就会返回[“End”,”End”]。因为第一次使用默认参数的时候L会被初始化指向一个空list，之后若没有被重新指向一个新的list，则L指向的对象就没有改变，所以会使用原先的list作为初始化变量。正确的使用方式如下：12345def add_end(L = None): if(L is None): L = [] L.append(\"End\") return L可变参数在函数定义的时候在参数前加上一个“ ”，这样参数接收到的就是一个tuple，类似于一个指针了。当想要传入一个list或者tuple的时候，只需要把列表的名字前加上” \\ “，当成参数传进去就可以。 123456# Num could be several numbers or a list/arraydef add(*num): res = 0 for x in num: res = res + x return res 关键字参数传入参数的时候需要将对应的参数的名称加入写上，在函数中自动组装成一个字典。关键字参数在定义的时候需要在形参前面加上两个星号。在传入参数时，需要标明键和对应的值1234def fun_name(para1, para2, **kw): print(para1,para2,\"other :\",kw)fun_name(p1,p2,age = 20, place = \"Beijing\") # Output like a dic命名关键字参数这个限制了参数的关键参数的名字，只接受对应关键字参数。命名关键字参数之前需要用星号与位置参数隔开,这些参数必须传入参数，否则会报错。如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要一个特殊分隔符*了：123456def fun_name1(para1, *para2, para3): exe.def fun_name(para1, *, para2): exefun_name(p1, para2 = p2) 上诉的所有参数可以同时使用，但是顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。 递归函数递归函数就是在定义的时候调用自身的函数，在这个函数当中维护着一个栈，所以递归的深度受到栈空间的限制。有一种可以避免栈溢出的方法，就是尾递归，尾递归在返回的时候尽返回函数本身，没有其他的语句。 尾递归调用时，如果做了优化，栈不会增长，因此，无论多少次调用也不会导致栈溢出。遗憾的是，大多数编程语言没有针对尾递归做优化，Python解释器也没有做优化，所以，即使把上面的fact(n)函数改成尾递归方式，也会导致栈溢出。 高级特性切片切片能够使我们很方便地从其他数列当中过去一定范围的子数列。1234567L = list(range(5))#Note that it won't contain the last oneL[0:3] # L[0]、L[1]、L[2]L[-2:-1] # L[-2]L[-2:] #L[-2]、L[-1]L[:] #copyL[::-1] # 原矩阵的逆序矩阵 迭代在python中可以使用for语句完成对数组或者是字典的遍历。12345#在默认情况下字典迭代的是键d = {\"a\":1, \"b\":2}for key in d: # Accessing keysfor value in d.values: #Accessing valuesfor k, v in d.items(): #Accessing key-value pairs想要判断一个对象是否是可迭代对象，可以使用collections模块的Iterable类型判断：12from collections import Iterableisinstance(\"abc\", Iterable) #判断str类型是否为可迭代对象当想要将数组的下标同时输出的时候，可以使用枚举类型1234for i, value in enumerate(['a','b']):#可以在循环中引入两个变量for x, y in [(1,1), (2, 4)]: 列表生成式可以使用range()生成一个序列，在列表中还可以加上循环语句和条件语句123#这里的if作为一个条件筛选的作用，不能加上else[x*x for x in range(10) if x % 2 == 0] #[0, 4, 16, 36, 64][x*x+i for x in range(10) if x % 2 == 0 for i in range(10)] #这样产生的效果就是双重嵌套循环 生成器生成器通过调用next()函数，根据生成器中的定义不断输出对应的生成结果。123456# Define a generatorg = (x*x for x in range(10))next(g) # 0#Traverse the whole for n in g: exe当生成器中没有元素的时候，再调用会报错： Traceback (most recent call last): File “\\“, line 1, in \\StopIteration 就像是一次性的物品，使用完之后就没有了。在函数中，用关键字yield返回计算结果，这也就是调用next函数的时候的返回值。1234567def fib(max): n,a,b = 0,0,1 while n &lt; max: yield b #返回当前生成式的值，此时这个函数式generator a,b = b, a+b n +=1 return 'done' 迭代器对于可以直接作用于for语句的对象统称为可迭代对象：Iterable。在python中可以使用函数isinstance()判断一个对象是否为可迭代对象。可以使用next()函数调用不断生成下一个值得对象称为迭代器:Iteator一些数据类型例如list、dict、str不是迭代器，但是可以通过函数iter()将他们转换成迭代器。迭代器在本质上就是一个数据流，个人理解就是一个逻辑上存在的有序序列，暗示序列中的元素不是存储在某个位置，而是仅仅存在于逻辑上，想要得到他需要通过计算得出。（类似于向量空间）像函数并不是存储了所有的y而是在逻辑上有这样的映射关系存在，可以说代表y这一类的数字，但是需要通过计算得到y的真正的值。 函数式编程 函数式编程就是一种抽象程度很高的编程范式，纯粹的函数式编程语言编写的函数没有变量 高阶函数在python中函数名就是指向实现该函数的作用的模块的变量。这也就是说可以使用其他的变量代替原先的函数的指针作用。因为是变量的缘故，函数名也可以指向新的量。12f = absf(-10) # 10高阶函数就是能将其他函数作为参数的函数。123def add(x,y,f): return f(x)+f(y)add(-5,-6,abs) # 11 函数式编程就是指这种高度抽象的编程范式。 map/reducemap()接受两个参数，一个是函数名一个是可迭代的参数列表，最后返回一个迭代器，这样做可以将运算规则抽象化。12345#转化成一个字符列表list (map(str,[1,2,3,4,5,6,7]))# 参数形式map(func_name, list_name)map参数中的list_name需要与Func_name函数中的参数列表一致，也可以将一个向量作为参数传入12345def add(a, b): return a + blist(map(add,[1,2,3],[1,2,4]))# [2,4,7]reduce()传入的参数与map一致，但是作用不同:下面是一个将数字字符串类型转换成整型的实例：12345678910from functools import reduceDIGITS = {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}def str2int(s): def fn(x,y): return x * 10 + y def char2num(s): return DIGITS[s] #字典，输入键返回对应的值 return reduce(fn,map(char2num,s)) #map先将s转换成对应的数字数组，然后reduce将这个数字数组转换成对应的数字总的来说，二者就是将一个参数（或参数列表）按照一定的规律传入函数，然后输出对应的结果的参数列表。简要记录一下lambda的使用方式：123lambda 参数：操作(，范围)f = lambda x,y : x+yf(1,2) # 1+2 filterfilter也是一个高阶函数，也与之前的两个函数一样，传入一个函数和一个参数列表，不同的是，当参数返回false的时候，会将对应的参数列表中的参数剔除。下面是一个利用筛选法求素数列表的代码实例：1234567891011121314151617#利用筛选法，求出素数表def _odd_iter(): n = 1 while True: n = n + 2 yield ndef _not_divisible(n): return lambda x : x % n &gt; 0def primes(): yield 2 it = _odd_iter() while True: n = next(it) yield n it = filter(_not_divisible(n),it) 对于生成器的使用还是不是很熟悉。怎么理解呢？ 就像是一个映射关系，本质上它什么都不是，只是数据之间的关系，生成器只是指明了自变量与因变量之间的联系，想要得到确切的值，你得访问它。 sortedsorted函数也是传入参数表和相应的函数，但是传入的顺序和形式与之前的有所不同。1sorted(list_name, key = func_name, reverse = True/False)参数表的比较形式是根据函数处理之后的参数表，一般按照从小到大的顺序，但是可以用reverse关键字，使得结果是从大到小的排序形式。 返回函数高阶函数除了可以接受函数作为参数之外，还可以将函数作为结果的返回值，返回的函数包含了当下参数的结算结果，当调用的时候，才真正计算函数的结果。12345678910def lazy_sum(*args): def sum(): ax = 0 for n in args: ax += n return ax return sumf = lazy_sum(1,2,3,4) #Return a functionf() # Return the sumation result: 10在这个函数中定义的函数称为内部函数，内部函数可以使用外部函数的参数和局部变量，返回的函数包含参数和变量，这种程序结果称为闭包（closure）。每一次的函数调用都会返回一个新的函数，这些函数调用结果互不干扰。 闭包在使用闭包的时候需要注意一点，返回的函数是没有被执行的，只有在调用的时候在会将这个函数执行，所以，假设内部函数中有循环，这个时候循环虽然在继续，也在正常返回函数，但是因为函数是在调用的时候才执行的，所以当所有函数在调用的时候只返回最终循环作为参数的结果。例如下面这个函数返回的函数运行之后的结果都是9，因为在计算的函数的时候，只传入了循环的最后一个数。12345678910def count(): fs[] # 用于存储返回函数 for i in range(1,4): def f(): return i*i fs.append(f) return fs#调用f1,f2,f3 = count()所以需要记住的一点：返回函数中不要有任何循环变量，或者是之后会发生变化的量如果想要在返回函数中使用循环，可以在定义一个函数，然后再返回函数之前，这个函数就被执行了。123456789def count(): def f(): def g(): return j*j return g fs =[] for i in range(1,4): fs.append(f(i)) # 参数传入，函数被执行 return fs 匿名函数（lambda）想要直接传入参数的时候，不需要定义一个函数的名称，可以用相应的lambda语句代替函数。12#筛选出序列中的奇数L = list(filter(lambda x : x % 2 == 1, range(1,20))) 修饰器修饰器实际上就是将原先的一个函数指向一个重新定义的函数，而原先的函数定义没有发生改变。原先提到一个变量可以指向一个函数，所以可以通过变量指向调用函数。12345def now(): print(\"?\")f = nowf() # ?f.__name__ # now下面是将now函数的重定向：12345678910def log(func): def wrapper(*args, **kw): print('call %s():' % func.__name__) return func(*args, **kw) return wrapper#在函数定义处加上@和函数名@logdef now(): print(\"?\")之后的语句就相当于调用了log(now),当调用的now函数的时候，会返回调用log的函数的结果。这相当于对函数做了一个重定向。 偏导数创建一个新函数，可以修改原先函数的默认值。1234 import functoolsint2 = functools.partial(int, base=2)#这里将函数int中的变量默认为2#int函数是将一个字符串类型的变量转换成base进制的数字，base的默认值为10 模块模块可以封装一些函数，增加代码的可读性和可维护性，而且不同模块当中的变量是可以相同的。如是模块名发生了冲突，可以将模块整合到包下面，这时候只要包名不冲突，对应的模块也就不会发生冲突。如果一个文件夹是一个包，需要在文件中包含__int__.py注意在创建模块的时候，不能与系统内置的模块相互冲突12345假设一个路径：&gt;myPackage&gt;&gt;&gt;&gt;__int__.py&gt;&gt;&gt;&gt;abc.py则abc对应的模块名称为myPackage.abc 模块名要遵循Python变量命名规范，不要使用中文、特殊字符； 使用模块在python中有很多的内置模块，可以利用这些模块编写一个自己的模块。以sys为例,创建一个名为hello.py的模块。123456789101112131415161718192021#!/usr/bin/env python3 加上这一行之后hello.py文件直接在Unix/Linux/Mac上运行# -*- coding: utf-8 -*- 表明了编码方式' a test module ' #模块的第一个字符串会被当成文档注释__author__ = 'Michael Liao' #模块作者import sys #import 是执行非main函数的部分def test(): args = sys.argv #获取命令行参数，存储到一个列表当中 if len(args)==1: print('Hello, world!') elif len(args)==2: print('Hello, %s!' % args[1]) else: print('Too many arguments!')if __name__=='__main__': #当程序在命令行中运行的时候，会将其中的一个变量__name__赋值为__main__， # 所以当在非命令行的模式下运行的时候，导入模块之后需要使用hello.test（）来运行程序 test()在sys.argv中会获取命令行参数，如python hello.py York,那么argv中的list中会存储两个量[‘hello.py’、‘York’] 作用域变量名称的作用域用_来表示。__name__表示特殊变量，有专门的用途，自己命名的时候不要使用这样的变量名称。_name_表示非公开的变量或者函数（虽然在python中没有一种能够完全限制private变量访问的机制，但是习惯上不应该引用这些变量或者是函数） 面对对象编程在初始化一个对象的时候需要使用一个特殊的方法__init__()这类似C++中的构造器，每当一个实例被创造出来的时候，这个方法都会被调用，这个方法的第一个参数用于是self，表示创建的实例本身123456789101112class Student(object): def __init__(self, name, score): self.name = name self.score = score #当对象当中的方法需要调用实例当中的变量或者函数的时候，需要在参数列表中加上self def print_score(self): print('{}\\'s score:{}'.format(self.name, self.score)) #创建一个实例student1 = Student('York', 99) 访问限制当不想让类外部访问内部变量或者函数的时候，可以在变量或者函数前面加上__(double),这时候就外部代码想要访问这个变量或者函数的时候就会报错 AttributeError: ‘Student’ object has no attribute ‘__name’ 当一个变量或者是函数被声明为私有的时候，可以通过public的内部函数调用私有函数，从而达到访问的目的。当想要修改私有变量的时候，也可以通过public函数实现内外的联通。虽然直接用点运算也可以修改参数，但是使用函数的好处就是可以进行参数检查。 不能直接访问__name是因为Python解释器对外把__name变量改成了_Student__name，所以，仍然可以通过_Student__name来访问__name变量所以当你违反规定直接用点运算进行调用的时候，你不会得到你想要的那个变量，而是得到会给对象加上一个__name的变量。 继承与多态 在OOP程序设计中，当我们定义一个class的时候，可以从某个现有的class继承，新的class称为子类（Subclass），而被继承的class称为基类、父类或超类（Base class、Super class）。 注意到之前在定义类的时候，在类名之后的括号中加上了object,这表示这个类是从object这个对象中继承而来的。子类中的方法可以对父类中的方法进行继承和覆写。123456789101112131415161718192021222324class Animal(object): def run(self): print('Animal is running...')class Dog(Animal): pass # class Dog has a method runclass Cat(Animal): def run(self): print('Cat is running') #The method has been overwrite#We can use isinstance(instance_name, type)to check whether the instance is a certain typec = Cat() isinstance(c,Animal)#Trueisinstance(c,Cat)#Ture#We can use those characters def run_twice(Animal): # This parameter can be any other name animal.run() anmial.run()#We can pass the parameter either the Animal or its subclassrun_twice(c) #the run will the overwitten one 静态语言与动态语言在下面的这个代码中，传入的参数不一定是Animal类或者是其子类，只要是有run这种方法就行了123def run_twice(Animal): # This parameter can be any other name animal.run() anmial.run() 获取对象信息 用type()函数可以得到一个变量的类型 想要判断一个子类是否是继承于某一个父类，可以使用isinstance(变量，类名) 使用dir()可以获取一个对象的所有属性 使用hasattr(类名，'属性名')可以用于判断这个对象当中是否有某种属性 getattr(类名，'属性名')可以获取指定对象的制定属性 hasattr(object, name)判断一个对象里面是否有name属性或者name方法，getattr(obj,name[,default)函数用于返回一个对象属性值setattr(obj,name,value)函数对应函数getattr()，用于设置属性值，该属性不一定是存在的。 Animal.run和Animal().run的区别永远记住，类只是一个模板，模板是不会亲自下海干活的。python中如果不加括号，除了个别的，那就是个标识符（你可以理解为变量）。加了括号代表运行前面的东西，比如f就是个标识符，f（）代表运行f。Animal(). run，如果Animal是个类，就代表先运行Animal这个类，记得前面章节说的，类运行变为实例，实例才能亲自下海干活。Animal(). run就是这个实例里的run函数（run没加括号表示没运行run，仅仅是个函数而已），Animal(). run（）就是先运行Animal生成一个实例，然后运行这个实例里的run函数。 实例属性和类属性可以在类定义的时候加上一个变量，这时候这个类就与这个对象相互绑定了。当创建实例的时候，可以访问这个属性，也可以重新定义这个属性，因为实例的优先级比类的优先级要高，所以类的属性会被屏蔽，但是可以使用del instanceName.attributeName删除实例定义的属性。这时候再访问这个属性就是类的属性了。12345678class Student(object): name = 'student'#创建实例s = Student()s.name #访问属性s.name = 'Joker' #绑定实例del s.name #删除原先绑定的实例#实例也可以绑定原先类中不存在的属性注意一点，self.name代表的是实例属性，Student.name类属性 面对对象高级编程暂略 错误、调试和测试错误处理当一个函数正常运行的时候会返回一个整数，当出错时会返回-1，但是这样十分不方便，因为要接受返回值，然后对返回值进行判断，再作为返回值，这就需要函数一层层上报，十分麻烦，所以再高级语言当中设置一套机制try...except...finally... trytry之后跟着对应的测试代码，当某语句出现错误的时候，会直接跳到except语句中，检查是否捕获到对应的错误信息，是则执行之后的代码，最后执行finally中的代码。12345678try: print('try') r = 10 / 0 print('result',r) #这一句不会被执行except ZeroDivisionError as e: print('except',e) #except: division by zerofinally: print('Finally...')ZeroDivisionError之类的异常，实际上都继承自BaseException，所以当except语句后面加上BaseException,表示捕获所有的异常，也就是说BaseException的所有子类都会被捕获。 调用栈 如果错误没有被捕获，它就会一直往上抛，最后被Python解释器捕获，打印一个错误信息，然后程序退出。 其实就是当main语句中某处出现错误的时候，会返回出错的位置，如出错的位置为函数，则跳转到这个函数中，继续检查出现错误的语句，然后一步步深入，这个称为异常栈 记录错误原先的错误抛出方式会导致程序退出，但是可以使用logging模块，将错误记录下来，然后继续执行程序123456789101112131415161718import loggingdef error(): try: result = 1/0 #result = int('w') print('Pass1') except Exception as e: logging.exception(e)error()print('Pass2')'''ERROR:root:division by zeroTraceback (most recent call last): File \"&lt;ipython-input-12-21a7559c0ac6&gt;\", line 4, in error result = 1/0ZeroDivisionError: division by zeroPass2''' 通过配置，logging还可以把错误记录到日志文件里，方便事后排查。 抛出错误 只有在必要的时候才定义我们自己的错误类型。如果可以选择Python已有的内置的错误类型（比如ValueError，TypeError），尽量使用Python内置的错误类型。 可以使用rise来抛出异常。 调试断言123def dive(): assert a != 0, 'AssertionError: The denominator is zero!' .... assert的意思是，表达式n != 0应该是True，否则，根据程序运行的逻辑，后面的代码肯定会出错。如果断言失败，assert语句本身就会抛出AssertionError： AssertionError: The denominator is zero! 当程序中包含过多的assert,也会导致不良的影响，在启动python解释器的时候可以加上-O（大写字母O）来关闭assert语句。 $ python -O err.py","link":"/2021/04/07/python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"《Computer Systems: A Programmer Perspective 3rd ed》","text":"第一章 A Tour of Computer Systems&amp;#8195这本书的前言部分主要介绍了本书主要包含的内容（the hardware architecture, the operating system, the compiler, the network）还有一些学习的预备知识（C语言、Lunux系统）。 &amp;#8195全文展开的逻辑是介绍Hello.c文件从编写到输出主要经历了什么 1.1 Information Is Bits + Context这一部分主要讲程序文件在计算机中的存贮方式123456#include &lt;stdio.h&gt;int main(){ printf(\"Hello,world!\\n\"); return 0;}这段代码在计算机中使用ASCII码存贮的，如下图： Most computer systems represent text characters using the ASCII standardthat represents each character with a unique byte-size integer value.The hello.c program is stored in a file as a sequence of bytes 注意每一行都是以换行符结束的，而换行符的ASCII码为10.包含ASCII字符的文件为文本文件，其他的文件为二进制文件。最后的注释部分介绍了C语言的优点，还有缺点： C pointers are a common source of confusion and programming errors. &lt;hr style=” border:solid; width:100px; height:1px;” color=#000000 size=1”&gt; 1.2 Programs Are Translated by Other Programs into Different Forms文件运行的时候会有四个阶段：在预处理阶段，预处理器会处理带有#的语句，并将它直接插入到程序文本中。编译阶段将文本文件转义成汇编语言文件，汇编语言相当于一种通用语言，能够使得不同的高级语言在同一个机器上运行。汇编阶段将hello.s转换成机器语言，并将结果存储在hello.o文件当中，这时候的文件是可迁移的（relocatable object program）链接阶段将程序文件中调用的一些函数方法的执行程序与主程序合并，使主程序调用的函数可以顺利运行，这时候的文件为hello,这时的文件已经准备好被加载入内存中，后被运行了。 1.4 Processors Read and Interpret Instructions Stored in MemoryWhat’s happening when we entering a sequence of command. 1.5 Cache MatterNote that we spend a lot of time to move data form disk to main memory by bus. Which is so-call processor-memory gap .In order to improve the performance of the operations,we use a Cache Memory between Main memory and Register which will store the information which is most likely to need in the near future.It maybe small to store data but fast to fletch when we need it. Because of physical laws, larger storage devices are slower than smaller storage devices. 1.6 Storage Devices Form a Hierarchy 1.7 The Operating System Manages the Hardware 1.7.1 Processes To be continue 总结 1.英文术语：interpreted language ： 直译语言（英语：Interpreted language），又称直译式语言，是一种编程语言。这种类型的编程语言，会将代码一句一句直接运行，不需要像编译语言（Compiled language）一样，经过编译器先行编译为机器码，之后再运行。这种编程语言需要利用解释器，在运行期，动态将代码逐句直译（interpret）为机器码，或是已经预先编译为机器码的的子程序，之后再运行。理论上，任何编程语言都可以是编译式，或直译式的。它们之间的区别，仅与程序的应用有关。许多编程语言同时采用编译器与解释器来实作，其中包括Lisp，Pascal，C，BASIC 与 Python。JAVA及C#采用混合方式，先将代码编译为bytecode，在运行时再进行直译。 magnetic-disk &amp; solid state drives：磁盘和固态硬盘lingking：链接器 链接器（英语：Linker），又译为链结器、链接器，是一个进程，将一个或多个由编译器或汇编器生成的目标文档外加库链接为一个可执行文档。 metadata： 元数据（Metadata），又称元数据、诠释数据、中继数据元数据，为描述数据的数据（data about data），主要是描述数据属性（property）的信息，用来支持如指示保存位置、历史数据、资源寻找、文档记录等功能。元数据算是一种电子式目录，为了达到编制目录的目的，必须在描述并收藏数据的内容或特色，进而达成协助数据检索的目的。 context exchange： 上下文交换(英语：context switch)，又称环境切换，电脑术语，是一个保存和重建CPU的状态 (内文)，因此令多个进程(process)可以分享单一CPU资源的计算过程。要交换CPU上的进程时，必需先行保存目前进程的状态，再将欲运行的进程之状态读回CPU中。 System Call: 在计算机中，系统调用（英语：system call），又称为系统调用，指运行在用户空间的进程向操作系统内核请求需要更高权限运行的服务。系统调用提供用户进程与操作系统之间的接口。大多数系统交互式操作需求在内核态执行。如设备IO操作或者进程间通信。","link":"/2021/01/09/%E3%80%8AComputer-Systems-A-Programmer-Perspective-3rd-ed%E3%80%8B/"},{"title":"《算法笔记》数据结构部分(STL&amp;链表&amp;树)","text":"C++ STL栈123456789101112#include &lt;stack&gt;using namespace std;//定义一个栈stack &lt;typename&gt; name;//stack函数实例stack.push(x);//将元素x加入到栈中stack.top();//获取栈顶元素stack.pop();//将栈顶元素弹出stack.empty();//判断栈是否为空，返回值类型为空stack.size();//返回栈内元素 队列123456789101112131415#include &lt;queue&gt;using namespace std;//队列的定义queue&lt; typename &gt; name;queue&lt;int&gt; Q;//queue函数实例Q.push(x);//将元素x入队Q.front();//获取队首元素Q.back();//获取队尾元素Q.pop();//将队首元素出队Q.empty();//判断队列是否为空Q.size();//队列中元素的个数 优先队列（Priority_queue）优先队列就是按照元素的优先级来确定对首部的元素的队列，它是由堆实现的，这种优先级的规则可以自定义。优先队列可以用于计算哈夫曼树最短路径权值，可以对Dijkstra算法进行优化，还可以解决一些贪心问题。12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include&lt;cstdio&gt;#include&lt;queue&gt;#include&lt;string&gt;using namespace std;int main() { priority_queue&lt;int&gt;q; q.push(3);//将3入队 q.empty();//检查队列是否为空 q.pop();//将优先级最高的元素出队 q.size();//队列的大小 //第一个参数是元素类型，第二个是承载底层数据结构堆的容器，第三个是参数的比较类，less&lt;int&gt;表示数字越大优先级越高 priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt;q_1;}//当想以结构体中的数据作为优先级的时候，应该堆操作符进行重载//使用时直接将相应的结构体定义的变量直接入队即可struct fruit { string name; int price; //价格高的优先级高 //由于队列默认将优先级高的放在队首，如果将小于号重载为大于号，最后会将规则反向 friend bool operator &lt; (fruit f1, fruit f2) { return f1.price &lt; f2.price; }};//也可以将比较函数写在结构体外面struct cmp{ bool operator()(fruit f1, fruit f2) { return f1.price &gt; f2.price; }};priority_queue&lt;fruit, vector&lt;int&gt;, cmp&gt;p_2;//当结构体数据较大应该使用引用来提高效率/*friend bool operator &lt; (const fruit&amp; f1, const fruit&amp; f2) { ....}*/ pair采用方法pair可以用于快速定义一个相当于拥有两个变量的结构体。使用pair需要添加函数头utility.当然map函数头中包含前者。1234//定义一个pair变量，并初始化pair&lt;typename1, typename2&gt;name(initial1, initial2);//定义一个临时pair变量name = make_pair(initial1, initial2); pair函数的操作比较两个pair函数:可以直接用比较符，规则是先比较第一个的大小，当相等时比较第二个元素的大小常见用途：1.代替二元结构体机器构造函数。2.作为map的键值进行插入。12345678910111213141516#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;map&gt;using namespace std;int main(){ map&lt;string, int&gt;mp;//定义一个哈希表 //往哈希表中插入两个对键值 mp.insert(make_pair(\"hey\", 5)); mp.insert(pair&lt;string, int&gt;(\"Hei\", 10)); //利用迭代器遍历哈希表 for(map&lt;string, int&gt;::iterator it = mp.begin();it != mp.end();++it){ cout&lt;&lt;it-&gt;first &lt;&lt; \" \" &lt;&lt; it-&gt;second &lt;&lt; endl; } return 0;} 向量需要包含文件头vector 和using namespace std;定义方式：1vector&lt;typename&gt; vector_name;操作：1.获取元素的最后一个元素1234vector_name.end()-1;//注意end是指向最后一个元素的下一位vector_name.back();vector_name.rbegine();vector_name.at(vector_name.size()-1); 集合set集合是一种内部有序且不含重复元素的容器。当数据加入到集合中是，会自动去重和排序，默认排序是从小到大。要使用集合需要加上set函数头，并且使用std名字空间。 定义方式：(其实容器定义的方式都大同小异) 迭代器不是指针，是类模板，表现的像指针。他只是模拟了指针的一些功能，通过重载了指针的一些操作符，、、、等封装了指针1set&lt;typename&gt; name; 访问方式：（集合只能通过迭代器访问）1234567891011//定义迭代器set&lt;typename&gt;::iterator it;//除了vector和string之外，其他的STL都不支持*（it+1）的访问方式//枚举set&lt;int&gt;st;//initialize.......for(set&lt;int&gt;::iterator it = st.begin(); it != st.end();it++){ visit(*it);}set常用的函数：123456789insert(x);//将x加入set，并实现递增排序和去重(O(logN))find(value);//找到对应value的迭代器(O(logN))erase(it);//删除迭代器所指的元素，可以通过find函数找到对应的迭代器erase(value);//删除值为value的元素。时间复杂度O(logN)erase(first, last);//删除区间元素，删除区间为[first, last)size();//set中元素的个数O（1）clear();//delete all elements within the set 使用unordered_set,只进行去重而不进行排序，速度比set要快很多。 字符串类型Stringstring类型将字符串数组的一些常用操作封装起来，使用时需要添加文件头string（注意一点string和string.h是不一样的），还需要std的名字空间。初始化12//define &amp; initializingstring str = \"abc\"; 访问123//Access//1.By subindexstr[1]; 想要输入或者输出字符串，只能使用cin和cout。需要用printf输出，可以使用c_str()函数将string类型转换成字符串数组1printf(\"%s\\n\",str.c_str());通过迭代器访问12345//define. It no needs typename string::iterator it;for(string::iterator it = str.begin(); it != str.end();++it){ printf(\"%c\", *it);}string和vector一样，能够直接通过对迭代器加减某数字实现访问。1str.begin() + 3; 函数实例12345678910//连接两string类型str3 = str2 + str1;str1 += str2;//按照字典序比较两string类型的大小str1 &gt;= str2;//返回string类型的长度str.size();str.length(); insert()函数12345str.insert(pos,string);//在str的第pos位插入stringO(N)//str的3号位插入str2(prototype-&gt;)insert(it,it2,it3);//串[it2, it3)插入到it对应的位置上str.insert(str.begin() + 3, str2.begin(), str2.end());erase()删除12345//删除单个元素erase(it);//删除元素的迭代器erase(fist,last);//删除区间[first, last)的元素erase(pos,length);//pos开始删除length个字符个数clear();//清空其他123456substr(pos,len);//冲pos开始获取长度为len的子串string::npos; //一个常数等于-1或者是unsigned_int的最大值，用于find函数失配的返回值find(str2);//找到str2在字符串中第一次出现的位置，找不到返回string::npos.时间复杂度O(nm)str.replace(pos, len, str2);//将str从pos位开始长度为len的子串替换成str2str.replace(it1,it2,str2);//把迭代器范围内[it1,it2)的子串换成str2 链表链表的概念链表的物理地址是可以是不连续的，但是链表逻辑上是连续的。链表包含两个部分，一个用于存储数据，一个用于存储下一个节点的内存地址，以保证逻辑上的连续。12345//链表的结构体定义struct node{ typename data;//数据域 node* next;//指针域}; 链表节点的空间分配为链表节点分配空间可以利用两种函数：malloc(C语言) 和new(C++)。但是在空间分配之后，需要队空间进行释放，否则在一些情况下就会导致内存泄漏（在一些大型程序中，可能会导致弃用的空间一直被占用，而使得无法申请新的空间）。 malloc函数123456789101112#include&lt;stdlib.h&gt;typename* p = (typename*)malloc(sizeof(typename));/*整个过程就是malloc函数申请一个于数据类型大小一致的空间，这个时候返回的指针是void类型，然后将他强制转化成int类型，并分配给typename指针。申请失败的时候会返回空指针*///释放内存free(p);//本质上就是将p指针指向空地址，原先的地址占用状态被修改 new运算符（推荐使用）12345//申请一个节点空间typename* p = new typename;//取消对该节点的占用delete(p; 链表的基本操作创建链表（运用for语句实现）123456789101112131415161718192021//传入的数组为每个节点的数据域的值//尾插法：需要一个链表最后一个节点的指针。node* create (int Array[]){ node *p, *pre, *head; head = new node;//创建头节点 head-&gt;next = NULL; pre = head; for(int i = 0; i &lt; 5; ++i){ //创建新结点：1.申请空间；2.完成指针域和数据域的赋值 p = new node; p-&gt;data = Array[i]; p-&gt;next = NULL; //更新状态指针 pre-&gt;next = p; pre = p; } return head;]//注意一点在删除一个节点的时候需要有一个指向该节点的指针，以便后续删除该节点 静态链表静态链表的主要原理就是Hash。它利用数组的下标作为相应节点的地址，适用于节点地址是比较小的整数。12345//静态链表节点的定义方式struct Node{ typename data; int next;//注意这里的地址是一个整型变量}node[size];需要注意一点：因为静态链表是由数组实现的，所以就可能需要对其进行排序，但是如果这时候结构体类型名和结构体变量名相同（是允许的），sort函数就与出现编译错误。（例题：A1032）静态链表的使用步骤：123456789101112131415161718192021222324252627//定义静态链表struct Node{ int address; typename data; int next; XXX;//节点的某些性质}node[MAXN];//初始化静态链表:将性质量定义为正常情况达不到的数字for(int i = 0; i &lt; MAXN; ++i){ node[i].XXX = 0;}//标记（针对性质操作）//可以针对性质进行统计，标记int p = begin, count = 0;//用于开始遍历和统计while(p != -1){ XXX = 1; count++; p = node[p]-&gt;next;}//简化操作//由于静态链表直接采用地址映射的方式，这可能会导致地址//不是连续的，此时应该将有效节点转移到左端，可以通过排//序（sort函数）来实现（结合初始化的值） 搜索深度优先搜索（DFS）深度优先遍历会优先解决一种情况下的所有情况之后，再去解决其他的情况。如果能将一个事件的各个情况写成树形结构，就可以很容易地通过这种方法解决。123456789101112131415161718192021222324252627282930313233343536373839/*有n 件物品，每件物品的重量为w[i］，价值为c[i］。现在需要选出若干件物品放入一个容量为V 的背包中，使得在选入背包的物品重量和不超过容量V 的前提下，让背包中物品的价值之和最大，求最大价值。(l&lt;n&lt;20)*/#include &lt;cstdio&gt;const int maxn = 30;int n;//物品数量int V;//背包容量int maxValue = 0;//最大的价值int w[maxn], c[maxn];//分别为单个物品的重量个价值//参数分别为物品编号，总质量，总价值void DFS(int index, int sumW, int sumC){ if (index == n) {//完成对所有物品的选用 if (sumW &lt;= V &amp;&amp; sumC &gt; maxValue) {//检查当前方案是否满足条件 maxValue = sumC;//更新最大价值 } return; } //对index号的物品，有两种结果，放入背包或是不放入背包 DFS(index + 1, sumW, sumC);//不放入背包 DFS(index + 1, sumW + w[index], sumC + c[index]);//放入背包}int main() { scanf(\"%d%d\", &amp;n, &amp;V); for (int i = 0; i &lt; n; ++i) { scanf(\"%d\", &amp;w[i]);//重量 } for (int i = 0; i &lt; n; ++i) { scanf(\"%d\", &amp;c[i]);//价值 } DFS(0, 0, 0);//从第零件物品开始，此时的价值和重量都是0 printf(\"%d\\n\", maxValue); return 0;}注意到在加入index号的物品时，总重量发生变化，这可能会导致结果不满足条件，如果能在进入递归之前能够进行检查，能够减少一些不必要的递归12345678910//在递归之前加上判断条件void DFS_A(int index, int sumW, int sumC) { if(index == n)return; DFS_A(index + 1, sumW, sumC); //检查质量是否满足要求，以确定是否进入递归 if (sumW + w[index] &lt;= V) { if (sumC + c[index] &gt; maxValue)maxValue = sumC + c[index]; DFS_A(index + 1, sumW + w[index], sumC + c[index]); }}深度优先遍历的方法可以用于解决获取最优“子序列”的问题，也就是满足基本条件下的最优序列。12345678910111213141516171819202122232425/*问题描述：给定N个整数，从中选择K个数，使这K个数之和恰好等于给定的整数X，求出元素平方和最大的结果算法思想：利用一个数组，将已经选择的整数放入其中，当选择index号数字时，将这个数字加入到数组中，进入递归，之后再将这个数字取出，进入不选择index号数的递归。*/int n, k, x, maxSumSqu = -1, A[maxn];vector&lt;int&gt;temp, ans;void DFS_BSqu(int index, int nowK, int sum, int sumSqu) { if (nowK == k &amp;&amp; sum == x) { if (sumSqu &gt; maxSumSqu) { maxSumSqu = sumSqu; ans = temp; } return; } if (index == n || nowK &gt; k || sum &gt; x)return; temp.push_back(A[index]); DFS_BSqu(index + 1, nowK + 1, sum + A[index], sumSqu + A[index] * A[index]); temp.pop_back(); DFS_BSqu(index + 1, nowK, sum, sumSqu);} 广度优先广度优先类似于先解决简单的问题（离起点最近）然后再一步步深入。广度优先会先遍历所有的情况，对于求最优解的情况有优势。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/*问题描述：给定一个n*m大小的迷宫，其中*代表不可通过的墙壁，而“.”代表平地，S表示起点，T代表终点。移动过程中，如果当前位置是（x,y）（下标从0开始），且每次只能往前上下左右移动，求从起点到终点的最小步数。算法思想：可以将迷宫当作树型结构，将迷宫的起点作为树的根节点现在问题转换成找到迷宫终点所在树的层数*/#include&lt;cstdio&gt;#include&lt;cstring&gt;#include&lt;queue&gt;using namespace std;const int maxn = 100;struct node{ int x, y;//记录当前的位置 int step;//步数（层数）}S,T,Node;//分别为起点，重点，临时节点int n, m;//分别为行，列char maze[maxn][maxn];//迷宫信息bool inq[maxn][maxn] = { false };//检查此位置是否遍历过//增量数组，XY组合表示一个节点上下左右四个方向的位置int X[4] = { 0,0,1,-1 };int Y[4] = { 1,-1,0,0 };//检查（x,y）这个位置是否应该入队bool test(int x, int y) { //超出边界 if (x &gt;= n || x &lt; 0 || y &gt;= m || y &lt; 0)return false; //遇到墙壁 if (maze[x][y] == '*')return false; //检查是否入队。入队则是之前访问过的位置 if (inq[x][y] == true)return false; return true;//表示该位置有效}int BFS() { queue&lt;node&gt;q; q.push(S);//将起点加入到队列中 //判断当前访问的位置（出队的位置）是否为终点 while (!q.empty()) { node top = q.front(); q.pop(); //该位置为终点，直接返回此时的深度 if (top.x == T.x &amp;&amp; top.y == T.y) { return top.step; } //检查该位置4个方向上的情况 for (int i = 0; i &lt; 4; ++i) { int newX = top.x + X[i]; int newY = top.y + Y[i]; if (test(newX, newY)) { //新节点，更新相关的信息 Node.x = newX, Node.y = newY; Node.step = Node.step + 1; q.push(Node); inq[newX][newY] = true; } } } return -1;}int main(void) { //迷宫规格 scanf(\"%d%d\", &amp;n, &amp;m); //传入迷宫信息 for (int i = 0; i &lt; n; ++i) { getchar(); for (int j = 0; j &lt; n; ++j) { maze[i][j] = getchar(); } maze[i][m + 1] = '\\0'; } scanf(\"%d%d%d%d\", &amp;S.x, &amp;S.y, &amp;T.x, &amp;T.y); S.step = 0; printf(\"%d\\n\", BFS()); return 0;}值得注意的一点，当将一个元素push入队的时候，其本质就是将该元素的一个副本入队，所以，队列中的元素和原数据来源是相互独立的。 二叉树二叉树可以通过递归的方式定义，也就是可以将二叉树的子树看作一个新的二叉树。注意一点，二叉树的左右节点是由严格区分的。 二叉树的存储和操作1234567891011121314151617181920212223242526272829303132333435363738394041424344//二叉树结构体的定义struct node{ typename data; node* lchild; node* rchild;};node* root = NULL;//建树之前根节点不存在，将其设为NULL//新建节点:申请空间，赋值，初始化，返回节点地址node* newNode(int v){ node* Node = new node; Node-&gt;data = v; Node-&gt;lchild = Node-&gt;rchild = NULL; return Node;}//搜索节点:检查特殊情况和满足条件的情况，然后用同样的方法检查其他的节点void search(node* root, int x, int newdata){ if(root == NULL)return; if(root-&gt;data == x)root-&gt;data = newdata; search(root-&gt;lchild, x, newdata); search(root-&gt;rchild, x, newdata);}//二叉树节点的插入,注意这里输入的参数是引用型的，因为要对这个树进行修改void insert(node* &amp;root, int x){ //查找失败，这就是要插入节点的地方 if(root == NULL){ root = newNode(x); return; } if(根据条件检查检索的方向)insert(root-&gt;lchild,x); else insert(root-&gt;rchild,x);}//二叉树的建立node* Create(int data[], int n){ node* root = NULL; for(int i = 0; i &lt; n; ++i){ insert(root,data[i]); } return root;} 二叉树的遍历 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144/*中序遍历（非递归）：先找到最左边的节点，在寻找的过程中将途中的节点加入到栈中，当遇到根节点的时候，取出栈顶元素（这一步相当于回溯），访问其右节点，然后继续原先的循环*/void InOrderWithoutRecursion2(BTNode* root){ //空树 if (root == NULL) return; //树非空 BTNode* p = root; stack&lt;BTNode*&gt; s; while (!s.empty() || p) { if (p) { s.push(p); p = p-&gt;lchild; } else { p = s.top(); s.pop(); cout &lt;&lt; setw(4) &lt;&lt; p-&gt;data; p = p-&gt;rchild; } }}/*先序遍历（非递归）：在访问头节点的同时先将右节点加入到栈中，然后再继续访问左子树。当没有左孩子的时候访问右节点，表现为取出栈顶元素，进行访问*/void PreOrderWithoutRecursion(BTNode* root){ if(root == NULL)return; stack&lt;BTNode*&gt;s; BTNode* p = root; s.push(root); while(!s.empty()) { visit(p); if(p-&gt;rchild)s.push(p-&gt;rchild); if(p-&gt;lchild)p = p-&gt;lchild; else{//访问右子树 p = s.top(); s.pop(); } }}/*后序遍历（非递归）：后序遍历有一个问题，需要当前访问的节点是父节点的左孩子还是右孩子，如果是左孩子，就访问右孩子，否则访问头节点。*/void postOrderWithoutRecursion(BTNode* root){ if(root == NULL)return; stack&lt;BTNode*&gt;s; BTNode* pCur, *pLastVisit; pCur = root; pLastVisit = NULL; //Find out the leftmost element of the tree. while(pCur){ s.push(pCur); pCur = pCur-&gt;lchild; } while(!s.empty()) { pCur = s.top(); s.pop(); //访问头节点的条件：无右孩子或者是右孩子已经被访问 if(pCur-&gt;rchild == NULL || pCur-&gt;rchild == pLastVisit){ visit(pCur); pLastVisit = pCur; } else{ s.push(pCur); pCur = pCur-&gt;rchild; //找到右子树的最左边的节点 while(pCur){ s.push(pCur); pCur = pCur-&gt;lchild; } } }}//递归版void xOrder(node* root){ if(root == NULL)return; //'* = printf(\"%d\\n\",root-&gt;data); *//前序遍历 xOrder(root-&gt;lchild); *//中序遍历 xOrder(root-&gt;rchild); *//后序遍历}//层次遍历:每次完成一个节点的遍历，就需要检查其是否为叶子节点，否则加入到队列中void LayerOrder(node* root){ queue&lt;node*&gt;q; q.push(root); while(!q.empty()){ node* now = q.front(); q.pop(); printf(\"%d\",now-&gt;data); if(now-&gt;lchild != NULL)q.push(now-&gt;lchhild); if(now-&gt;rchild != NULL)q.push(now-&gt;rchild); }}//如果还想要直到当前节点所在的层数，可以在结构体中做好标记struct node{ int data; int layer; node* lchild; node* rchild;};void LayerOrder(node* root){ queue&lt;node*&gt;1; root-&gt;layer = 1; q.push(root); while(!q.empty()){ node* now = q.front(); q.pop(); printf(\"%d\",now-&gt;data); //更新节点信息之后，再将节点入队 if(now-&gt;lchild != NULL){ now-&gt;lchild-&gt;layer = now-&gt;layer + 1; q.push(now-&gt;lchild); } if(now-&gt;rchild != NULL){ now-&gt;rchild-&gt;layer = now-&gt;layer + 1; q.push(now-&gt;rchild); } }} 树的静态实现(非二叉树)实现静态写法是为了避免指针可能带来的错误。主要的思想就是将树的孩子节点存储在一个向量（“变长数组”）中。123456struct node{ typename data; vector&lt;node&gt; child;//??}Node[maxn];//如果不需要数据域，可以用如下方法定义vector&lt;int&gt;child[maxn];//这里定义了maxn个向量 树的遍历123456789101112131415161718192021//先序遍历：先访问节点，之后递归地遍历其孩子节点void PreOrder(int root){ visit(root); for(int i = 0; i &lt; Node[root].child.size();++i){ PreOrder(Node[root].child[i]); }}//层序遍历：先访问头节点，然后将孩子节点入队，直到队列为空void LayerOrder(int root){ queue&lt;int&gt;Q; Q.push (root); while(!Q.empty()){ int front = Q.front(); Q.pop(); visit(Q); //下面是访问该节点所有孩子节点的方法 for(int i = 0; i &lt; Node[front].child.size();++i){ Q.push(Node[front].child[i]); } }} 二叉查找树二叉查找树是节点按照一定规律排列的树，根节点的数据域大于或者小于左右孩子节点的数据域。同时二叉查找树还可以是一个空树。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788//二叉查找树的操作//新建一个节点：申请空间，赋值初始化，返回节点地址node* newNode(int v){ node* Node = new node; Node-&gt;data = v; Node-&gt;lchild = Node -&gt;rchild = NULL; return Node;}//查找二叉查找树中数据域为x的节点void search (node* root, int x){ //递归出口 if(root == NULL){ printf(\"search failed\\n\"); return; } //根据当前节点值得情况，决定递归方向 if(x == root-&gt;data)printf(\"%d\\n\",root-&gt;data); else if(x &lt; root-&gt;data) search(root-&gt;lchild, x); else search(root-&gt;rchild, x);}//插入一个数据域为x的新节点（注意这里的root是需要引用，后续修改）void insert (node* &amp;root, int x){ //当查找失败的时候，这个地方即为节点插入的位置 if(root == NULL){ root = newNode(x); return; } //由数据域的情况决定递归的方向 if(x == root-&gt;data)return; else if(x &lt; root-&gt;data)insert(root-&gt;lchild, x); else insert(root-&gt;rchild, x);}//二叉查找树的建立node* Crate(int data[], int n){ node* root = NULL; //将数组数据找到一个合适的地方插入 for(int i = 0; i &lt; n; ++i)insert(root,data[i]); return root;}//二叉查找树的删除//可以用根节点的前去或者后继来代替被删除的头节点//找到极值点的过程就是不断向左或者向右的过程，直到遇到空节点//找到以root为头节点的最大全职的节点node* findMax(node* root){ while(root-&gt;child != NULL)root = root -&gt; rchild; return root;}//找到权值最小的节点node* findMin(node* root){ while(root-&gt;lchild != NULL)root = root-&gt;lchild; return root;}//删除节点：想用前驱后者后继节点覆盖要删除的节点，然后问题就转换成删除前驱或后继节点//先找到想要删除的节点，然后判断节点的类型，然后再进行相应的递归操作//删除以root为根节点的权值为x的节点void deleteNode(node* &amp;root, int x){ if(root == NULL)return; //找到需要删除的节点 if(root-&gt;data == x){ //当需要删除的节点为叶节点，直接删除 if(root-&gt;lchild == NULL &amp;&amp; root-&gt;rchild == NULL)root = NULL; //左孩子非空，则用右孩子的极值替换该节点，然后删除该极值节点 else if(root-&gt;lchild != NULL){ node* pre = findMax(root-&gt;lchild); root-&gt;data = pre-&gt;data; deleteNode(root-&gt;lchild,pre-&gt;data); } //右孩子非空，操作同上 else{ node* next = findMin(root-&gt;rchild); root-&gt;data = next -&gt; data; deleteNode(root-&gt;rchild, next-&gt;data); } //寻找需要删除的节点 else if(root-&gt;data &gt; x)deleteNode(root-&gt;lshild,x); else deleteNode(root-&gt;rchild, x); } }对于删除节点的操作，可以进行优化，主要里利用极值节点坑定没有左子树或右子树的性质，将该极值节点的子树直接连接到该极值节点的父节点上即可。加入一直删除前驱或者后继，就会导致最后树变得十分不平衡，解决这个方法可以采取交替删除前驱后继或者是记录子树高度，优先在高度更高的的子树中删除节点。 平衡二叉树平衡二叉树是左右子树高度相差不超过1的二叉树。这样的结构可以保证在大多数操作下保持O(logn)的性能。因为当二叉树严重失衡时，二叉树退化成链表，此时操作的时间复杂度变为O(n)。在平衡二叉树中，右子树与左子树的高度之差称为该节点的平衡因子。 12345678910111213141516171819202122232425262728293031//节点结构体struct node{ int v, height;//节点权值和子树高度 node* lchild, *rchild; };//生成一个新的节点node* newNode(int v){ node* Node = new node;//申请节点空间 Node-&gt;v = v;//节点权值 Node-&gt;height = 1;//该节点本身的高度 Node-&gt;lchild = Node-&gt;rchild = NULL;//初始化孩子节点}//获取当前树的高度:从结构体变量中获取int getHeight(node* root){ if(root == NULL)return 0; return root-&gt;height;}//计算平衡因子:左子树高度减去右子树高度int getBalanceFactor(node* root){ return getHeight(root-&gt;lchild) - getHeight(root-&gt;rchild);}//更新当前节点的高度:孩子节点的最大高度加上节点本身void updateHeight(node* root){ root-&gt;height = max(getHeight(root-&gt;lchild), getHeight(root-&gt;rchild)) + 1;}//ALV的查找操作与二叉排序树的操作完全一致 对于ALV的插入操作，要根据树的结构做出相应的不同的操作。（BF：Balance Factor）树型| 判定条件|调整方法|—|———-|————-LL| BF(root) = 2;BF(root-&gt;lchild) = 1|对root进行右旋|LR|BF(root) = 2;BF(root-&gt;lchild) = -1|先对root-&gt;lchild进行左旋后对root进行右旋RR|BF(root) = -2;BF(root-&gt;lchild) = -1|对root进行左旋RL|BF(root) = -2;BF(root-&gt;lchild) = 1|先对右子树进行右旋，再对root左旋通过表格，可以总结：L代表根节点是正数，R代表孩子节点的负数。下图时LL和LR型的树的调整示意图注意到LR型是将LR先左旋转换成LL型的二叉树然后再执行右旋的，所以LR型的二叉树的调整可以由基本的左旋右旋组合而来。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465//左旋:将右孩子的左孩子连接到头节点处，其原先的左孩子连接到原先的头节点的右孩子处void L(node*&amp; root){ node* temp = root-&gt;rchild; root-&gt;rchild = temp-&gt;lchild; temp-&gt;lchild = root; //跟新调整之后的节点高度 updateHeight(root); uodateHeight(temp); root = temp;}//右旋void R(node*&amp; root){ node* temp = root-&gt;lchild; root-&gt;lchild = temp-&gt;rchild; temp-&gt;rchild = root; updateHeight(root); uodateHeight(temp); root = temp;}//插入节点：找到插入的位置，判断插入后树的类型，然后再做相应的操作void insert (node*&amp;root,int v){ if(root == NULL){ root = newNode(v); return; } //节点小，则在左子树中插入 if(v &lt; root-&gt;v){ insert(root-&gt;lchild,v); //更新节点信息， updateHeight(root); //L if(getBalanceFactor(root) == 2){ //LL if(getBalanceFactor(root-&gt;lchild)==1) R(root); //LR else if(getBalanceFactor(root-&gt;lchild)==-1){ L(root-&gt;lchild); R(root); } } else{ //从右子树中插入节点 insert(root-&gt;rchild,v); updateHeight(root); //R if(getBalanceFactor(root) == -2){ //RR if(getBalanceFactor(root-&gt;rchild)==-1)L(root); //RL else if(getBalanceFactor(root-&gt;rchild) == 1){ R(root-&gt;rchild); L(root); }//else if }//if }//else}//AVL树的建立node* Create(int data[], int n){ node* root = NULL; for(int i = 0; i &lt; n; ++i)insert(root,data[i]); return root;} 并查集 在计算机科学中，并查集（英文：Disjoint-set data structure，直译为不交集数据结构）是一种数据结构，用于处理一些不交集（Disjoint sets，一系列没有重复元素的集合）的合并及查询问题。并查集支持如下操作：查询：查询某个元素属于哪个集合，通常是返回集合内的一个“代表元素”。这个操作是为了判断两个元素是否在同一个集合之中。合并：将两个集合合并为一个。添加：添加一个新集合，其中有一个新元素。添加操作不如查询和合并操作重要，常常被忽略。 以下是并查集得一些基本操作。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061const int N = 10;int father[N];//初始化void initialSet(int father[], int N) { for (int i = 1; i &lt;= N; ++i) { father[i] = i; }}//查找:根节点的父节点就是其本身int findFather(int x) { while (x != father[x]) { x = father[x]; } return x;}//递归版本int findFatherRe(int x) { //递归出口 if (x == father[x])return x; else return findFather(father[x]);}//并查集合并：先判断两节点是否再同一并查集中（判断根节点是否相同），然后再将其中一个根节点的父节点指向另一个根节点//这样能能够保证并查集是个树型结构，不会出现环void Union(int a, int b) { int faA = findFather(a); int faB = findFather(b); //当二者不是统一并查集时合并 if (faA != faB){ father[faA] = father[faB]; }}//路径压缩：将搜索的时间复杂度由O(n)变为O(1)，其实就是将所有节点的父节点全部指向根节点int findFatherPatheShorten(int x){ int a = x;//找到根节点，同时保存初始节点 //找到根节点 while (x != father[x]) { x = father[x]; } //将该节点的父节点指向根节点，并保存该节点原先的父节点的信息 while (a != father[a]) { int z = a; a = father[a]; father[z] = x; } return x;}//递归版本int findFatherRSRec(int v) { if (v == father[v])return v; else{ int F = findFather(father[v]); father[v] = F; return F; }} 堆堆本质上就是满足父节点大于（或小于）孩子节点的二叉树。所有节点存储在一个数组当中，这样i节点的孩子节点分别为$2i和2i+1$。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273const int maxn = 100;int heap[maxn], n = 10;void swap(int &amp;a, int &amp;b) { int temp = a; a = b; b = temp;}//向下调整O(logn)：从low到high。找出该节点得该子节点中最大得节点，然后于该节点进行比较，若孩子节点较大，则与孩子节点进行交换void downAdjust(int low, int high) { int i = low, j = i * 2; while (j &lt;= high) { //找出孩子节点中较大的 if (j + 1 &lt;= high &amp;&amp; heap[j + 1] &gt; heap[j]) ++j; //与父节点进行比较 if (heap[j] &gt; heap[i]) { swap(heap[j], heap[i]); i = j; j = i * 2;//这里只去检查被调整的元素是否满足堆的条件，因为为改动的节点应该是满足堆的要求的 } else{ break; } }}//建堆O(n):从最后一个非叶节点往后进行循环，这是对原先数组进行了排序，以满足堆的要求void createHeap() { for (int i = n / 2; i &gt;= 1; --i)downAdjust(i, n);}//删除堆顶元素O(logn)void deleteTop() { //将最后一个元素代替堆顶元素，然后减少节点数量 heap[1] = heap[n--]; downAdjust(1, n);//改动了这个节点就从这个节点进行调整}//向上调整：当插入一个节点的时候，这个节点被放到最后，逐个与其父节点比较，直到该节点小于父节点void upAdjust(int low, int high){ int i = high, j = i / 2;//high就是最后一个节点，即插入的节点 //父节点在范围之内 while (j &gt;= low) { if (heap[j] &lt; heap[i]) { swap(heap[j], heap[i]); i = j; j = i / 2; } else { break; } }}//添加元素，借用上面的函数:加入节点，然后进行相应的调整void insert(int x) { heap[++n] = x; upAdjust(1, n);}//堆排序:将头节点与最后一个节点进行交换，然后对堆进行调整void heapSort() { createHeap(); for(int i = n; i &gt; 1; i--){ swap(heap[i], heap[1]); downAdjust(1, i - 1); }} 哈夫曼树哈夫曼树构建过程用语言描述就是，先将队列中权值最小的两个节点合并成新的节点，加入到队列中，然后一直按照这个规律执行，直到队列中只剩下一个节点。这个时候头节点的权值就是最短路径权值12345678910111213141516171819202122232425262728293031323334//以下是求一个实例的最短路径的权值的算法#include&lt;cstdio&gt;#include&lt;queue&gt;using namespace std;priority_queue&lt;long long, vector&lt;long long&gt;, greater&lt;long long&gt;&gt; q;int main() { int n; long long temp, x, y, ans = 0; scanf(\"&amp;d\", &amp;n); for (int i = 0; i &lt; n; ++i) { scanf(\"%lld\", &amp;temp); q.push(temp); } while (q.size()&gt;1) { //获取前两个最大节点 x = q.top(); q.pop(); y = q.top(); q.pop(); //将节点合并之后再入队 q.push(x + y); //统计最短路径权值 ans += x + y; } printf(\"%lld\", ans); return 0;}哈夫曼编码是一种用于无损数据压缩的熵编码（权编码）算法，它可以根据数据的一些特点（如出现频率）来制定相应长度的编码从而达到数据压缩的目的。","link":"/2021/02/25/%E3%80%8A%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E3%80%8B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%83%A8%E5%88%86-STL-%E9%93%BE%E8%A1%A8-%E6%A0%91/"},{"title":"《算法笔记》数据结构（图）","text":"图的存储图有两种存储方式：邻接表和邻接矩阵。邻接矩阵需要的空间较大，一般适用于顶点数目不超过1000的情况 邻接矩阵相当于一个离散的平面直角坐标系，每一个坐标代表一对节点的相互之间的关系，当两节点不直接相连的时候，这个坐标上的值可以设为0、-1或者是无穷大。否则可以在该点上赋值为这两点之间的权值。 邻接表将这些节点之间的关系保存在几个链表中，每一个链表都是在描述一个节点的连接情况。可以将这些数据保存在向量中。12345678910111213141516171819const int N = 10;//顶点个数vector&lt;int&gt;Adj[N];//之后直接将节点的信息连接到相应的向量之后int x;void Create() { for (int i = 0; i &lt;= 10; ++i) { Adj[i].push_back(x); }}//当需要存放更多节点信息的时候，可以用结构体+构造函数struct Node{ int v, w; Node(int _v, int _w) :v(_v), w(_w) {};};//赋值：Adj[1].push_back(Node(3,4)); 图的遍历遍历就是将图中所有的节点都访问一遍，要做到不重复访问，不遗漏。主要的方法有深度优先和广度优先。 深度优先访问的时候优先访问下一层的节点，运用递归的话，在递归返回的时候就相当于一次回溯，然后继续递归，即向下访问。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051const int MAXV = 1000;//最大顶点数const int INF = 100000000000;//一个很大的数字//邻接矩阵:检查其邻接节点是否存在然后逐一访问。class Adjacency_matrix {private: int n, G[MAXV][MAXV];//n为顶点数 bool vis[MAXV] = { false };//访问数组，没访问的数组赋值为false void DFS(int u, int depth) { vis[u] = true; //将该节点的所有相邻的节点全部访问一遍 for (int v = 0; v &lt; n; ++n) { //该节点未被访问且与访问节点相联 if (vis[v] == false &amp;&amp; G[u][v] != INF)DFS(v, depth + 1); } } //确保所有连通子图都被访问到 void DFSTrave() { for (int u = 0; u &lt; n; ++u) { if (vis[u] == false)DFS(u, 1); } }};//邻接表class Adjancency_list {private: vector&lt;int&gt;Adh[MAXV]; int n; bool vis[MAXV] = { false }; void DFS(int u, int depth) { vis[u] = true; //Traveling node u's all neighbours for (int i = 0; i &lt; Adj[u].size(); ++i) { int v = Adj[u][i];//u节点的第i+1的邻接节点 if (vis[v] == false)DFS(v, depth + 1);//没有访问则向下访问 } } void DFSTrave() { //保证所有连通子图的节点都被访问到 for(int u = 0; u &lt; n; ++u) { if (vis[u] == false)DFS(u, 1); } }}; 广度优先 在遍历过程中优先访问一个节点的所有的相邻的节点。这个时候需要借助队列，将该节点的所有相连节点加入到队列中，在队列中的节点顺序就是最终的广度优先遍历的顺序。同时，为了防止重复访问，需要建立一个数组，将节点的序号作为数组的下标，作为该节点是否被访问的标识。 算法思想：先将起始节点加入到队列中，然后不断取出队列中的元素，访问并加入到队列中，并将该点相连的节点加入到队列中，直到队列中的元素为空。 判断一个节点v1是否与另一个节点v2是否相连： 邻接矩阵中，只需要确定[v1,v2]所对应的值是否为1，是则为相连，反之不相连。 在邻接表中，只需要遍历这个节点所连接的那一条邻接表即可。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107int n, G[MAXV][MAXV];bool inq[MAXV] = { false };//广度优先邻接矩阵版：先将首个节点入队，class BFS_AdjMatrix {public: void BFS(int u) { queue&lt;int&gt;q; //将首节点放到队列中 q.push(u); inq[u] = true; //将相邻的节点加入到队列中 while (!q.empty()) { int u = q.front(); q.pop(); for (int v = 0; v &lt; n; ++v) { if (inq[v] == false &amp;&amp; G[u][v] != INF) { q.push(v); inq[v] = true;//访问之后加入队列，改变标识 } } } } void BFSTrave() { //将未被访问过的节点全部访问一遍 for (int u = 0; u &lt; n; ++u) { if (inq[u] == false)BFS(u); } }};//邻接表：访问节点的方式为遍历该向量的所有节点class BFS_AdjList {private: vector&lt;int&gt;Adj[MAXV];//这其实相当于一个二维向量 int n; bool inq[MAXV] = { false };//判断节点是否在队列中 void BFS(int u) { queue&lt;int&gt;q; q.push(u); inq[u] = true; while (!q.empty()) { int u = q.front(); q.pop(); for (int i = 0; i &lt; Adj[u].size(); ++i) { int v = Adj[u][i]; if (inq[v] == false) { q.push(v); inq[v] = true; } } } } void BFSTravel() { for (int u = 0; u &lt; n; ++u) { if (inq[u] == false)BFS(u); } } //当想要得出所有节点的所在层的信息的时候：利用结构体，在其中加上层次这一变量 struct Node { int v;//节点编号 int layer;//所在层次，头节点为第0层 }; void BFS(int s) { vector&lt;Node&gt;Adj[MAXV]; int n; bool inq[MAXV] = { false }; queue&lt;Node&gt;q; Node start;//第一个访问的节点 //初始化首个节点 start.v = s; start.layer = 0; q.push(start); inq[start.v] = true;//做好相应的标识 while (!q.empty()) { Node topNode = q.front(); q.pop(); int u = topNode.v; for (int i = 0; i &lt; Adj[u].size(); ++i) { //将next赋值为该节点连接的节点 Node next = Adj[u][i]; next.layer = topNode.layer + 1;//赋值为上一层的层数+1 if (inq[next.v] == false) { q.push(next); inq[next.v] = true; } } } }}; 最短路径这类问题是求解图中从源点到图中任一节点的最短的距离（路径）。主要的算法有Dijkstra算法、Bellman-Ford算法、SPFA算法、Floyd算法。 Dijkstra算法算法图示（取自Wikipedia）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116//Dijkstra算法const int MAXV = 1000;const int INF = 1e9;//无穷大//寻找最短距离//邻接矩阵:先找到与源点最近的相邻节点，然后从该节点出发，遍历该节点的所有的未被访问的相邻的节点，并更新最小权值//O(V*(V+V)) = O(V^2)class SPD_AdjMatrix {private: int n, G[MAXV][MAXV];//分别为顶点数和以邻接矩阵形式存储的图 int d[MAXV];//该节点到源点的最短距离 bool vis[MAXV] = { false };//访问数组，以图节点的编号作为索引 void Dijkstra(int s){ fill(d, d + MAXV, INF);//将所有的节点初始化为极大值 d[s] = 0;//源点到源点的距离为0 //找到与起点相邻的路径最短的节点 int u = -1, MIN = INF;//最短距离的节点编号和距离 for (int i = 0; i &lt; n; ++i) { //遍历所有相邻节点 for (int j = 0; j &lt; n; ++j) { //未被访问，并且距离权值小于之前记录的最小值 if (vis[j] == false &amp;&amp; d[j] &lt; MIN) { u = j; MIN = d[j]; } } } //说明剩下的顶点与起点s不相连通 if (u == -1)return; vis[u] = true; for (int v = 0; v &lt; n; ++v) { //与该节点相连且未被访问且以该节点为中介的权值比原先的权值更小 if (vis[v] == false &amp;&amp; G[u][v] != INF &amp;&amp; d[u] + G[u][v] &lt; d[v]) { d[v] = d[u] + G[u][v]; } } } //要记录最短路径的具体情况，可以记录每个节点最短路径的前驱，将该节点作为数组下标，数组中的值作为前驱节点的编号 int pre[MAXV]; void DijkstraPath(int s) { fill(d, d + MAXV, INF); for (int i = 0; i &lt; n; ++i)pre[i] = i;//(添加)初始化，将每个节点的前驱初试化为其本身 d[s] = 0; //找到与起点相邻的路径最短的节点 int u = -1, MIN = INF; for (int i = 0; i &lt; n; ++i) { for (int j = 0; j &lt; n; ++j) { if (vis[j] == false &amp;&amp; d[j] &lt; MIN) { u = j; MIN = d[j]; } } } if (u == -1)return; vis[u] = true; for (int v = 0; v &lt; n; ++v) { if (vis[v] == false &amp;&amp; G[u][v] != INF &amp;&amp; d[u] + G[u][v] &lt; d[v]) { d[v] = d[u] + G[u][v]; pre[v] = u;//(添加)将节点前驱初始化 } } } //输出路径 void DFS(int s, int v) { if (v == s) { printf(\"%d\\n\", s); return; } DFS(s, pre[v]); printf(\"%d\\n\", v); }};//邻接表：O(V^2 + E)class SPD_AdjList {private: struct Node{ int v, dis; }; vector&lt;Node&gt;Adj[MAXV]; int n; int d[MAXV]; bool vis[MAXV] = { false }; void Dijkstra(int s) { fill(d, d + MAXV, INF); d[s] = 0; for (int i = 0; i &lt; n; ++i) { int u = -1, MIN = INF; for (int j = 0; j &lt; n; ++j) { if (vis[j] == false &amp;&amp; d[j] &lt; MIN) { u = j; MIN = d[j]; } } if (u == -1)return; vis[u] = true; //利用向量的特性，直接获取相邻的节点 for (int j = 0; j &lt; Adj[u].size(); ++j) { int v = Adj[u][j].v; //检查是否满足条件 if (vis[v] == false &amp;&amp; d[u] + Adj[u][j].dis &lt; d[v]) { d[v] = d[u] + Adj[u][j].dis; } } } }};To Be Continue…","link":"/2021/03/07/%E3%80%8A%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E3%80%8B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%88%E5%9B%BE%EF%BC%89/"},{"title":"《算法笔记》第一部分C&#x2F;C++语言基础","text":"《算法笔记》的笔记第二章： C/C++快速入门 # 前言 在学习之前有一个小插曲，用vi命令打开.c文件的时候总是提示存在交换文件，这让我没有办法修改我的目标文件，经过查询相关资料，我发现只要将对应的交换文件删除就可以了，产生原因可能是因为在退出编辑模式之前退出文件了。应该是shift+double z，而不是crtl **具体的操作方法**：使用ls - al 命令查看文件夹目录，找到交换文件（文件后缀是.swp）然后就用 rm - 文件名 删掉相应的交换文件就可以了 *PS：我发现当交换文件出现重名的时候，文件的拓展名会到发生变化（.swn 、.swo等） PPS：很久没有用我的Ubuntu了，很多的命令都忘记了，所以一些常用的命令需要在这里记下来，以便之后学习的时候复习。* vi/vim、cd、ls、mkdir &lt;hr style=” border:solid; width:100px; height:1px;” color=#000000 size=1”&gt;虽然之前学过C/C++但是担心自己有什么遗漏所以还是看了一遍，在这里主要记录的就是自己原先不是很熟悉的内容。 2.1 基本数据类型 cin和cout消耗的时间会比scanf和printf多得多。而且在同一个程序当中不应该同时使用cout和printf（会出现问题） C++标准库中，stdio.h的推荐写法：cstdio（就是去掉后缀，然后在最前面加上c,eg: —-&gt; \\） 基本数据类型：i）整型：int —-&gt; 32bit （10\\^9以内使用）|| long long ——&gt; 64 bit(如果long long型赋大于2\\^31-1的初值的时候，需要在初值后面加上LL，否则会编译错误)ii)浮点型：（Mantissa：小数部分）由上图可以知道单精度float有效精度只有6~7位（具体原因之后补充），双精度浮点型double的有效精度为15~16位。书中的建议：（应该是单精度浮点型的精度在大多时候都不够用吧） 对于浮点型来说，只需记住一点，不要使用float，碰到浮点型的数据都应该使用double来存贮。 iii）字符型：字符在C语言中使用使用ASCII码统一编码的。（需要记住一点小写字母比大写字母的ASCII码值大32，0的ASCII码为48）（还要记住几个常用的转义字符：\\n代表换行,\\0代表空字符，其ASCII码为0，\\t代表Tab键）这一部分总结来说就是%c会将整型数字转化成相应ASCII码所对应的值。对于字符串型可以转化成字符数组，但是不能赋值给字符变量 3.强制类型转换 格式：（新类型名）变量名 如果在计算过程中需要类型转换，那么就不能等它算完再在赋值的时候转换 4.符号常量和const常量 这是定义常量的两种方式（更加推荐后者）格式：12#define 标识符 常量//注意这里最后是没有分号的const 数据类型 变量 = 常量；宏定义（Macro definition）的陷阱：12345678910#include &lt;stdio.h&gt;#define CAL(x) (x * 2 + 1)int main(void){ int a = 1; printf(\"%d\\n\",CAL (a + 1)); return 0;}//输出：4//因为宏定义只会将数据原封不动地带进去，实际上的运算过程为：a+1*2+1.//所以在用宏定义的时候应该将变量全部用括号括起来5.运算符 i）算数运算符没有幂次运算符，^代表的是位异或（位运算符可以用来定义无穷大的数）123//实际上就是整型的上限const int INF = (1 &lt;&lt; 30) -1;const int INF = 0x3fffffff;位运算符的使用技巧：123456789101112131415161718192021//1.判断两个数字是否异号，利用补码编码的符号位进行异或运算（同0异1）int i = -1, j = 1;(i ^ j &lt; 0) = true; //2.将编码最后一个1转换成0，可用于求解统计二进制编码中1的个数和判断一个数是不是2的指数//这个数减去一之后，会向从右开始的第一个数借一位，这使得这一位变成0，然后与运算，//将不相同的位全部变成0，这样就去掉了最右边的哪一个1n &amp; (n-1);//可以用于统计1的个数，或者进行相应的运算//统计一个数的二进制数中1的个数(汉明权重)int hammingWeight(uint32_t n){ int res = 0; while(n != 0){ n = n &amp; (n - 1); res++; }}//判断一个数是否为2的指数：注意2的指数有一个特点，在二进制编码中只能有一个1bool isPowerOfTwo(int n){ if(n &lt;= 0)return false; return (n &amp; (n - 1)) == 0;} ii）条件运算符格式：A ? B : C; 12//用条件运算符+宏定义判断大小的结构#define MAX(a, b) ((a) &gt; (b) ? (a) : (b)) 2.2 顺序结构2.2.1 赋值语句而如果要给多个变量赋同一个值，可以使用连续等号的方法：12int n, m;n = m = 5; 2.2.2 输入/输出语句（scanf/printf）1.scanf函数注意到字符串类型不需要使用取址运算符，因为字符串类型相当于一个数组，数组名称代表第一个元素的地址。另外，除了%c 外， scanf 对其他格式符（如%d）的输入是以空白符（即空格、 Tab ）为结束判断标志的123456int main (void){ int a, a1; scanf(\"%d%d\", &amp;a, &amp;a1); printf(\"%d %d\", a, a1);}//input:1 2 output:1 2但是对于%c 123456789int main(void){ int a; char c, str[10]; scanf(\"%d%c%s\", &amp;a, &amp;c,str); printf(\"a=%d, c=%c,str=%s\", a, c, str); return 0; //Input:1 2 3 //Output:a = 1, c=, str = 2 //可见空格也被当成一个字符了} scanf()的返回值：输入数字，匹配%d,配置b的值成功，scanf返回成功配置数量1；输入字母，不匹配%d,配置b的值失败，scanf返回成功配置数量0；输入Ctrl+Z，scanf返回-1； 2.printf函数这里注意一点：在scanf中double的格式符为%lf，而在printf中格式符为%f 接下来介绍三种使用的输出格式：（m为一个具体的数字） %md 可以使不足 位的 int 型变量以m位进行右对齐输出，其中高位用空格补齐。如果变量本身超过m位，则保持原样。 %0md 和上面的类似，只不过是用0而不是空格 %.mf 让浮点数保留m位小数输出，采用”四舍六入五成双“[4]的规则 2.2.3 getchar &amp; putchar获取和输出一个字符，注意getchar（）是可以识别换行的。 123456789101112131415161718int main(void){ char c1, c2, c3; c1 = getchar(); getchar(); c2 = getchar(); c3 = getchar(); putchar(c1); putchar(c2); putchar(c3);}//Input:ab(&lt;Enter&gt;)c/*Output:ac*/ 2.2.5 typedef可以给复杂的数据类型起一个别名1typedef long long LL;//之后就可以用LL代替long long了 2.2.6 常用的math函数需要#include 123456789//只能是括号中的类型（？）1. fabs（double x）————（float absolute value）给double型变量取绝对值2. floor(double x) &amp; ceil(double x) ————（地板和天花板）向下和向上取整3. pow(double r, double p)————（幂函数：power function）返回 r^p4. sqrt(double x) ————（Arithmetic square root）返回算数平方根5. log（double x） ————（Natural logarithm） 返回以自然对数为底数的对数值6. sin(double x) 、cos(double x)、tan(double x) ————可以用来精确定义pi的值：acos（-1.0）7. asin(double x) 、acos(double x)、atan(double x) ————反三角函数8. round(double x) ————（round：用整数表示的, 取整数的, 整数的）四舍五入取整 C语言中没有对任意底数求对数的函数，因此必须使用换底公式来将不是以自然对数为底的对数转换为以e为底的对数，即 log_ab = log_eb/log_ea注意：pow()可能导致错误的情况： 如果==底数 x 为负数并且指数 y 不是整数==，将会导致 domain error 错误。 如果底数 x 和指数 y 都是0，可能会导致 domain error 错误，也可能没有；这跟库的实现有关。 如果底数 x 是 0，指数 y是负数，可能会导致 domain error 或 pole error 错误，也可能没有；这跟库的实现有关。 如果返回值ret 太大或者太小，将会导致 range error 错误。 原文链接：https://blog.csdn.net/yuanbo_shaw/article/details/79511132 2.3 选择结构因为这部分的内容比较熟悉，就跳过了。 12345678910111213switch(表达式){ case 表达式1：//相当于switch中的语句的结构，如果匹配，则执行之后的语句 ... break; case 表达式2： ... break; ......... default: ....//注意每个case语句之后是没有大括号的！//break是用来结束当前switch语句的 对于for语句，在C语言中是不允许定义变量的，但是在C++中可以（将代码文件保存为.cpp的格式即可） 2.5 数组2.5.1 一维数组 数组的大小必须是整型常量，不能是变量。但是可以自己申请空间以定义数组1234567//Cint* a = (int*)malloc(sizeof(int)*n);free(a);//C++int* a = new int[n];delete[] a;//释放内存~~~ 当数组没有被初始化值的时候，一般默认是赋值为0，但是有时候有可能被赋值为很大的随机数 给数组赋值的方法： 1234int a[10] = {0};//这种方法只能用于将数组初始化为0int a[10] = {-1};//-1 0 0 0 0 0 0....(测试环境VS2019)fill (a, a + 10, -1);//初始化为-1，需要函数头algorithm和using namespace std;int a[10] = {};//初始化为0 2.5.2 冒泡排序本质上就是通过不断地交换减少数组中的逆序数对。在一遍遍历过程中，不断将较大的元素与相邻的元素进行交换。而最大的元素因为总是会比之后的元素更大，所以会被移到最后。1234567891011121314void BubbleSort(int a[],int n){ int sorted = false; while(!sorted){ sorted = true;//优化 for(int i = 1; i&lt;=n;++i){ if(a[i-1] &gt; a[i]){ int temp = a[i-1]; a[i-1] = a[i]; a[i] = temp; sorted = false; } } }} 2.5.3 二维数组123//二维数组想要作为参数传入函数中，需要确定二维数组的大小（至少是第二维需要确定）//二维数组的赋值方式int a[5][6] = {{3,1,2},{8,4},{},{1,2,3,4,5}};//剩余部分将会被赋值为0 注意：当数组大小较大时（数量级），需要将其定义在主函数外面，否则会使程序异常退出。 因为在函数内部申请的局部变量来自于系统栈，允许的空间较小；函数外部申请的全局变量来自静态存储区，允许申请的空间大。[6] 2.5.4 memset函数menset函数可以给数组中的每一个函数赋值，但是menset使用的是按字节赋值的，这就是说一个整型变量的四个字节都会被赋相同的值。 1234567891011//memset（数组名，赋值，sizeof（数组名））；int main(void){ int A[5] = { 1,2,3,4,5 }; memset(a, 1, sizeof(A)); for (int i = 0; i &lt; 5; ++i) { printf(\"%d\\t\", a[i]); }}//输出：16843009 16843009 16843009 16843009 16843009[5]//赋值为0或者-1（0的二进制补码为全0，-1的二进制补码为全1）//还可以用fill函数对数组进行赋值，但是执行速度较差。 这里每个字节的意思是每个字节都设为1，注意不要与每个位赋值弄混淆。因为int是8字节所以，调用menset之后，数组中存储的数字为：0000 0001 0000 0001 0000 0001 0000 0001.（1字节为8位） 2.5.5 字符数组输入：（scanf）%c:输入单个字符（能识别空格与换行并将其输入）%s:输入字符串并保存在字符数组中（以空格或者换行作为结束标志）（gets）输入一行字符串，以\\n作为结束标识。（getchar）获取输入额一个字符123456char str2 [5][10];//定义...for(int i = 0; i &lt; 3; ++i){ gets(str2 [i]);//运用这种方法将将输入的第一行赋值给数组的一整列}//输出格式类似，运用的函数为puts（与gets类似）注意：字符串是以‘\\0’（ASCII 为 0）作为结尾的，所以存储的长度应该比实际存储长度大一。==还有当用gets或者scanf函数的输入时，会自动在字符串尾部加上‘\\0’==，但是当用getchar函数（getchar每次只获取一个字符，所以’\\0’作为单独字符需要调用额外的getchar函数）时，一定要在每个字符串后面加上‘否则会出现乱码123456789char str[15];for (int i = 0; i &lt; 3; ++i) { str[i] = getchar();}puts(str);return 0;//Input:T^T//Output:T^T烫烫烫烫烫烫烫烫烫烫坍G醶\u0014?烫烫哎^v€麧//应该是程序不知道什么地方是结束 2.5.6 string.h头文件1234567#include&lt;string.h&gt;...char str1[10], str2[10];//代表字符数组strlen(str1)；//得到第一个'\\0'之前的字符个数strcmp(str1,str2)；//按照字典序比较（&lt;:返回负整数；=：返回0；&gt;：返回正整数）strcpy(tr1,str2);//str2复制给str1，包含'\\0'strcat(str1,str2);//(concatenate：把事物连接起来)str2接到str1后面 2.5.7 sscanf &amp; sprintf（都在stdio.h中）（补充） 123456789101112131415//这个函数的主要用途就是将字符数组的内容转化成整型，放到整型变量中int n;char str[100] = \"123\";sscanf(str, \"%d\", &amp;n);//相当于将str作为输入对象（类似于scanf的屏幕输入）printf(\"%d\\n\", n);//就像printf一样，只不过是将其打印到了一个字符串数组中去了double db = 3.1415;int n1 = 12;char str1[100], str2[100] = \"good\";sprintf(str1, \"%d:%.2f,%s\", n1, db, str2);//将这些元素输出给str1printf(\"str1 = %s\\n\", str1);//输出：// 123// str1 = 12:3.14,good 2.6 函数函数这部分也比较熟悉所以大部分省略了 1.数组可以作为参数，但是不允许作为返回类型出现 2.7 指针 指针（英语：Pointer），是编程语言中的一类数据类型及其对象或变量，用来表示或存储一个存储器地址，这个地址的值直接指向（points to）存在该地址的对象的值。 相关的操作有：&amp; ——取此变量的地址* ———取该地址对应的值指针变量的运算：加（减）代表的是指针指向前一个（后一个）存储块。看下面这个例子1234int* x, int y...x = &amp;y + 3 //结果是x存储的地址是y的地址+12//因为一个int类型占4个字节，所以这样总的来说就是向前移动了12个字节 在函数中，想要修改传入的值，就需要传入该变量的地址（传址访问），包括要修改指针变量也是需要将指针变量所对应的地址传进去。 注意：常量是不能被使用取址运算符。因为引用的对象必须是可以修改的左值，也就是说放常量被引用的时候，它并不能被修改，所以索性就不能被引用了。 在数组中，一下两种检索方式是等价的 12&amp; big_array[ 0 ] + i * sizeof( big_array[ 0 ]);//对地址直接修改&amp;big_array[ i ] = big_array + i;//通过指针运算（以下来自于《C程序语言设计2e》） Pointers and Arrays注意事项：1.(ip)++这里的括号是必要的，因为单元运算符像\\、++结合，是从右向左运算的。（一个准则，当你遇到不熟悉的运算符的时候，将所有可能出错的地方全部加括号） 2.在传参的时候，想要修改传入参数，需要传入参数的地址，例如swap(&amp;a,&amp;b)； 3.int a[num],这是在申请大小为num的数组，索引范围为0 ~ num-1 2.8 结构体（struct）的使用2.8.1 结构体的定义方式以及访问方式注意在结构体内不能用定义的结构体定义变量，但是可以定义指针类型。123456//结构体的定义方式struct structname{ int a;//成员变量 structname b;//不能定义自己本身（会引起循环定义的问题） structname* c;//可以定义自身类型的指针变量}A;//结构体变量，相当于 structname A；结构体内元素的访问方式：点运算符：”.“非指针变量的访问方式；指针运算符：”-&gt;“指针变量的访问方式。 2.8.3 结构体初始化构造函数是用来初始化结构体的一种函数。1234567891011121314151617181920212223//默认情况下构造函数是不显示的//但是想要自己重新定义构造函数，就不能不经初始化就定义结构体变量//想要同时实现二者，需要像以下这样定义构造函数//只要参数个数和类型不完全相同，就可以定义多个构造函数，以适应不同环境下的初始化struct studentInfo{ int id;char gender; studentInfo(){};//默认的构造函数 studentInfo(char _gender){//这里的变量名不能和外部的一样 gender = _gender; } studentInfo(int _id, char _gender){ id = _id; gender = _gender; }};//初始化方式studentInfo A;A = studentInfo(2021,\"girl\");//调用构造函数初始化//C++的另一种构造函数的方式studentInfo(int _id, char _gender):id(_id),gender(_gender){}; 2.9 补充内容2.9.1 cin 与 cout这两个输入输出函数虽然简洁（不用定义类型之类的）但是面对大量数据的时候，效率较低。123456//\"&gt;&gt;\"可以看成数据流的方向//多变量输入cin &gt;&gt; n &gt;&gt; db &gt;&gt; c &gt;&gt; str;//多变量输出cout &lt;&lt; n &lt;&lt; \"\\n\" &lt;&lt; db &lt;&lt; endl; 2.9.2 浮点数比较由于在计算机中采用有限位的二进制编码，因此浮点数在计算机中的存储并不总是精确的[8]。在经过大量运算之后，浮点数的精度可能会发生变化，这就给比较操作（&gt;、&lt;、=）产生了干扰。所以，我们定义一个极小数eps（通常取）,只要比较数落在特定的区间内（）即可。123//用宏定义等于const double esp = 1e-8;#define Equ(a,b) ((fabs((a)-(b)) &lt; (esp)))其他的比较运算符的所在区间如下图：还有几点需要注意： 经过大量的运算之后，一个变量存储的0可能是一个很小的负数，这时候使用sqrt函数就会报错，这时候就应该运用esp使变量保证在定义域内（*） 某些编译环境中，可能会输出-0.00.这是能将此输出放到字符串中，与“-0.00”比较，如果一致，那就加上esp修正这个值。 2.10 黑盒测试补充内容动态数组在定义数组之前，若数组大小未知，则需要对数组的空间进行申请1234567891011121314151617181920//一维数组//动态分配，数组长度为mint *array = new int [m];//释放内存delete[] array; //定义结构体动态数组并初始化#include&lt;iostream&gt;#include&lt;algorithm&gt;struct Mystruct{ int a, b;}int main(){ Mystruct* structs = new Mystruct[100]; Mystruct initializer = {20, 30}; fill(structs, structs + 100,initializer);} C语言的共生体参考：https://www.runoob.com/cprogramming/c-unions.html共生体是一种能在相同的内存位置存储不同的数据类型的一种特殊的数据类型。在共生体中能定义很多的不同的成员变量，但是任何时候只能有一个成员带有值。这样做可以节省空间，可以应用于变量不会同时使用的情况。 通信中的数据包会用到共用体:因为不知道对方会发一个什么包过来，用共用体的话就很简单了，定义几种格式的包，收到包之后就可以直接根据包的格式取出数据。 定义方式1234567891011121314union [union tag]{ member def; menber def; ....}[union variable(s)];//实例:成员变量可以是自定义的结构类型union Data{ int i; float f; char str[20];}data; 共用体占用的内存应足够存储最大数据类型成员。 访问共生体成员想要访问共生体成员需要使用点运算符。但是因为共生体所有的成员共用一个空间，所以在同一时间只能有一个成员变量能够拥有完整的赋值。123456//数据损坏union Data data;//这样只有data.str能够拥有完成的数据data.i = 10;//在后续的赋值过程中对应的内存被占用data.f = 220.5;strcopy(data.str, \"Union\"); 实例判断机器是大端机还是小端机12345678910111213141516union{ char str; int data;};data=0x01020304;if(str==0x01){ cout&lt;&lt; \"此机器是大端！\"&lt;&lt;endl;}else if(str==0x04){ cout&lt;&lt;\"此机器是小端！\"&lt;&lt;endl;}else{ cout &lt;&lt;\" 暂无法判断此机器类型！\"&lt;&lt;endl;} C 位域C语言提供了一种更好的利用内存空间的方式。这种方式可以告诉编译器你只用这些字节123456789101112struct{ unsigned int withValidated : 1;//只用一位来存储该变量 unsigned int heightValidated : 1;//后面的数字表示数据占用的空间的大小}status;struct{ unsigned int age : 3;}Age;Age,age = 7;//能够表示的最大值Age.age = 8;//输出的时候为0，溢出 枚举类型定义格式1234567891011121314enum name {eleName1, eleName2,....};enum DAY{ MON = 1,TUE,WED,THU,FRI,SAT,SUN}day;//1,2,3,4,5,6,7//enum DAY day;day = WED;printf(\"%d\",day);//3enum seasons{ spring, summer = 3, autumn, winter;};//0，3，4，5 友元函数 在面向对象编程中，友元函数（friend function）是一个指定类（class）的“朋友”，该函数被允许访问该类中private、protected、public的资料成员。普通的函数并不能访问这些资料，然而宣告一个函数成为一个类的友元函数则被允许访问这些资料。友元函数的宣告可以放在类声明的任何地方，不受访问限定关键字private、protected、public的限制。一个相似的概念是友谊类。友谊关键字应该谨慎使用。如果一个拥有private或者protected成员的类，宣告过多的友元函数，可能会降低封装性的价值，也可能对整个设计框架产生影响。 友元函数在类内部定义，可以在类外部定义。定义时在前面加上一个friend关键字12345678910111213class Box{ double width; public: double length; friend void printWidth(Box box);}void printWidth(Box box){ cout &lt;&lt; box.width &lt;&lt; endl;//访问私密成员} 重载 C++ 允许在同一作用域中的某个函数和运算符指定多个定义，分别称为函数重载和运算符重载。 重载函数应该有不同的输入参数，这样能够编译器会根据不同的输入参数确定函数的定义，这个过程叫做重载决策 函数重载123456789101112131415class printData{ public: void print(int i) { cout &lt;&lt; \"整数为: \" &lt;&lt; i &lt;&lt; endl; } void print(double f) { cout &lt;&lt; \"浮点数为: \" &lt;&lt; f &lt;&lt; endl; } void print(char c[]) { cout &lt;&lt; \"字符串为: \" &lt;&lt; c &lt;&lt; endl; }}; 运算符重载 重载的运算符是带有特殊名称的函数，函数名是由关键字 operator 和其后要重载的运算符符号构成的。与其他函数一样，重载运算符有一个返回类型和一个参数列表。 12345//将两个Box类相加Box operator+(const Box&amp;, const Box&amp;);Box box1, box2, box3;....box3 = box1 + box2; 文件（C++PrimerPlus）文件本身就是一连串的存储在设备当中的字节。 文件输入和输出文件输出流的类包含在文件头fstream（fstream.h）中。下面是写入文件的步骤： 创建一个ofstream对象 将这个对象链接到特定的文件 用输入输出流控制命令，对文件中的字节进行操作 打开一个文件可以用open()方法1234567//创建文件对象ofstream fout;//将文件对象与特定文件相互链接fout.open(\"jar.txt\");//或者在定义对象的时候初始化链接ofstream fout(\"jar.txt\");文件对象在输入或者输出的时候，会对每一个文件对象设立一个缓冲区，这个缓冲区存储输入的字节，当缓冲区满了以后，再将其中的内容转换到文件中。这种以缓冲区为单位一块块地传输字节，极大地提升了文件处理的速度。读取文件中的内容123456char ch;fin &gt;&gt; ch;char buffer[80];fin.getline(buffer,80);//getline在string函数头中string line;getline(fin, line);可以用close方法，断开文件对象与文件的链接，这样能够保证文件缓冲区就会被刷新，这样保证了文件会被实时更新。下面是对文件的输入操作的实例。1234567891011121314151617181920212223242526void fileio17_16() { string filename; cout &lt;&lt; \"Enter name for new file: \"; cin &gt;&gt; filename; ofstream fout(filename.c_str());//将C++的string类型转换成C语言的char数组，返回一个数组指针 fout &lt;&lt; \"For your eyes only!\\n\"; cout &lt;&lt; \"Enter your secret number:\"; float secret; cin &gt;&gt; secret; fout &lt;&lt; \"Your secret number is \" &lt;&lt; secret &lt;&lt; endl; fout.close(); ifstream fin(filename.c_str()); cout &lt;&lt; \"Here are the contents of \" &lt;&lt; filename &lt;&lt; \":\\n\"; char ch; while (fin.get(ch)) cout &lt;&lt; ch; cout &lt;&lt; \"Done\\n\"; fin.close(); //return 0;} 总结（主要记录遇到的问题） 1.想直接赋值字符串而不是字符(Solved) 字符串常量可以作为初值赋给字符型数组，并用%s输出123&gt;char strl[25] = \"cser\";&gt;printf(\"%s\", strl);&gt;//对于字符串型可以转化成字符数组，但是不能赋值给字符变量 2.用VS2019编译sanf无法通过，出现C4996错误。(Solved) 在 Visual Studio 中关闭项目的警告：打开项目的 “属性页” 对话框。 选择 “配置属性” “ &gt; c/c + + &gt; 高级” 属性页。编辑 “禁用特定警告” 属性以添加 4996 。 选择 “确定” 以应用所做的更改。 3.浮点型的有效精度（？）4.“四舍六入五成双”规则？5.menset按字节赋值？6.系统栈&amp;静态存储区？7.正则表达式？8.浮点数不总是精确的详细原因","link":"/2020/12/31/%E3%80%8A%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E3%80%8B%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86C-C-%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/"},{"title":"命令笔记","text":"linux 命令12345678910111213141516171819pwd # Present Working Directorytar &lt;options&gt; &lt;filename&gt; # Tape ARchiverm -rf # 删除文件夹以及其中的内容cat -n # 查看文件中的内容，-n加上行序号less # 可以滚动查看， 输入q退出grep &lt;pattern&gt; &lt;file&gt; # -v: 不包含模式的字串， -R递归地查找chmod 777 -R &lt;dir_name&gt; # 将文件夹以及其目录中的所有文件的访问权限全开cd - # 上次目录head # 查看文件开头file # 查看文件属性${var#week} # 将var头部的week删掉，$会去除末尾的字符lsof -i:9008 # 检查9008端口是否开放## ----- g++ -------# - 这样做的好处是当某一个链接文件改动的时候，不需要重新编译所有的文件g++ filename.cpp -c # 只编译不运行g++ *.o -o main # 将编译的文件链接 Makefile1234567891011121314151617181920212223242526272829303132333435make -f fileName # fileName 你指定的makefile文件# make通过修改文件的时间戳来判断文件是否被更新## ---------------一个编译实例----------# 增量编译(只重新编译修改过的文件)CXX = g++TARGET = helloOBJ = main.o printhello.o factorial.o # 声明依赖# 设置编译模式$(TARGET) : $(OBJ) $(CXX) -o $(TARGET) $(OBJ)# 依赖项的来源，通过g++编译而来main.o: main.cpp $(CXX) -c main.cpp## ----------第三个版本-----CXXFLAGS = -c -Wall # Wall： warning all$(TARGET) : $(OBJ) $(CXX) -o $@ $^ # @: TARGET, ^:OBJ# ----------统一的规则------------## $&lt;: 表示依赖中的第一个， $^: 代表所有的依赖%.o: %.cpp $(CXX) $(CXXFLAGS) $&lt; -o $@.PHONY: clean # 防止出现文件叫clean。这里生成一个依赖于clean的项目，但是什么都不做clean: rm -f *.o $(TARGET)## -----------版本4----------SRC = $(wildcard *.cpp) # 当前目录下的所有.cpp文件都放到变量SRC中OBJ = $(patsubst %.cpp, %.o, $(SRC)) # 把SRC中的.cpp文件替换成.o然后存储到OBJ中 CMake文件名：CMakeLists.txt12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# 由于cmake会生成大量的临时文件，所以最好将cmake的过程放在build# 文件下，这样清除的时候会比较方便cmake_minimum_required(VERSION 3.10) # 需要的cmake的最低版本project(hello VERSION 1.0) # 项目名称以及对应的版本号# 配置头文件将版本号传递给源代码configure_file(TutorialConfig.h.in TutorialConfig.h)# TutorialConfig.h 文件会被自动写入 build 目录，需要将目录加入到搜索头文件的路径列表中（以下添加到CMakeList.txt文件末尾）target_include_directories(${PROJECT_NAME} PUBLIC ${PROJECT_BINARY_DIR})# PROJECT_BINARY_DIR 表示当前工程的二进制路径，即编译产物会存放到该路径，此时PROJECT_BINARY_DIR 就是 build 所在路径。# -------------TutorialConfig.h.in ----------------// the configured options and settings for Tutorial#define Tutorial_VERSION_MAJOR @Tutorial_VERSION_MAJOR@#define Tutorial_VERSION_MINOR @Tutorial_VERSION_MINOR@# -------------TutorialConfig.h.in ----------------#-----------------------------------------# 以后可以通过这个头文件查看版本信息，MAJOR.MINOR# cmake 构建之后，会在build中生成一个TutorialConfig.h文件// the configured options and settings for Tutorial#define Tutorial_VERSION_MAJOR 1#define Tutorial_VERSION_MINOR 0# ------------TutorialConfig.h---------------# 生成hello程序，后面的是依赖的文件add_executable(hello main.cpp factorial.cpp printhello.cpp)## -------- 外部构建 --------# --build 指定编译生成的文件存放目录，其中就包括可执行文件，. 表示存放到当前目录cmake --build .cmake .. # .. 是CMakeLists.txt的存放路径## ------- 使用变量 --------set(SRC_LIST a.cpp b.cpp c.cpp) # 将多个文件用一个变量保存set(CMAKE_CXX_STANDARD 11) # 设置c++11标准set(CMAKE_CXX_STANDARD_REQUIRED True)add_executable(${PROJECT_NAME} ${SRC_LIST})## -------------添加库---------------# MathFunctions/CMakeLists.txtadd_library(MathFunctions mysqrt.cpp) # 添加一个叫 MathFunctions 的库文件## 顶级CMakeLists.txt # add the MathFunctions library add_subdirectory(MathFunctions) # add the executable add_executable(${PROJECT_NAME} tutorial.cpp) target_link_libraries(${PROJECT_NAME} PUBLIC MathFunctions) # add the binary tree to the search path for include files # so that we will find TutorialConfig.h target_include_directories(${PROJECT_NAME} PUBLIC ${PROJECT_BINARY_DIR} ${PROJECT_SOURCE_DIR}/MathFunctions ) gdb12345678910111213info s # 查看栈信息info r # 查看寄存器信息info local # 查看局部变量bt # 查看调用栈disas # 查看汇编代码， 可以指定函数x/[count][format] [address] # 打印内存值 - x/s 0x402400 # 打印在地址0x402400中的值，转换成stringrun res.txt # 后面可以加上传入的参数stepi # 二进制中的一步fs next # 切换关注的窗口，gdb或者命令行窗口condition 1 item_to_remove==1 # 为断点添加一个条件backtrace # 查看错误栈 快捷键1ctrl + L: 刷新gdb页面 快捷键（Linux）1ctrl + D: 结束当前任务 docker 命令12345678# 开启dockerdocker start user_name# 进入dockerdocker attach user_name# 打开ssh服务(进入对应的docker之后)service ssh start Git \\text{工作区}\\stackrel{add}{\\rightarrow}\\text{暂存区}\\stackrel{commit}{\\rightarrow}\\text{本地仓库}\\stackrel{push}{\\rightarrow}\\text{远程仓库}\\stackrel{pull}{\\rightarrow}\\text{本地} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# In the work directorygit config --global user.name \"yourName\"git config --global user.email yourEmailgit init # initialize the repositorygit status # repository informationgit add fileNamegit commit -m \"commit msg\"EADADWEgit log # 查看以前的版本touch .gitignore # 不追踪的文件# 创建新分支git branch branchName# 两种切换分支的命令git checkout branchName - git checkout -d branchName # 删除分支 - git checkout -b temp # 创建并切换到新建的分支git switch branchName# 合并分支git merge temp# add 和 commit合在一起写git commit -a -m \"msg\" # 或者-am# 提交git push -u &lt;remote_branch&gt; &lt;loacal_branch&gt;# 添加远程分支（命名为origin）git remote add origin https:****.git# 下载远程内容#### 直接下载zip是不会下载版本信息的，所以需要使用以下命令git clone# 总结echo \"# learningGit\" &gt;&gt; README.mdgit initgit add README.mdgit commit -m \"first commit\"git branch -M maingit remote add origin https://github.com/Baymine/learningGit.gitgit push -u origin main# 解决冲突## 建立分支git checkout -b my_feature## 检查差异（与main branch之间的差异）git diffgit merge &lt;branch&gt; # 合并分支，如果有冲突就选择放弃或者保留改动# 不同分支中保存不同的内容，可以从远端pull最新的内容到本地 ESDAW","link":"/2022/11/08/%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0/"},{"title":"《算法笔记》第四章：算法初步（算法思想）","text":"Learn to learn1.Whenever I tackle a new subject, one of my first thoughts is what kind of structure am I trying to build. What would be the input situations that should cause me to remember this knowledge? How do I need to manipulate it, discriminate between similar-seeming situations, calculate or reason with it?2.When my end goal is to solve a practical problem, I should begin thinking about applications. 排序算法选择排序：从无序表中选择最值元素，放到有序表的末端插入排序：将无序表中的以一个元素插入到有序表中的相应的位置 sort 函数C语言：qsort函数 C++：sort函数（方便，推荐使用，需要加上#include &lt;\\algorithm\\&gt;和using namespace std;） 1234567891011121314151617181920212223//函数模板sort(首元素地址,尾元素地址,比较函数（可选项）)；//比较char类型时，默认按照字典序//之后的cmp函数（Compare）可以自定义，以达到不同的排序效果，默认情况下是从小到大//实现从大到小输出bool cmp(int a, int b) return a &gt; b;.....sort(a, a + 4, cmp);//从大到小排序//*原因？*//对结构体数组的排序struct node{ int x,y;}ssd[10];//编写cmp函数bool cmp(node a, node b){ if(a.x != b.x) return a.x &gt; b.x; esle return a.y &lt; b.y;//如果x相等则按照y的值进行排序}//容器的排序（vector、string 、deque）sort（vector.begin(),vector.end(),cmp）;//可以调用相应的方法作为排序的标准 散列散列是典型的运用空间换时间策略的方法，就是将数据存储在一个更加容易访问的数据结构中，例如数组。可以将数组的下标和数组中存储的元素结合起来，这样可以根据下标的信息直接访问数组内的信息。根据映射的方式不同，散列分为不同的类型。 线性散列就先上面的例子一样，直接将数组内的信息与数组的下标相结合，这样查询的时间复杂度将为O(1) 取留余数法把关键值除以某个数之后的余数作为散列的关键值。H_{(key)}=key \\% mod当取mod是一个素数的时候，可以尽可能地覆盖[0, mod)范围内的所有数，还有为了不越界，数组的大小应该不小于mod。当两个数与一个数的模相等的时候，这时候就产生了冲突。 线性探测法检查的情况。这种方法易产生扎堆，在一定程度上会降低效率 平方探查法检查、(先正后负)如果超出了边长，则把对表长进行取模。如果出现小于零的情况(其中TSize为表长)为了避免负数出现的麻烦，可以只进行正向的平方探测。 链地址法将哈希值相同的元素连接成一个单链表，表头元素就是数组的元素 在标准模板库中，有map可以直接使用hash表的功能（C++11以后可以用unordered_map，速度更快）。另外将一对或者是多对的整数映射成一个整数的方法可以是像十进制数那样，一个数字代表十位一个代表个位。（） map的常见用法map函数可以将任何类型映射到其他的任何类型（包括容器），使用map函数需要添加\\头文件，需要加上using namespace std;123456789101112131415161718//定义一个map#include &lt;map&gt;using namespace std;map&lt;映射前的类型，映射后的类型&gt;容器名称//注意一点，如果是字符串到整型的的映射必须是string而不能使用char数组map&lt;char, int&gt;mp;//map容器的访问方式//通过下标访问mp['c'] = 20;//注意这个是唯一的，后续的赋值会覆盖原先的值//运用迭代器//迭代器定义map&lt;typename1, typename2&gt;::iterator it;//这两个类型名称是定义map时定义的变量类型//访问键值it-&gt;first;it-&gt;second;//遍历map中的所有键值的循环for(map&lt;char,int&gt;::iterator it = mp.begin(); it != map.end();it++){...}//map是使用红黑树实现的，会以键从小到大的顺序自动排序 map常用函数 函数名 功能 时间复杂度 find(key) 返回键为key的映射的迭代器 O(logN) N为映射个数 erase() 删除一个元素、删除一个区间内的所有元素 传入迭代器：O(1)传入键值：O(log(N))（N为map中的元素个数） size() 获得map中映射的对数 O(1) clear() 清空map中所有的元素 O(N) 123456789101112131415//运用范例#include &lt;stdio.h&gt;#include &lt;map&gt;using namespace std;int main(){ map&lt;char, int&gt;mp; mp['a'] = 1; mp['b'] = 2; map&lt;char, int&gt;::iterator it = mp.find('b'); mp.erase(it); mp.erase('b');//与上面的作用相同 mp.erase(it, mp.end());//传入删除的区间 mp.size(); mp.clear();} 字符串哈希12345678910111213141516171819202122232425262728//将字母映射成十进制数//算法思想：将26个字母看成26进制数，然后转换成相应的十进制数，转换过程为：//个位数加上更高位数乘以进制数，这个可以类比十进制数的构成，因为传入的时候是从高位开始的（从左向右读取），//所以可以将每一次输入的数字都是在个位数，其他的按照进制数倍增int hashFunc(char S[], int len) { int id = 0; for (int i = 0; i &lt; len; ++i) { id = id * 26 + (S[i] - 'A');//个位数+更高位数*进制数 printf(\"%d\\n\", id); } return id;}//当还遇到小写字母的时候int hashFunc(char S[], int len){ int id = 0; for(int i = 0; i &lt; len; ++i){ if(S[i] &gt;= 'A' &amp;&amp; S[i] &lt;= 'Z'){ id = id * 52 + (S[i] - 'A'); } else if(S[i] &gt;= 'a' &amp;&amp; S[i] &lt;= 'z'){ id = id * 52 + (S[i] - 'a') + 26;//注意这里加上的26，是因为在这个52进制当中，大写字母在前面 //类比十进制， 8 = 3 + 5； } } return id;}//如果还出现了数字，则将进制数扩大到62 递归分治这种思想让我想到了一个成语：众人拾柴火焰高。将”火焰高“这个目的划分成“众人拾柴”，这个规模较小而与原问题相似的子问题。这包含分治思想的三个方面：首先将一个问题进行分解，然后求解子问题，最后将问题的结果合并成原问题的结果。这样的话你只需要专注于一个小问题就可以。当然，子问题应该是相互独立的、没有交叉的。 递归 这实际上是一种分治思想，这样做的结果就是只需要专注于一个小问题即可，但是与之前“拾柴”的的例子不一样，之前的像是单层的分解，但是递归应该是多层次的。 在使用递归的时候应该注意两点，递归式和递归边界。这也就是怎么划分和划分到什么地步的问题。 下面是求解全排列的问题：在全排列问题中，每一个元素只有两种状态，被选和没有被选，只需要所有的元素的这两种状态全部遍历一遍就可以了。在选和不选中做抉择，可以将所有情况画成一棵树，这棵树就叫做决策树 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//全排列，字典序//头部应该是不断更新的，也就是子排列中的头部/*算法思想：先确定排列的首部，然后剩下的子序列做同样的操作，这样就可以将问题不断减小。*/#include &lt;cstdio&gt;const int maxn = 11;int n;//待排元素的个数int p[maxn];//存储当前排列int hashTable[maxn] = { false };//判断索引元素是否在排列数组中int count = 0;//统计全排列的个数//处理排列的idex号位void generateP(int index){ //这是递归边界，前面的元素全部排列完毕，现在是要将数组输出 if (index == n + 1) { for (int i = 1; i &lt;= n; ++i) { printf(\"%d\", p[i]); } printf(\"\\n\"); return; } //遍历检查所有的元素，这里引用了外部的变量n，由主函数定义（作为参数是不是好点？） for (int x = 1; x &lt;= n; ++x) { //哈希表是来表示索引元素是否已经加入数组了 if (hashTable[x] == false) { p[index] = x;//以x作为头部的时候 hashTable[x] = true;//更新状态 //这里是继续下一位，注意这里还没有将哈希表重置，所以原先作为首部的元素是不会再被赋值了 generateP(index + 1); hashTable[x] = false;//完成递归项中的一个，重置状态 } } count++; return;}int main() { n = 9;//表示输出1~3的全排列同时还表示全排列的数组元素个数 generateP(1);//表示从P[1]开始 printf(\"\\n%d\", count); return 0;} 在一点条件下，之后的实例都无法满足要求，这时候可以直接退出该层递归，返回上一层。这种方法成为回溯1234567891011121314151617181920212223242526272829303132333435//n皇后问题，n*n的格子中，放入n个皇后，这n个皇后不能在同行、列、对角线#include&lt;cstdio&gt;#include&lt;cmath&gt;const int maxn = 11;int n;//待排元素的个数int p[maxn];//存储当前排列int hashTable[maxn] = { false };//判断索引元素是否在排列数组中int count = 0;//统计全排列的个数void generateP(int index) { if (index == n + 1) { count++; return; } for (int x = 1; x &lt;= n; x++) { if (hashTable[x] == false) { bool flag = true; for (int pre = 1; pre &lt; index; pre++) { //检查是否在同一对角线上，注意进入if语句之后该次循环就会被跳过 if (abs(index - pre) == abs(x - p[pre])) { flag = false; break; } } if (flag) { p[index] = x; hashTable[x] = true; generateP(index + 1); hashTable[x] = false; } } }} 贪心用局部最优来达到全局最优的结果。分为在线算法（Online Algorithms）和离线算法（Offline Algorithms），可以证明在线算法无法得到最优解。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106//B1020月饼//忽略最后注释部分#include&lt;cstdio&gt;#include&lt;algorithm&gt;using namespace std;struct mooncake { double store; double sell; double price;}cake[1010];//定义函数的时候一定要大括号bool cmp(mooncake a, mooncake b) { return a.price &gt; b.price;}int main(void) { int n;//月饼种类 double D;//市场需求量 scanf(\"%d%lf\", &amp;n, &amp;D); //初始化库存 for (int i = 0; i &lt; n; ++i) { //少些%不会报错，但会出错 scanf(\"%lf\", &amp;cake[i].store); } //初始化利润 for (int i = 0; i &lt; n; ++i) { scanf(\"%lf\", &amp;cake[i].sell); cake[i].price = cake[i].sell / cake[i].store;//计算单价 } //将数组由根据单价由大到小排列 sort(cake, cake + n, cmp); double ans = 0;//最大利润 //枚举各种月饼 for (int i = 0; i &lt;= n; ++i) { //检查是否满足市场需求量 if (cake[i].store &lt;= D) { D -= cake[i].store;//更新需求量 ans += cake[i].sell; } else { ans += cake[i].price * D; break; } } printf(\"%.2f\\n\", ans); return 0;}/*算法思想：先算出单价利润最大的月饼，然后将对应的全部卖出，要考虑的需要较为进阶的语言知识，现阶段还是不要这样做为好，直接定义最大的情况下的数组即可*//*#include&lt;cstdio&gt;struct MoonPie{ int rep;//库存 int profit;//利润 MoonPie(){}; MoonPie(int _rep){ rep = _rep; } MoonPie(int _profit){ profit = _profit; } int value = profit / (double)rep;};int main(void){ int n;//月饼种类 int re;//需求量 int profit,rep; in maxValue = 0;//最大单价 scanf(\"%d %d\",&amp;n,&amp;re); //输入数据，定义动态数组， int *p = new int[n]; //找出单个利润最大的月饼 //初始化数据 for(int i = 1; i &lt;= n; ++i){ scanf(\"%d\",&amp;rep); p[i] = MoonPie(rep); } for(int i = 1; i &lt;= n; ++i){ scanf(\"%d\",&amp;profit); p[i] = MoonPie(profit); } for(int i = 1; i &lt;= n; ++i){ if(maxValue &lt; p[i].value) maxValue = p[i].value; } //比较市场需求量和库存，计算最终的利润}*/ 二分二分查找12345678910111213int binarySearch(int A[],int left, int right, int x){ int mid;//查找区间的中间的位置 while(left &lt;= right){ mid = (left + right)/2; if(A[mid] == x) return mid;//找到 //更新查找区间 else if(A[mid] &gt; x)right = mid -1; else left = mid + 1; } return -1;}//当查找范围较大时，（left+right可能会越界）这个时候可以用mid = left+(right-left)/2 代替 当查找的元素数组中包含重复的元素时，这也就是说目标元素在数组中可能不止一个，这个时候就应该返回目标元素所在的区间。算法的总体思路：对于一个有序表，找出第一个与目标元素相等的位置和第一个与目标元素不相等的位置，得到对应的区间1234567891011121314//找出目标数组的上界，第一个大于等于x的元素的位置//注意在这里二分法的上界是n因为当x不存在的时候，位置范围可能在数组范围之外的那个元素的位置int lower_bound(int A[],int left, int right, int x){ int mid; //注意这个判断条件，只是确定x的范围，对x是否存在并不关心（？） while (left &lt; right){ mid = (left + right) / 2; if(A[mid] &gt;= x)right = mid; else left = mid +1; } return left;}//同样的求目标元素的上界，即数组元素第一次与目标元素不相同的时候，与求下界的函数相比，主要的区别就在于//判断语句中少了等于，这样当指向这个数组元素的时候，就会继续进行原先的步骤,因为这个函数的主要目的就是找到第一个与目标元素不相等的元素的位置二分查找的思想本质上就是利用目标左右两端的情况，来不断调整范围，以实现向目标趋近的目的。所以，二分法不仅仅可以用于查询满足条件的目标，还可以求目标的近似。下面是一个求的近似值 的例子12345678910111213141516171819202122/*算法思想：考虑函数f(x) = x^2，想要求sqrt(2),只需要找到函数值趋向于2的数即可。先比较区间中点mid的与f(x)的大小，若mid&gt;f(x), 则从[left,mid]中去寻找，其他情况类似，直到达到想要的精度*/const double esp = 1e-5;//需要的精度double f(double x) return x * x;//关系函数double calSqrt(){ double left = 1, right = 2, mid;//左、右区间范围，中间元素指针 while(right - left &gt; esp){//检查是否满足精度 mid = (left + right)/2; //更新区间信息 if(f(mid) &gt; 2)right = mid; else left = mid; } return mid;}//这本质上就是求解一个方程，因为算法只能逼近与一个点，所以需要在区间内只有一个目标，或者说保证二者的关系是单调的 快速幂 题目描述：给定三个正数a、b、m（a&lt;),求） 算法分析:因为数字的数量级太大，直接通过循环来求解需要的时间会很多（时间复杂度为O(n)）,可以借用快速幂的方法： a^b=\\left\\{ \\begin{aligned} \\ a *a^{b-1} （b为奇数）\\\\a^{\\frac b2}*a^{\\frac b2}（b为偶数） \\\\ \\end{aligned} \\right.这样可以将幂次的乘积进一步减少123456789101112131415161718//快速幂的递归形式typedef long long LL;//参数分别为底数、指数、模数LL binaryPow(LL a, LL b, LL m){ if(b == 0)return 1;//递归出口 if(b % 2 == 1) return a * binaryPow(a, b - 1, m) % m; else { LL mul = binaryPow(a, b / 2, m); return mul * mul % m; }}//if(b % 2 == 1)还可以这样写if (b &amp; 1)代替，后者就是检查b的二进制形式的最后//一位是否是1，是则为奇数，否则为偶数//还有注意返回时不要写：return (binariPow(a, b / 2, m) * binariPow(a, b / 2, m)) % m;//因为这样会导致额外的运算 To Be Continue… 双指针双指针法分为两种，一种是首尾指针，一种是快慢指针，前者用于 归并排序快速排序其他高效技巧与算法回溯（动态规划）动态规划的关键就是将一个问题划分成几个相互之间有交集的子问题。典型的问题就是求最优解的问题，可以从前到后，不断将最优的解放到数组中，这样要求解该轮下的最优解，只需要将所有情况都试一遍，然后比较出最优的那一个即可。这个过程就像是遍历一棵树，找到最优子节点，然后以子节点作为头节点继续遍历，直到满足条件。 动态规划问题的分析模式： 1.分析最优解的结构2.递归地定义最优解的值3.计算最优解（从低向上）4.展示结果 123456789101112131415161718192021#找出数组中两两不相邻的数字的最大值def de_opt(arr): opt = np.zeros(len(arr)) opt[0] = arr[0] opt[1] = max(arr[0], arr[1]) for i in range(2, len(arr)): A = opt[i-2] + arr[i] B = opt[i-1] opt[i] = max(A,B) return opt[len(arr) - 1]#递归写法def rec_opt(arr, i) if i == 0: return arr[0] elif i == 1: return max(arr[0], arr[1]) else: A = rec_opt(arr, i - 2) + arr[i] B = rec_opt(arr, i - 1) return max(A, B) 回溯（sù）：将选择一种情况作为一个结果，然后将不选择该情况作为另一个结果，找出两种情况的最优解，得到局部的最优解。","link":"/2021/02/27/%E3%80%8A%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E3%80%8B%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E7%AE%97%E6%B3%95%E5%88%9D%E6%AD%A5%EF%BC%88%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3%EF%BC%89/"},{"title":"《算法笔记》第十一章(动态规划)","text":"@[toc] 动态规划介绍动态规划（Dynamic Programming)用于解决一类最优化问题。它将一个问题划分成几个相同的子问题，通过找到子问题的全局最优解，得到整个问题的最优解。DP与贪心算法的主要区别是：贪心算法选用的是当前步骤的最优解，但是DP采用的是当前子问题的全局最优解。DP因为每一步都是当前子问题的全局最优解，所以最后的一个子问题（原问题）也是全局最优解。而贪心算法由于是局部最优解，所以只能得到一个局部最优解。在动态规划的一类问题中，子问题之间会出现重叠子问题，为了避免重复计算，可以用一个数组变量作为备忘录，记录当前的子问题的最优解。下面是求解斐波那契数列的问题：1234int F(int n) { if (n == 0 || n == 1)return 1; else return F(n - 1) + F(n - 2);}可以注意到在求解最终结果之前，这个算法花费了大量的时间去计算一些重复的问题，因为，所以在完成第一个递归的时候，其实第二个递归式已经被计算过了，所以可以将这个结果利用起来。12345678910111213141516171819202122232425#define MAXN = 10 int F(int n) { //将数组初始化为-1.表示该结果未被计算 int*dp = new int[n]; fill(dp, dp + n, -1); if (n == 0 || n == 1)return 1; if (dp[n] != -1)return dp[n]; else { dp[n] = F(n - 1) + F(n - 2); return dp[n]; } } //当只需要第n个斐波那契数的时候，使用三个变量滚动更新即可 int F(int n) { if (n == 1 || n == 0)return 1; //三个变量分别表示F(n-2)、F(n-1)、F(n) int a = 1, b = 1, c = 0; for (int i = 2; i &lt;= n; ++n) { c = a + b; a = b; b = c; } }通过记忆之前的计算结果，避免了重复子问题的求解，从而使求解的时间复杂度由原先的O()转变成O()。 递推写法现在看一个数塔问题，需要求解从顶层到最底层的所形成的最大的数字。如下图：从最顶层开始，我们先假设下一层的各个元素到最低层所形成的最大数字都已经知道了，并且存放在一个二维数组中。在上图中，最顶层的元素到最层的所形成的最大数字可以表示为： dp[1][1] = max(dp[2][1],dp[2][2]) + val[1][1]其中，dp存放各节点到最底层形成的最大数字，val存放当前节点的所存储的值。 同样的，每一个子问题的求解也可以用与头节点相同的方法进行求解。所以可以得到一个状态转移方程： dp[i][j] = max(dp[i+1][j],dp[i+1][j+1]) + val[i][j]这样就得到了一个上下层之间的关系式。这也就是说我们可以利用下层的结果来求解上层！又注意到，最底层节点到最底层节点所能形成最大的数字就是其本身！所以通过自底向上（Bottom-up）的方法，可以逐步向上求解的最终的问题的答案！这种算法的分析模式似乎就是从上往下分析最优解的结构，从下往上求解最优解。12345678910111213int dp[maxn][maxn];int numTower(int f[maxn][maxn]){ //边界 for(int j = 1; j &lt;= n;++j){ dp[n][j] = f[n][j]; } //向上更新各节点的最优结果 for(int i = n -1; i &gt;= 1; i--){ for(int j = 1; j &lt;= i;j++){ dp[i][j] = max(dp[i + 1][j],dp[i + 1][j + 1]) + f[i][j]; } }}这一类问题有一个共同点，那就是拥有最优子结构(Optimal Structure)，通过这个最优子结构可以构造出这个问题的最优解。这样一个问题想要用动态规划进行求解，需要满足两个条件：拥有重叠子问题和最优子结构。前者是发挥动态规划优势条件，后者是产生状态转移方程的条件。递归与递推的写法在本质上是一致的，但是在写法上存在一些区别，递归是通过向下递归，一步步得到最优解的（就像是先利用还未被解出来的结果）所以是自顶向下的。而递推需要一步步获得子问题的最优解（就像是利用的是求解出来的结果），所以是自底向上的。 最大连续子序列和问题描述： 给定一个数字数列,求，，使得最大，输出这个最大和 暴力解法首先可以采用枚举的方式，从第一个元素开始。让固定，让指针向后移动，统计最大值，然后将向后移动，重复上面的操作。这样枚举过程需要的时间复杂度为，加上求和过程中的复杂度为，总复杂度为,如果用数组记住原先的计算结果，通过推算求得子序列的和，那么总复杂度为. 动态规划将作为以结尾的、和最大的连续子序列，这样的取值为： dp[i] = max\\{A[i],dp[i-1]+A[i]\\}这也就是选择加或者不加之前元素的序列，看看哪个序列和更大。1234567891011121314151617181920212223242526272829303132#include &lt;cstdio&gt;#include&lt;algorithm&gt;using namespace std;const int maxn = 10010;int A[maxn], dp[maxn];void sumOfserial() { //输入 int n; scanf(\"%d\", &amp;n); for (int i = 0; i &lt; n; ++i) { scanf(\"%d\", &amp;A[i]); } //边界 dp[0] = A[0]; //更新状态数组 for (int i = 1; i &lt; n; i++) { dp[i] = max(A[i], dp[i - 1] + A[i]); } //找到最大的结果所在的位置 int k = 0; for (int i = 1; i &lt; n; ++i) { if (dp[i] &gt; dp[k]) k = i; } //输出结果 printf(\"%d\\n\", dp[k]);} 最长不下降子序列（LIS）LIS(Longest Increasing Sequence)问题描述 在一个数字序列中，找到一个最长的子序列（可以不连续），使得这个序列是不下降（非递减）的。 暴力求解如果采用暴力解法，即每个元素都有两种情况，加入子序列或者是不加入子序列，将每一个元素进行枚举，找出最长的LIS，更新最大长度，但是这样的时间复杂度为O()。 动态规划现在尝试使用动态规划进行求解。将当成以结尾的LIS，将第个序列元素作为，想要找到最长的序列，就需要遍历之前的所有，尝试将加入到这个子序列中，看是否能形成更大的LIS。所以的状态转移方程为： dp[i] = max\\{1, dp[j]+1\\}\\\\(j = 1,2,....,i-1 \\&\\& A[j]","link":"/2021/03/25/%E3%80%8A%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E3%80%8B%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"title":"机器学习中的数学: When Models Meet Data","text":"Data, Models, and LearningThe title contains three major components of a machine learning system. Data as VectorsFirst, we need to make information as number, so as to we can use it as training data. Models as FunctionsThere are two main school relative to the machine learning, function and probabilistic model. The former one gives a specific value, the later one would give the distribution of the result.And in order to value a model, we use cost function or loss function to discribe it. 经验风险最小化（Empirical Risk Minimization）本节主要探讨几个问题：那些函数可以被用作预测函数？如何衡量一个模型的好坏？如何让一个从已知训练集中训练出来的模型很好地预测未见得数据？在找合适的模型时，应该遵循什么样的步骤？ 假设函数的种类（Hypothesis Class of Functions）我们训练的目的是找到一个参数列表,使得函数的输出结果能够更接近真实值，即： f(x_n,\\theta^*)\\approx y_n\\quad for \\ all\\ \\ a = 1,\\cdots,N在本节中使用代表模型的预测值。 代价函数(Loss Function for Training)经验风险（empirical risk）：真实值与预测值的偏差 对于一个给定的训练集,实例矩阵（example matrix）：,标签矩阵,对应的平均损失为： R_{emp}(f,\\boldsymbol X, y)=\\frac{1}{N}\\sum\\limits^N_{n-1} l(y_n,\\hat y_n)我们希望模型不仅仅能够很好地拟合训练数据，还希望模型能够很好地预测数据，所以能够找到一个期望风险（Expected Risk） \\bold R_{true}(f)=\\boldsymbol{\\mathbb E_{x,y}}[l(y,f(\\boldsymbol x))]正则化减小过拟合(Regularization to Reduce Overfitting)如果有足够的参数，给定地模型一般能够很好地拟合测试数据，但是预测数据却与实际数据有较大的偏差，这时候就是模型发生了过拟合。一般情况下，已知的数据分为测试数据和训练数据，分别用于测试和训练模型。 Regularization is a way to compromise between accurate solution of empirical risk minimization and the size or complexity of the solution.对于一个最小二乘问题：,加上正则项则是： \\min\\limits_\\theta\\frac{1}{N}\\|y-X\\theta\\|^2+\\lambda \\|\\theta\\| 用交叉验证评估泛化性能(Cross-Validation to Assess the Generalization Performance)我们将已知数据进行拆分，一部分用于模型训练，一部分用于模型性能测试，这个称为验证集（validation set）。但是如果训练数据太少，可能导致得不到好的模型，如果训练数据太少可能导致噪声估计。所以应该对已有的数据进行合理的划分，这就有K-折交叉验证（K-fold cross-validation） 这样得到的期望泛化误差（expected generalization error）为： \\mathbb E_\\mathcal V[R(f,\\mathcal V)]\\approx\\frac{1}{K}\\sum^K_{k=1}R(f^{(k)},\\mathcal V^{(k)})其中，为预测值与真实值之间的误差。但是这个方法有几个缺点，首先是不合理的数据划分可能会导致的几个不好的结果，与之前的训练集和测试集之间的大小关系导致不同后果一致。同时需要对模型进行K次训练，可能需要大量的计算资源。 Evaluating the quality of the model, depending on these hyperparameters, may result in a number of training runs that is exponential in the number of model parameters. 参数估计（Parameter Estimation）最大似然估计（Maximum Likelihood Estimation）定义一个关于参数的函数，去评估模型对数据的拟合的好坏。一般使用负对数似然（negative log-likelihood）： \\mathcal L_x(\\boldsymbol\\theta)=-\\log p(\\boldsymbol x|\\boldsymbol\\theta)在上式中，样品值是固定的，变化的是参数,这个函数彰显的是给定参数的情况下，取得样品值的概率。假设两个相互独立且均匀分布的数据集，,,他们的似然方程可以呗分解为： p(\\mathcal Y|\\mathcal X,\\theta)=\\prod^N_{n=1}p(y_n|\\boldsymbol x_n,\\boldsymbol\\theta)但是从优化的角度来看，和比乘积更容易处理： \\mathcal L(\\theta)=-\\log p(\\mathcal Y|\\mathcal X, \\theta)=-\\sum^N_{n=1}\\log p(y_n|x_n,\\theta) hence should be interpreted as observed and fixed, this interpretation is incorrect. 最大后验估计（Maximum A Posteriori Estimation）如果我们有关于参数的先验知识，这样可以利用贝叶斯公式更新后验概率，以对参数进行估计。这个与之前提到的正则项类似，在似然概率之后乘以一个对参数的先验概率分布。 这部分需要补充 模型拟合（Model Fitting）拟合的意思就是优化模型的参数，以最小化代价函数。参数化（arametrization）：一种描述模型的方式。 y = ax+b\\rightarrow \\theta:=\\{a,b\\}书中使用表示参数化的模型，$M^$为真实值，上图中的红线可以认为是代价函数。*拟合的三种结果： 泛化线性模型(generalized generalized linear)：In statistics, the generalized linear model (GLM) is a flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution.连接函数（Link Function）：The link function provides the relationship between the linear predictor and the mean of the distribution function. 贝叶斯推断（Bayesian Inference）之前提到的极大似然估计和极大后验估计最后都是在解决一个优化问题，通过解决这个优化问题，我们可以得到模型参数，利用这个参数我们可以得到预测值的分布由于仅仅是关注于部分数据的后验分布会损失部分的信息，而损失的信息可能对决策系统至关重要，所以得到一个完成数据的后验分布十分重要 这部分需要补充，关于信息损失 对于一个数据集、一个参数先验和一个似然方程的后验分布为： p(\\theta|\\mathcal X)=\\frac{p(\\mathcal X|\\theta)p(\\theta)}{p(\\mathcal X)},\\quad p(\\mathcal X)=\\int p(\\mathcal X|\\theta)p(\\theta)d\\theta利用参数的后验分布，我们可以将对参数的不确定性转移到数据上,也就是我们的预测值不再依赖于参数了： p(\\boldsymbol x)=\\int p(\\boldsymbol x|\\boldsymbol\\theta)p(\\boldsymbol\\theta)d\\boldsymbol\\theta=\\mathbb E_\\boldsymbol\\theta[p(\\boldsymbol x|\\boldsymbol\\theta)]上式说明，预测值是所有参数下的预测值的均值。 潜变量模型（Latent-Variable Models） Mathematical models that aim to explain observed variables in terms of latent variables are called latent variable models 潜变量（Latent-Variable）These could in principle be measured, but may not be for practical reasons. In this situation, the term hidden variables is commonly used (reflecting the fact that the variables are meaningful, but not observable). 想要简化模型，最简单的方法就是减少模型的参数的数量。但是利用潜变量模型（expectation maximization (EM) algorithm），可以更加规范地简化模型。潜变量模型能够帮助我们描述从参数中获取预测值地过程：将数据表示为,模型的参数表示为,潜变量表示为,我们可以得到条件分布： p(\\boldsymbol x|\\boldsymbol z,\\boldsymbol\\theta)想要得到给定模型参数下的预测数据，我们需要消去潜变量： p(x|\\theta)=\\int p(x|z,\\theta)p(z)dz注意到似然方程与潜变量无关，有了上面这个式子，我们可以直接使用极大似然估计来进行参数估计。用上式带入到贝叶斯公式中： p(\\theta|\\mathcal X)=\\frac{p(\\mathcal X|\\theta)p(\\theta)}{p(\\mathcal X)}其中，为给定的数据集。这样得到了后验概率分布，可以用于贝叶斯推断。与上式类似，我们可以得到潜变量的后验分布： p(z|\\mathcal X)=\\frac{p(\\mathcal X|z)p(z)}{p(\\mathcal X)},\\quad p(\\mathcal X|z)=\\int p(\\mathcal X|z,\\theta)p(\\theta)d\\theta但是还是遇到了积分。而且同时将参数和潜变量消掉也非常困难。下面这个式子相对好计算： p(z|\\mathcal X,\\theta)=\\frac{p(\\mathcal X|z,\\theta)p(z)}{p(\\mathcal X|\\theta)} 补充一下这部分？含义？ 有向图模型（Directed Graphical Models/Bayesian networks）将一个随机变量表示为一个有向图的节点，随机变量之间的关系表示为有向图的边，这样可以很好的得出随机变量之间的关系，而且可以将随机变量之间的关系变换转换成有向图的操作. 图的语义（Graph Semantics）下图表示的是a、b、c三个随机变量，边代表条件概率分布，例如a、b节点，代表所以，一个联合概率分布可以表示为： p(\\boldsymbol x)=\\prod^K_{k=1}p(x_k|Pa_k)其中，表示节点的父节点。对于一个重复N次的伯努利实验的联合概率分布为：图(b)是一种更加紧凑的表示方法，图 (c)中的、是潜变量的超参数（Hyperparameter）也是的一个超前驱（hyperprior） 条件概率分布和d-分离（有向分离）（Conditional Independence and d-Separation）假设一个互不相交的节点集，,在下，与条件独立，表示为： \\mathcal A \\perp \\!\\!\\!\\perp\\mathcal B\\ |\\ \\mathcal C有向分离(d-separation)的基本思想：通过贝叶斯网中看两个事件的关系（两个事件是否条件独立），从而简化概率计算。（利用两时间的相互独立的性质）当三个节点满足下面地条件之一的时候，则表示是d-分离的。 下面的参考博客中有对应结论的推导 参考这里两种情况： 若不观测，则,只有才能说明相互独立，也就是有向独立（d-separation） 若观测,则使用条件概率公式,只有满足才能说明相互独立，也就是有向独立（d-separation） 模型选择（Model Selection）越复杂的模型能够表示的数据之间的关系就越多，例如一个二次函数模型，除了能够表示线性关系之外，还可以表示数据之间的二次关系。虽然复杂的模型能够表示更多的数据关系，但是有时候因为数据量比较小，可能会导致过拟合的现象。我们还需要知道如何评估模型在泛化数据下的性能。 嵌套交叉验证（Nested Cross-Validation）将数据分为三个部分，第一部分用于训练模型，第二部分用于计算误差： \\mathbb E_\\mathcal V[\\boldsymbol R(\\mathcal V| M)]\\approx = \\frac{1}{K}\\sum^K_{k=1}\\boldsymbol R(\\mathcal V^{(k)}|M)其中代表的是经验风险(empirical risk)计算所有模型的经验风险，然后选取经验风险最小的模型作为最终模型，然后利用测试数据计算模型的泛化误差。 贝叶斯模型选择（Bayesian Model Selection）简单的模型较复杂的模型不容易出现过拟合的现象，所以在能够合理拟合数据的情况下，应该尽可能选取简单的模型，这被称为奥卡姆剃刀（Occam’s razor）。在贝叶斯概率的应用过程中，定量地体现了一个“自动奥卡姆剃刀” 上图中，横坐标表示所有的可能的数据集，纵坐标表示模型对对应数据的拟合程度。我们会选用拟合程度更好的模拟作为最终的模型。 下图是数据生成过程：第一个表示模型的先验概率，表示模型被选取的概率，第二个表示模型对应的参数的分布，最后一个是模型的生成数据。 用贝叶斯网可以表示为：我们可以利用贝叶斯公式计算后验分布： p(M_k|\\mathcal D)\\propto p(M_k)p(\\mathcal D|M_k)，\\quad(*)其中的后验分布不依赖于参数,因为： p(\\mathcal D|M_k)=\\int p(\\mathcal D|\\boldsymbol \\theta_k)p(\\boldsymbol \\theta_k|M_k)d\\boldsymbol \\theta_k这个式子被称为边际似然（marginal likelihood）利用(*)式，可以得到极大后验估计： M^*=\\operatorname {arg}\\max_{M_k}p(M_k|\\mathcal D) 似然与边际似然有些不同点，前者更容易出现过拟合的现象，后者因为参数被边际化掉了，出现过拟合的现象更小。而且边际似然中嵌套着模型复杂度和数据拟合之间的一个折中。 模型比较中的贝叶斯因子（Bayes Factors for Model Comparison）在给定数据集和两个模型,想要计算后验分布 \\underbrace{\\frac{p\\left(M_{1} \\mid \\mathcal{D}\\right)}{p\\left(M_{2} \\mid \\mathcal{D}\\right)}}_{\\text {posterior odds(后验相对风险) }}=\\frac{\\frac{p\\left(\\mathcal{D} \\mid M_{1}\\right) p\\left(M_{1}\\right)}{p(\\mathcal{D})}}{\\frac{p\\left(\\mathcal{D} \\mid M_{2}\\right) p\\left(M_{2}\\right)}{p(\\mathcal{D})}}=\\underbrace{\\frac{p\\left(M_{1}\\right)}{p\\left(M_{2}\\right)}}_{\\text {prior odds }} \\underbrace{\\frac{p\\left(\\mathcal{D} \\mid M_{1}\\right)}{p\\left(\\mathcal{D} \\mid M_{2}\\right)}}_{\\text {Bayes factor }} ??? 如果选择每一个模型的概率相等，即,则可以根据贝叶斯因子与1的关系，选择模型。 信息准则（information criteria）：Akaike information criterion：corrects for the bias of the maximum likelihood estimator by addition of a penalty term to compensate for the overfitting of more complex models with lots of parameters.其中，M表示参数的个数Bayesian information criterion (BIC) \\log p(x)=\\log\\int p(x|\\boldsymbol\\theta)p(\\boldsymbol\\theta)d\\boldsymbol\\theta\\approx\\log p(x|\\boldsymbol\\theta)-\\frac{1}{2}M\\log N这里N表示数据集，M表示参数个数这部分遇到的时候在详细学习","link":"/2021/05/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6-When-Models-Meet-Data/"},{"title":"机器学习中的数学：信息论(Information Theory)","text":"@[toc] 参考：Dive into Deep Learning A. zhang ect Chapter 18 Appendix: Mathematics for Deep Learning 利用信息论我们可以测量或者比较在不同的信号（signals）中信息。在这部分，我们主要讨论机器学习对信息论的一些概念和应用。首先我们先简要描述介绍一下机器学习和信息论之间的关系。机器学习的主要的任务就是从数据中提取出有价值的信息，然后利用这些信息去做一些预测。而信息论主要研究信息的编码、解码、转换和操作（sencoding, decoding, transmitting, and manipulating information）。所以，我们可以利用信息论来讨论机器学习在训练中对信息的处理过程。 信息（Information）信息就是能够将所有事情通过一种或者是多种编码格式编码成一个特定的序列。但是怎么样编码才能正确地表述事物所具有的信息量呢？在我们描述一个事件的时候，如果这件事情是不寻常的，这时候我们需要更多的信息来描述，反之需要更少的信息。这就好比说一个普通的碗和清朝乾隆皇帝御用的碗，后者是比较少见的，需要更多的必要信息才能描述清楚它的特征。所以可以将信息表示为事件发生的抽象概率。 自信息（Self-information）香农（Shannon）将比特（bit）作为信息的单位，这将时间发生的概率转换成比特数。这样，对于一个长度为的二进制序列所包含的信息为比特。假设二进制序列每一个位置为1或者0的概率相等（都为）,所以对于一个事件,这个事件为：一个长度为二进制序列，每种序列出现的概率为,香农定义了自信息，将事件的概率转换成了比特数： I(x) = -\\log_2(p)举例来说，对于一个序列“0010”的自信息为： I(\"0010\") = -\\log_2(p(\"0010\"))=-\\log_2(\\frac{1}{2^4})=4\\ bits* 在本章节中，我们省略log的下标，如无特殊说明都表示 熵（Entropy）自信息只能描述一个离散事件的信息，这部分介绍能够任意随机变量的描述方式。 提出熵的动机（Motivating Entropy）熵的形式受限于香农熵定理： 我们通过观察随机变量得到的信息与随机变量的元素的名称无关，与发生概率为0的元素无关。 两个随机变量一起观测得到的信息 两个随机变量分开观测得到的信息。当两个随机变量相互独立的时候，取得等号。 通过一个确定事件所得到的信息为0 我们可以将抛掷一个完全均匀的硬币所得到的信息为1比特作为基准，以消除使用不同的基本单位而导致的对同一事件的信息量上的差异。 定义（Definition）对于一个随机变量, 遵循概率分布,概率密度函数或概率质量函数为,我们利用熵来描述信息的期望值： H(x)=-E_{x\\sim P}[\\log p(x)]具体来说： H(X)=\\left\\{\\begin{aligned} & -\\sum_i p_i\\log p_i, \\quad p_i = P(X_i)\\quad X 是离散型随机变量 \\\\ & -\\int_x p(x)\\log p(x) dx\\quad X是连续型随机变量 \\end{aligned} \\right.连续性随机变量的熵也被称为微分熵（Differential Entropy） 解释（Interpretation）在这一节中，主要解释两个关于上述公式的问题。 为什么要使用负对数？ 首先是为什么要使用对数。这是为了保证熵对独立随机变量的可加性。对于一系列相互独立的事件发生的概率为, 那么所有事件发生的概率为 ,使用对数可以将这个连乘转换成连加。 为什么添加负号？ 因为信息的定义。由于发生概率低的事件应该包含更多的信息，但是对数是一个单调递增函数，所以为了保证事件概率和对应的熵之间的反比例的关系，我们需要对对数加一个负号，让他变成单调递减函数。 为什么需要期望函数？ 对于一个随机变量X，它的自信息（）就是对于某个输出的不确定性的数量。但是当事件发生的概率趋向于0的时候，这种不确定性就会趋向于.同样的，我们可以将熵解释为观测事件X的平均不确定性。举例子来说，对于一个模型的相互独立的输出的对应的概率为， 那么这个系统的熵就是输出值的平均自信息： H(S) = \\sum_ip_i\\cdot I(s_i)=-\\sum_ip_i\\cdot\\log p_i 熵的性质（Properties of Entropy）下面考虑随机事件, 它对应的概率分布为 对所有离散型随机变量:(连续性随机变量的熵可能会是负数) 假设一个随机事件，我们想用一个新的概率分布来估计则有：H(X)=-E_{x\\sim P}[\\log p(x)]\\le -E_{x\\sim P}[\\log q(x)] 当的时候，取得等号。 对于一个随机变量, 将会传递最多的信息，如果他能将这些信息均匀地分布在所有可能的结果上。具体来说，对于一个概率分布的k种相互独立的输出:H(X)\\le \\log(k), with\\ equality\\ if \\ and \\ only \\ if \\ p_i=\\frac{1}{k},\\forall_i但是如果是一个连续性随机变量，那么处理过程就会很麻烦了。我们假设P在一个有限的区间内，那么，如果这个随机变量在这个区间上满足均匀分布，那么这个随机变量的熵的值将会是最大的。互信息（Mutual Information）在这部分，我们联合变量的熵。在本节中，我们使用的联合变量遵循联合概率分布,概率密度函数为,其中联合熵(Joint Entropy)联合熵与先前定义的熵的形式一致：H(X,Y)=-E_{(x,y)\\sim P}[\\log p_{X,Y}(x,y)]\\tag {*}具体形式为：H(X,Y)=\\left\\{\\begin{aligned} &-\\sum_x\\sum_yp_{X,Y}(x,y)\\log p_{X,Y}(x,y),\\quad 离散型\\\\ &-\\int_{x,y}p_{X,Y}(x,y)\\log p_{X,Y}(x,y)dxdy,\\quad 连续型 \\end{aligned}\\right.表示一对随机变量的全部的不确定性。当的时候，,当X与Y相互独立的时候,所以有：H(X),H(Y)\\le H(X,Y)\\le H(X)+H(Y) 条件熵（Conditional Entropy）在机器学习中，我们更多的时候，我们更关注条件上而不是联合熵。例如我们要根据图片判断图片的标签，这就可以理解为在图片像素信息条件下的对标签的信息。条件熵的定义与之前的几种熵的定义相似： H(Y|X)=-E_{(x,y)\\sim P}[\\log p(y|x)]其中：.条件熵与熵和联合熵的关系为： H(Y|X)=H(X,Y)-H(X)这样条件熵既可以理解为存在于Y中的而不存在与X中的的信息。 互信息（Mutual Information）上面我们讨论了联合变量之中独有的信息，现在我们讨论两个变量之间共有的信息。所以根据定义可以得到（互信息:） I(X,Y) = H(X,Y)-H(Y|X)-H(X|Y)将原先的定义式带入，整理可得： I(X,Y)=E_xE_y\\left\\{ p_{X,Y}(x,y)\\log \\frac{p_{X,Y}(x,y)}{p_X(x)p_Y(y)} \\right\\}在本节中提到的定义之间的关系如下图： 互信息的性质(Properties of Mutual Information) 对称性： 非负性： 如果两个随机变量是相互独立的，那么 如果X是Y的可逆函数： 点间互信息（Pointwise Mutual Information）点间互信息:就是互信息定义中的对数部分： pmi(x,y) = \\log\\frac{p_{X,Y}(x,y)}{p_X(x)p_Y(y)}他描述的是两个联合事件发生的概率比分别发生的概率的具体的数值关系。 互信息的应用（Applications of Mutual Information）在自认语言处理中，歧义消除（Ambiguity Resolution）是一件比较难的事情。也就是一些词在文中的含义不是很明确。例如先前出现的新闻“亚马逊起火了”，我们不知道是公司起火了，还是那个雨林起火了。这时候就产生了歧义。我们先找出一组词，这些词与亚马逊公司有较大互信息。同样找到与亚马逊雨林有较大互信息的词，然后分析这些那些在文中有更高的出现频率。利用这个，我们能够了解新闻是关于公司的还是雨林的。 Kullback–Leibler 散度（Kullback–Leibler Divergence）我们可以利用范数来表示任何维度两点之间的距离。现在我们想知道两个概率分布之间的距离（相似程度）。KL散度就是一种测量两种分布之间相似程度的量。 定义（Definition）对于一个随机变量遵循概率分布,概率密度分布为.我们利用另一个概率分布(),那么和之间的KL散度（相对熵，Relative Entropy）定义为： D_{KL}(P\\|Q)=E_{x\\sim P}[\\log\\frac{p(x)}{q(x)}]可见DL散度就是在描述两个随机变量之间不确定性程度的相对关系。 性质（Properties） 非对称性： 非负性：,当时取得等号。 如果则 以下三种表达式等价：D_{KL}(P(X,Y)\\| P(X)P(Y))E_Y\\{D_{KL}(P(X|Y))\\|P(X))\\}E_X\\{D_{KL}(P(Y|X)\\|P(Y))\\} For the first term, we interpret mutual information as the KL divergence between P(X, Y ) and the product of P(X) and P(Y ), and thus is a measure of how different the joint distribution is from the distribution if they were independent. For the second term, mutual information tells us the average reduction in uncertainty about Y that results from learning the value of the ʼs distribution. Similarly to the third term. 交叉熵（Cross-Entropy）对于一个二分类问题，预测值为.预测结果为1的概率为：所以log似然方程为： \\begin{aligned} l(\\theta)&=\\log L(\\theta)\\\\ &=\\log \\prod^n_{i=1}\\pi_i^{y_i}(1-\\pi_i)^{1-y_i}\\\\ &=\\sum^n_{i=1}y_i \\log(\\pi_i)+(1-y_i)\\log(1-\\pi_i) \\end{aligned}我们的目标就是最大化这个似然函数，这种方法就是极大似然估计。看到式中的自然对数，我们可以联想到之前提到一些信息论的概念。这暗示我们这个函数可以从信息论的角度理解。 正式定义（Formal Definition）我们假设有两个随机变量:(前者是真实值的分布，后者是预测值的分布).，我们可以通过交叉熵来描述两种分布之间的散度： CE(P,Q)=-E_{x\\sim P}[\\log (q(x))]通过之前提到的关系式，可以将上式转化为： CE(P,Q) = H(P)+D_{KL}(P\\|Q)性质（Properties）交叉熵可以用于优化问题的损失函数，以下几种说法是等价的： 最大化分布对于分布P的预测概率(最大化) 最小化交叉熵 最小化KL散度 这些性质可以从交叉熵的定义中得出。注意因为P是真实值的分布，所以是一个常量。 交叉熵作为多元分类问题的目标函数（Cross-Entropy as An Objective Function of Multi-class Classification）现在考虑一个k分类问题，这个分类问题的标签用独热编码（One-hot encoding）表示,预测标签值为： \\hat y_i=p_\\theta(y_i|x_i)=\\sum^k_{j=1}y_{ij}p_\\theta(y_{ij}|x_i)所以交叉熵可以表示为： CE(y,\\hat y)=-\\sum^n_{i=1}y_i\\log\\hat y_i=-\\sum^n_{i=1}\\sum^k_{j=1}y_{ij}\\log(y_{ij}|x_i)另一方面，我们可以利用极大似然估计来解决这个问题。假设一个随机变量满足k分类多元伯努利分布，对应的概率为,也就是： p(z)=p(z_1,\\cdots,z_k)=Multi(p_1,\\cdots,p_k),\\ where\\ \\sum^k_{i=1}p_i=1z的联合概率质量函数为: p^z=\\prod^k_{j=1}p^{z_j}_j所以对应的log似然方程为： l(\\theta)=\\log L(\\theta)=\\log\\prod^n_{i=1}p^{y_i}=\\log\\prod^n_{i=1}\\prod_{j=1}^{k}p^{y_{ij}}=\\sum^n_{i=1}\\sum^k_{j=1}y_{ij}\\log p_j所以对于多分类问题最大化log似然函数等价于最小化交叉熵损失","link":"/2022/10/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%EF%BC%9A%E4%BF%A1%E6%81%AF%E8%AE%BA-Information-Theory/"},{"title":"机器学习中的数学ch11：基于高斯混合模型的密度估计（Density Estimation with Gaussian Mixture Models）","text":"@[toc]在本章节中，我们会介绍关于密度估计的几个主要的概念，例如：期望最大化算法（expectation maximization (EM) algorithm）。当我们使用数据进行模型训练的时候，我们需要将数据按照一些方法表示出来，最常见的方法就是将数据点本身代表数据，如下图：但是当数据集很大的时候，这种方法就不是很有效了（在上图这种多模型数据中的表现也不好）。在密度估计中，我们使用参数族（例如高斯分布、贝塔分布等）中的密度来表示数据。例如，我们可以找到数据集的均值和方差，然后利用高斯模型表示这些数据，我们可以认为数据集就是从这些模型中抽样出来的。但是 ，在实践过程中，这些模型有时候不能很好地表示这些数据，也就是说这些模型的具有有限的建模能力（have limited modeling capabilities）。所以，我们介绍一种更通用的数据模型：混合模型（mixture model）。混合模型可以将一个概率分布用K种不同的基本分布的凸组合（convex combination）表示： p(x)=\\sum^K_{k=1}\\pi_k p_k(x)\\\\ 0\\le \\pi_k\\le 1,\\quad \\sum^K_{k=1}\\pi_k=1其中，为基本分布（高斯分布，贝塔分布等），为混合权重（mixture weight），混合权重能够保证混合模型的概率密度分布的总积分仍旧是1。通过将基本模型进行混合，混合模型能够很好地表示一些多模型数据（如上图中数据）。在本章中，主要讨论高斯混合模型（Gaussian mixture models (GMMs)）。我们的目标是通过最大化模型参数的似然来训练GMMs。这里我们不会项之前那样找到一个闭型（closed-form，解析解）的极大似然估计的解，而是找到一组相互独立的联立方程（dependent simultaneous equation），解这些方程只能通过迭代的方式。 高斯混合模型（Gaussian Mixture Model）高斯混合模型是一个密度模型，在这个模型中，我们将K个高斯分布组合起来，即: p(x|\\theta)= \\sum^K_{k=1}\\pi_k\\mathcal N(x|\\mu_k.\\Sigma_k)\\\\0\\le \\pi_k\\le1,\\sum^K_{k=1}\\pi_k=1其中，为模型参数的整合参数。这个混合模型能够在数据处理的时候提供更高的灵活度。下图是一个高斯混合模型的曲线图： 利用极大似然估计进行参数学习（Parameter Learning via Maximum Likelihood）假设有一个从未知分布中抽样得到的独立同分布的数据集，我们的目标是找到能够更好地表示这个未知分布的GMM的参数。这里我们使用极大似然估计求解参数，由于数据都是独立同分布的，所以我们可以对似然函数进行分解： p(\\mathcal X|\\theta)=\\prod^N_{n=1}p(x_n|\\theta),\\quad p(x_n|\\theta)=\\sum^K_{k=1}\\pi_k\\mathcal N(x_n|\\mu_k,\\Sigma_k)其中的每一个都是一个高斯混合密度，所以对应的自然对数似然为： \\log p(\\mathcal X|\\theta)=\\sum^N_{n=1}\\log p(x_n|\\theta)=\\underbrace{\\sum^N_{n=1}\\log \\sum^K_{k=1}\\pi_k \\mathcal N(x_n|\\mu_k,\\Sigma_k)}_{=: \\mathcal L}我们的目标就是找到能够最小化这个自然对数似然的模型参数，我们原先讨论极大似然估计的解的时候，是将这个似然函数对参数球偏导，然后将这个偏导设为0，求解出参数的值。但是在这里我们不能求出一个闭型的解。 不能求出闭型的解的原因？原先我们讨论的是单个高斯分布，所以对应的自然对数概率分布为： \\log \\mathcal N(x|\\mu,\\Sigma)=-\\frac D2\\log (2\\pi)-\\frac 12\\log\\det(\\Sigma)-\\frac 12(x-\\mu)^\\top \\Sigma^{-1}(x-\\mu)这个简单的形式能够让我们找到闭型的解，但是对于混合函数，其中的log后面的K次求和没有办法拆开，所以也就很难找到闭型的解了。 所以我们使用迭代的方式找到模型的最佳参数,这个方法就是期望最大化算法（expectation maximization (EM) algorithm），EM的关键思想就是更新其中一个参数，而保持其他参数固定。由于函数的局部最优解出的梯度都是0，所以可以将对参数分别进行求偏导，然后将这些偏导设为0，这是最优化自然对数似然的必要条件： \\begin{aligned} &\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{\\mu}_{k}}=\\mathbf{0}^{\\top} \\Longleftrightarrow \\sum_{n=1}^{N} \\frac{\\partial \\log p\\left(\\boldsymbol{x}_{n} \\mid \\boldsymbol{\\theta}\\right)}{\\partial \\boldsymbol{\\mu}_{k}}=\\mathbf{0}^{\\top}, \\\\ &\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{\\Sigma}_{k}}=\\mathbf{0} \\Longleftrightarrow \\sum_{n=1}^{N} \\frac{\\partial \\log p\\left(\\boldsymbol{x}_{n} \\mid \\boldsymbol{\\theta}\\right)}{\\partial \\boldsymbol{\\Sigma}_{k}}=\\mathbf{0} \\\\ &\\frac{\\partial \\mathcal{L}}{\\partial \\pi_{k}}=0 \\Longleftrightarrow \\sum_{n=1}^{N} \\frac{\\partial \\log p\\left(\\boldsymbol{x}_{n} \\mid \\boldsymbol{\\theta}\\right)}{\\partial \\pi_{k}}=0 \\end{aligned}由于是一个复合函数，所以可以使用链式法则进行求偏导： \\frac{\\partial\\log p(x_n|\\theta)}{\\partial \\theta}= \\frac {1}{p(x_n|\\theta)}\\frac{\\partial p(x_n|\\theta)}{\\partial \\theta}其中：； .接下来主要介绍求解上述的几个等式。但是在求解之前我们介绍一个很重要的概念：责任（responsibilities） 责任（Responsibilities）我们将第k个混合成分对第n个数据点的责任定义为： r_{nk}:=\\frac{\\pi_k\\mathcal N(x_n|\\mu_k,\\Sigma_k)}{\\sum^K_{j=1}\\pi_j\\mathcal N(x_n|\\mu_j,\\Sigma_j)}这个第k个混合成分（Mixture Component）对数据点的责任与下面的似然函数呈比例： p(x_n|\\pi_k,\\mu_k,\\Sigma_k)= \\pi_k\\mathcal N(x_n|\\mu_k,\\Sigma_k)如果一个数据点与其中的混合成分越匹配（模型对应的部分能够很好地表示数据），那么相对应的责任也就越大。一个数据点的责任可以使用一个规范化的概率向量表示：。（？ 满足Boltzmann/Gibbs分布）可以将责任理解为数据点在各个混合成分中，所占有的比例，也就是各混合成分得到这个数据点的概率（一个不是很准确的理解就是，这个数据在各个混合成分之间的分量）.接下来确定模型参数的时候，都需要依赖于这个责任，我们先改变一个参数，而保持其他的参数不变，然后计算对应的责任，之后不断将这两个步骤进行迭代，知道得到一个局部最优解。其实，正是二者与责任的高度相关性，使得最终的解没有一个闭型的解。 更新均值（Updating the Means）定理：（GMM均值的更新）GMM的均值参数为： \\mu^{new}_{k}=\\frac{\\sum^N_{n=1}r_{nk}x_n}{\\sum^N_{n=1}r_{nk}}由于更新一个混合模型的参数需要所有混合模型的均值、协方差矩阵和混合权重，所以我们不能一次性为所有的找到闭型的解。（我们需要同步更新？像梯度下降法那样？）证明：这里对定理进行简单的证明，但是不做详细说明结合之前的结论，我们求解似然函数对均值的偏导： \\begin{aligned} \\frac{\\partial p\\left(\\boldsymbol{x}_{n} \\mid \\boldsymbol{\\theta}\\right)}{\\partial \\boldsymbol{\\mu}_{k}} &=\\sum_{j=1}^{K} \\pi_{j} \\frac{\\partial \\mathcal{N}\\left(\\boldsymbol{x}_{n} \\mid \\boldsymbol{\\mu}_{j}, \\boldsymbol{\\Sigma}_{j}\\right)}{\\partial \\boldsymbol{\\mu}_{k}}=\\pi_{k} \\frac{\\partial \\mathcal{N}\\left(\\boldsymbol{x}_{n} \\mid \\boldsymbol{\\mu}_{k}, \\boldsymbol{\\Sigma}_{k}\\right)}{\\partial \\boldsymbol{\\mu}_{k}} \\\\ &=\\pi_{k}\\left(\\boldsymbol{x}_{n}-\\boldsymbol{\\mu}_{k}\\right)^{\\top} \\boldsymbol{\\Sigma}_{k}^{-1} \\mathcal{N}\\left(\\boldsymbol{x}_{n} \\mid \\boldsymbol{\\mu}_{k}, \\boldsymbol{\\Sigma}_{k}\\right) \\end{aligned}将上述的似然函数带入到对代价函数的偏导中： \\begin{aligned} \\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{\\mu}_{k}} &=\\sum_{n=1}^{N} \\frac{\\partial \\log p\\left(\\boldsymbol{x}_{n} \\mid \\boldsymbol{\\theta}\\right)}{\\partial \\boldsymbol{\\mu}_{k}}=\\sum_{n=1}^{N} \\frac{1}{p\\left(x_{n} \\mid \\theta\\right)} \\frac{\\partial p\\left(\\boldsymbol{x}_{n} \\mid \\boldsymbol{\\theta}\\right)}{\\partial \\boldsymbol{\\mu}_{k}} \\\\ &=\\sum_{n=1}^{N}\\left(\\boldsymbol{x}_{n}-\\boldsymbol{\\mu}_{k}\\right)^{\\top} \\boldsymbol{\\Sigma}_{k}^{-1}\\underbrace{\\frac{\\pi_{k} \\mathcal{N}\\left(\\boldsymbol{x}_{n} \\mid \\boldsymbol{\\mu}_{k}, \\boldsymbol{\\Sigma}_{k}\\right)}{\\sum_{j=1}^{K} \\pi_{j} \\mathcal{N}\\left(x_{n} \\mid \\mu_{j}, \\Sigma_{j}\\right)}}_{=r_{nk}} = \\sum^N _{n=1} r_{n k}\\left(\\boldsymbol{x}_{n}-\\boldsymbol{\\mu}_{k}\\right)^{\\top} \\boldsymbol{\\Sigma}_{k}^{-1} \\end{aligned}为了求解,需要求解: \\sum^N_{n=1}r_{nk}x_n=\\sum^N_{n=1}r_{nk}\\mu_k^{new}\\Leftrightarrow \\mu^{new}_k=\\frac{1}{N_k}\\sum^N_{n=1}r_{nk}x_n我们定义第k个混合元素对数据集的总贡献为： N_k:=\\sum^N_{n=1}r_{nk}得证。 这个均值更新的过程还可以使用重要性加权的蒙特卡罗估计（importance-weighted Monte Carlo estimate）理解。数据点的重要性权值就是所有混合成份对数据点的责任(存疑where the importance weights of data point are the responsibilities of the kth cluster for .)。可以将均值的更新过程想象成均值点被各个数据点拉着移动，而每个数据点对均值点的力的大小就是责任，如下图： 也可以将更新过程理解为在下式分布中的所有的数据点的期望值： r_k:=[r_{1k},\\cdots,r_{Nk}]^\\top/N_k这也是一个规范化的概率向量： \\mu_k\\leftarrow \\mathbb E_{rk}[\\mathcal X]更新协方差（Updating the Covariances）定理（更新GMM的协方差）更新协方差参数： \\Sigma^{new}_k=\\frac1N_k\\sum^N_{n=1}r_{nk}(x_n-\\mu_k)(x_n-\\mu_k)^\\top证明过程（原书p356）比较麻烦，这里略过.与更新均值相似，更新协方差可以理解为是中心化数据Missing argument for \\mathcal\\tilde \\mathcal X_k:=\\{x_1-\\mu_k,\\cdots.x_N-\\mu_k\\}的平方的重要性加权期望值。 更新混合权重（Updating the Mixture Weights）定理： \\pi^{new}_k=\\frac{N_k}{N},\\quad k=1,\\cdots,K其中，N是数据点的个数。证明：略（原书p358） 关于权重的更新即为第k个混合成分全部责任与数据点的个数的比。因为也可以理解为所有混合成分的的所有责任的总和，所以可以理解为第k个混合成分对于整个数据集的相对重要性。由于的更新等式依赖于责任，所以更新这个式子需要依赖于其他的所有参数： 实例（Example）初始化假设一个一维数据集,现在有一个由三个成分混合而成的GMM，混合成份分别为： \\begin{aligned} p_1(x) &= \\mathcal N(x|-4,1) \\\\ p_2(x) &= \\mathcal N(x|0,0.2)\\\\ p_3(x) &= \\mathcal N(x|8,3) \\end{aligned}初始化权重为：,在坐标中表示为：责任： \\left[\\begin{array}{ccc} 1.0 & 0.0 & 0.0 \\\\ 1.0 & 0.0 & 0.0 \\\\ 0.057 & 0.943 & 0.0 \\\\ 0.001 & 0.999 & 0.0 \\\\ 0.0 & 0.066 & 0.934 \\\\ 0.0 & 0.0 & 1.0 \\\\ 0.0 & 0.0 & 1.0 \\end{array}\\right] \\in \\mathbb{R}^{N \\times K} .第n行告诉我们对的所有混合成分的责任，责任之和为1，列告诉我们一个混合成分对所有的数据集的责任的情况。更新均值经计算，均值的变化为： \\begin{aligned} & \\mu_1:-4\\rightarrow -2.7\\\\ & \\mu_2:0\\rightarrow -0.4\\\\ & \\mu_3:8\\rightarrow3.7 \\end{aligned}变化形式表现在图中为：；可以看到第一个混合成分和第三个混合成分朝着数据域的方向上移动。协方差更新 \\begin{aligned} &\\sigma^2_1:1\\rightarrow 0.14\\\\ & \\sigma^2_2:0.2\\rightarrow0.44\\\\ & \\sigma_3^2:3\\rightarrow1.53 \\end{aligned}这些变化表现在图像上为：权重参数更新 \\pi_1:\\frac13\\rightarrow0.29\\\\ \\pi_2:\\frac13\\rightarrow0.29\\\\ \\pi_3:\\frac 13\\rightarrow0.42注意到图像中的各个峰值发生了变化。经过这一系列的更新，得到的模型能够更好地拟合给定的数据。 期望最大化算法（EM Algorithm）由于之前提到的参数更新的过程依赖于责任,而责任又与这些参数呈复杂的依赖关系，使得上述的更新过程没有一个闭型的解。接下来我们介绍一种解决参数的问题的迭代方案——期望最大化算法（The expectation maximization algorithm）。这其实是一种参数学习的泛化迭代方案。在高斯混合模中，我们选择参数的初始化值,不断改变这些参数，直到他们收敛于期望步（E-step）和极大步（M-step）之间的不断迭代。 期望步：评估责任(属于k混合成分的的数据点n的后验概率)极大步：用更新后的责任重新估计参数 由于EM算法每进行一次迭代都会导致似然函数值上升，所以可以利用这个特性直接检查自然对数似然或者参数。一个实例化的步骤如下：迭代过程中的变化情况： 现在我们对开篇的时候的数据进行处理：我们观察迭代的最终结果：由上图可以直到，左边的一簇数据可以由一个单一的成分进行表示，但是右边的一簇数据是由两个成分混合儿而成的，所以这两个混合成分对这一簇的数据的责任在0.5左右。 潜变量角度（Latent-Variable Perspective）我们使用一个离散型的潜变量模型来理解GMM。这样就可以将原先提到的责任的概念解释为后验概率分布了。其实，这个潜变量就是用来描述一个数据点在各个混合成分中的占有情况（表现为概率）。 生成过程和概率模型（Generative Process and Probabilistic Model）想要得到对应的概率模型，我们需要弄清楚数据的生成过程。假设一个混合模型由K个成分组成，而且每一个数据只能够由唯一的一个混合成分生成，这里我们引入一个定义域由0，1组成的随机变量,这个随机变量表示第k个混合成份是否生成了该模型。所以： p(x|z_k=1)=\\mathcal N(x|\\mu_k,\\Sigma_k)其中，,其中包含个0和个1.例如，表示该数据是由第二个混合元素生成的。在实际过程中，可能是未知的，也就是可能是由不同的高斯模型混合按照不同的比例混合而成的。所以假设一个关于潜变量的先验分布： p(z)=\\pi=[\\pi_1,\\cdots,\\pi_K]^\\top,\\sum^K_{k=1}\\pi_k=1其中，表示该数据点由第k个成分生成的概率（类比为混合比例）。潜变量的建模过程实际上对应着数据的生成过程，下面是单个数据的生成过程： 生成关系为： z_{(i)}\\sim p(z)\\\\x^{(i)}\\sim p(x|z^{(i)}=1)这种数据的采样依赖于图模型中的父节点的采样，这种采样称为原始采样(Ancestral Sampling)通常一个概率模型是由数据和潜变量的联合分布定义的，结合前面的知识，我们可以得到所有K个成分的联合分布： p(x,z_k=1)=p(x|z_k=1)p(z_k=1)=\\pi_k\\mathcal N(x|\\mu_k,\\Sigma_k)对于所有的: p(\\boldsymbol{x}, \\boldsymbol{z})=\\left[\\begin{array}{c} p\\left(\\boldsymbol{x}, z_{1}=1\\right) \\\\ \\vdots \\\\ p\\left(\\boldsymbol{x}, z_{K}=1\\right) \\end{array}\\right]=\\left[\\begin{array}{c} \\pi_{1} \\mathcal{N}\\left(\\boldsymbol{x} \\mid \\boldsymbol{\\mu}_{1}, \\boldsymbol{\\Sigma}_{1}\\right) \\\\ \\vdots \\\\ \\pi_{K} \\mathcal{N}\\left(\\boldsymbol{x} \\mid \\boldsymbol{\\mu}_{K}, \\boldsymbol{\\Sigma}_{K}\\right) \\end{array}\\right]似然（Likelihood）想要得到似然函数,我们需要将潜变量消去，由于我们原先定义的潜变量是离散型的，所以只需要连加就可以将潜变量消掉： p(z|\\theta)=\\sum_zp(x|\\theta,z)p(z|\\theta), \\quad \\theta:=\\{\\mu_k,\\Sigma_k,\\pi_k:k=1,\\dots,K\\}采样的图模型为：(N个样本点) 结合之前的知识，我们可以得到： p(x|\\theta)=\\sum^K_{k=1}\\pi_k\\mathcal N(x|\\mu_k,\\Sigma_k)所以对于给定的数据集的似然函数为： p(\\mathcal X|\\theta)=\\prod^N_{n=1}p(x_n|\\theta)=\\prod^N_{n=1}\\sum^K_{k=1}\\pi_k\\mathcal N(x_n|\\mu_k,\\Sigma_k)这个与原先的概率模型一致 后验分布（Posterior Distribution）根据贝叶斯公式，我们得到潜变量的后验分布： p(z_k=1|x)=\\frac{p(z_k)p(x|z_k=1)}{p(x)}将之前的结论带入： p(z_k|x)=\\frac{p(z_k)p(x|z_k)}{\\sum^K_{j=1}p(z_j)p(x|z_j)}=\\frac{\\pi_k\\mathcal N(x|\\mu_k,\\Sigma_k)}{\\sum^K_{j=1}\\pi_j\\mathcal N(x|\\mu_j,\\Sigma_j)}可以发现，这就是我们之前提到的责任 拓展到整个数据集（Extension to a Full Dataset）我们原先讨论的是单个数据，现在考虑一个数据集每一个数据点都有自己的潜变量: z_n=[z_{n1},\\cdots,z_{nK}]^\\top\\in\\mathbb R^K由于所有的数据都是独立同分布的，所以可以将条件分布分解为连积的形式： p(x_1,\\cdots,x_N|z_1,\\cdots,z_N)=\\prod^N_{n=1}p(x_n|z_n)后验分布： \\begin{aligned} p\\left(z_{n k}=1 \\mid \\boldsymbol{x}_{n}\\right) &=\\frac{p\\left(\\boldsymbol{x}_{n} \\mid z_{n k}=1\\right) p\\left(z_{n k}=1\\right)}{\\sum_{j=1}^{K} p\\left(\\boldsymbol{x}_{n} \\mid z_{n j}=1\\right) p\\left(z_{n j}=1\\right)} \\\\ &=\\frac{\\pi_{k} \\mathcal{N}\\left(\\boldsymbol{x}_{n} \\mid \\boldsymbol{\\mu}_{k}, \\boldsymbol{\\Sigma}_{k}\\right)}{\\sum_{j=1}^{K} \\pi_{j} \\mathcal{N}\\left(\\boldsymbol{x}_{n} \\mid \\boldsymbol{\\mu}_{j}, \\boldsymbol{\\Sigma}_{j}\\right)}=r_{n k} \\end{aligned}这还是第k个混合元素的责任。 期望最大化算法重新回顾（EM Algorithm Revisited）EM算法是一种用于求解极大似然估计的迭代算法，可以从潜变量的角度推导得来。对于一个给定的模型参数,在期望步时，计算自然对数似然的期望： Q(\\theta|\\theta^{(t)})=\\mathbb E_{z|x,\\theta^{(t)}}[\\log p(x,z|\\theta)]=\\int \\log p(x,z|\\theta)p(z|x,\\theta^{(t)})dz之后的极大步算则一个最大化上式的参数用于更新。但是EM算法并不一定会收敛于极大似然估计的解，有时候会收敛于局部最优解。可以采用不同的初始化值，这样可以减少得到局部最优解的风险。 拓展阅读核密度估计（Kernel Density Estimation）:核密度估计是一种非参数密度估计，其实我们熟悉的直方图就是一种非参数估计，其中直方图的间距不合适可能会导致过拟合或者欠拟合。对于一个数据集，核密度估计的分布为： p(x)=\\frac{1}{Nh}\\sum^N_{n=1}k(\\frac{x-x_n}{h})其中，k为核函数（Kernel Function），就是一个非负且积分值为1的函数。是一个光滑参数（smoothing/bandwidth parameter）这个与直方图的面元（直方图的柱子的宽度，bin size）大小类似。核函数通常的选择就是高斯函数或者时均匀分布函数。同时，核密度估计与直方图密切相关，但是核密度估计是光滑的，直方图不是。","link":"/2021/07/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6ch11%EF%BC%9A%E5%9F%BA%E4%BA%8E%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1%EF%BC%88Density-Estimation-with-Gaussian-Mixture-Models%EF%BC%89/"},{"title":"机器学习中的数学 ch12：支持向量机分类（Classification with Support Vector Machines）","text":"@[toc]在机器学习中，有一种分类问题，这种分类问题只有两个预测结果，是或否，即： f:\\mathbb R^D\\rightarrow \\{0,1\\}为了计算方便，我们使用0，1来表示两种分类的结果，这种分类问题被称为二元分类（Binary Classification）。本章节就是主要介绍用支持向量机（Support Vector Machine，SVM）来解决这种分类问题。支持向量机给我们提供了一个用几何的方式的视角看待监督式机器学习。在原先的章节中，我们使用概率模型来理解机器学习问题：用极大似然估计和贝叶斯推断对模型进行优化。支持向量机利用的是另一个角度，这种角度需要大量的代数知识，如内积、投影等。另外，由于用支持向量机解的优化问题没有一个解析解，所以我们需要利用之前学到的各种的优化方法，这可以作为之前学到的知识的一种实践。在支持向量机的视角下的机器学习问题与概率视角下的机器学习问题略有不同，前者的模型是由数据分布的概率视角得出的。后者是设计一个函数，然后再训练的过程中不断优化，这是基于几何理解的。接下来我们将从两个视角看待SVM：几何视角和损失函数视角。同时，为了提高模型的泛化能力，线性分类子应该允许一些错误的分类。之后我们还利用拉格朗日乘子得到对偶版本的SVM，这让我们可以利用另一个角度看待SVM。我们还介绍SVM的核方法，以及解非线性核SVM的优化问题。 分离超平面（Separating Hyperplanes）对于两点的相似程度，我们可以使用内积来表示。而一个分类问题的本质就是将数据集在一个平面上表示，然后将数据所在的空间划分成两个子空间。为了方便起见，我们考虑一个简单的分类问题： f:\\mathbb R^D\\rightarrow \\mathbb R, \\ x\\in \\mathbb R^D\\\\ x\\mapsto f(x):=\\langle w,x\\rangle+b其中的参数为：.我们原先提到，超平面实际上就是仿射子空间，所以我们假设一个超平面在一个二分类问题中将两类数据分离到两个子空间中： \\{x\\in\\mathbb R^D:f(x)=0\\}在下图中，我们可以知道w是超平面的法向量，b是超平面的截距。证明：假设有两个点在超平面上: f(x_a)-f(x_b)=\\langle w,x_a\\rangle+b-(\\langle w,x_b\\rangle + b)=\\langle w, x_a-x_b\\rangle由于超平面的方程为,而选取的两个点在超平面上，所以,所以： \\langle w, x_a-x_b\\rangle=0所以，w与超平面相互垂直。对于一个二分类问题，数据点在超平面的上方为一类，下方为另一类，所以： y_n=\\left\\{\\begin{aligned} 1,\\quad\\langle w,x_n\\rangle+b\\ge0 \\\\ -1\\quad \\langle w,x_n\\rangle+b","link":"/2021/07/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6-ch12%EF%BC%9A%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E5%88%86%E7%B1%BB%EF%BC%88Classification-with-Support-Vector-Machines%EF%BC%89/"},{"title":"机器学习中的数学：线性回归Linear Regression","text":"@[toc]回归的目的就是找到一个函数,将输入的数据映射成.数据的观测噪音为：,其中是一个独立均匀分布的随机变量，描述数据噪音。 噪音理解成预测值与观测值的偏差，准不准确？ 问题描述（Problem Formulation）因为观测噪音的缘故，我们使用概率模型，并且用一个似然函数对噪音进行建模。具体来说，我们考虑以下回归问题的的似然函数： p(y|\\boldsymbol x)=\\mathcal N(y|f(\\boldsymbol x),\\sigma^2)其中，是输入值,为噪音函数值（目标）与之间的关系为： y= f(\\boldsymbol x)+\\epsilon其中，是一个独立均匀的高斯分布。 Our objective is to find a function that is close (similar) to the unknown function that generated the data and that generalizes well. 假设在线性模型的条件下： p(y|\\boldsymbol x,\\boldsymbol \\theta)=\\mathcal N(y|\\boldsymbol x^\\top\\boldsymbol\\theta,\\sigma^2)\\Leftrightarrow y=\\boldsymbol x^\\top\\boldsymbol\\theta+\\epsilon,\\quad \\epsilon \\sim \\mathcal N(0,\\sigma^2)Why? 这里说明一下线性模型的意思，线性代表的是输入数据的线性组合，所以对于,即使是非线性函数，这个模型也是线性模型。 参数估计（Parameter Estimation）给定一个训练集,包含个输入和观测值.用概率图模型（Probabilistic graphical model）可以表示为： 又因为每一个样本又是相互独立的，所以可以将似然方程进行分解： p(\\mathcal Y|\\mathcal X,\\boldsymbol\\theta)=p(y_1,\\cdots,y_N|\\boldsymbol x_1,\\cdots,\\boldsymbol x_N,\\boldsymbol\\theta)=\\prod^N_{n=1}p(y_n|\\boldsymbol x_n,\\boldsymbol\\theta) = \\prod^N_{n=1}\\mathcal N(y_n|\\boldsymbol x_n^\\top\\boldsymbol\\theta,\\sigma^2)接下来详细介绍获取最优化参数的方法。 极大似然估计（Maximum Likelihood Estimation）我们可以通过极大似然估计得到参数： \\boldsymbol \\theta_{ML}=\\arg \\max_\\theta p(\\mathcal Y|\\mathcal X,\\boldsymbol\\theta)上面的似然概率不是参数的分布，而是函数。极大似然估计的目的就是最大化训练数据的概率分布。在实际过程中，我们常常采用似然对数转换（Log-Transformation）的方式，将问题转化成最小化负对数似然： -\\log p(\\mathcal Y|\\mathcal X,\\boldsymbol\\theta)=-\\log \\prod_{n=1}^N p(y_n|\\boldsymbol x_n,\\boldsymbol\\theta)=-\\sum^N_{n=1}\\log p(y_n|\\boldsymbol x_n,\\boldsymbol\\theta)这样做可以将原先的乘积转换成和， What does this suppose means?More specifically, numerical underflow will be a problem when we multiply N probabilities, where N is the number of data points, since we cannot represent very small numbers, such as . 由于在线性规划中，似然概率分布满足高斯分布（噪音项满足高斯分布），所以可以得到： ?？需要补充Note that: p(y|x,\\theta)=\\mathcal N(y|x^\\top\\theta,\\sigma^2)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-\\frac{(y-x^\\top)^2}{2\\sigma^2}} \\log p(y_n|\\boldsymbol x_n,\\boldsymbol\\theta)=-\\frac{1}{2\\sigma^2}(y_n-\\boldsymbol x_n^\\top\\boldsymbol\\theta)^2+\\operatorname {const}于是得到损失函数： \\begin{aligned} \\mathcal{L}(\\boldsymbol{\\theta}) &:=\\frac{1}{2 \\sigma^{2}} \\sum_{n=1}^{N}\\left(y_{n}-\\boldsymbol{x}_{n}^{\\top} \\boldsymbol{\\theta}\\right)^{2} \\\\ &=\\frac{1}{2 \\sigma^{2}}(\\boldsymbol{y}-\\boldsymbol{X} \\boldsymbol{\\theta})^{\\top}(\\boldsymbol{y}-\\boldsymbol{X} \\boldsymbol{\\theta})=\\frac{1}{2 \\sigma^{2}}\\|\\boldsymbol{y}-\\boldsymbol{X} \\boldsymbol{\\theta}\\|^{2} \\end{aligned}我们将定义为设计矩阵（Design Matrix）可以通过求导求解损失函数的最小值： \\begin{aligned} \\frac{\\mathrm{d} \\mathcal{L}}{\\mathrm{d} \\boldsymbol{\\theta}} &=\\frac{\\mathrm{d}}{\\mathrm{d} \\boldsymbol{\\theta}}\\left(\\frac{1}{2 \\sigma^{2}}(\\boldsymbol{y}-\\boldsymbol{X} \\boldsymbol{\\theta})^{\\top}(\\boldsymbol{y}-\\boldsymbol{X} \\boldsymbol{\\theta})\\right) \\\\ &=\\frac{1}{2 \\sigma^{2}} \\frac{\\mathrm{d}}{\\mathrm{d} \\boldsymbol{\\theta}}\\left(\\boldsymbol{y}^{\\top} \\boldsymbol{y}-2 \\boldsymbol{y}^{\\top} \\boldsymbol{X} \\boldsymbol{\\theta}+\\boldsymbol{\\theta}^{\\top} \\boldsymbol{X}^{\\top} \\boldsymbol{X} \\boldsymbol{\\theta}\\right) \\\\ &=\\frac{1}{\\sigma^{2}}\\left(-\\boldsymbol{y}^{\\top} \\boldsymbol{X}+\\boldsymbol{\\theta}^{\\top} \\boldsymbol{X}^{\\top} \\boldsymbol{X}\\right) \\in \\mathbb{R}^{1 \\times D} \\end{aligned}（）令上式等于0： \\begin{aligned} \\frac{\\mathrm{d} \\mathcal{L}}{\\mathrm{d} \\boldsymbol{\\theta}}=\\mathbf{0}^{\\top} {\\longrightarrow} \\boldsymbol{\\theta}_{\\mathrm{ML}}^{\\top} \\boldsymbol{X}^{\\top} \\boldsymbol{X}=\\boldsymbol{y}^{\\top} \\boldsymbol{X} \\\\ \\Longleftrightarrow \\boldsymbol{\\theta}_{\\mathrm{ML}}^{\\top}=\\boldsymbol{y}^{\\top} \\boldsymbol{X}\\left(\\boldsymbol{X}^{\\top} \\boldsymbol{X}\\right)^{-1} \\\\ \\Longleftrightarrow \\boldsymbol{\\theta}_{\\mathrm{ML}}=\\left(\\boldsymbol{X}^{\\top} \\boldsymbol{X}\\right)^{-1} \\boldsymbol{X}^{\\top} \\boldsymbol{y} . \\end{aligned} Normal equation is derived by MLE.——Ng 基于特征的极大似然估计（Maximum Likelihood Estimation with Features）当遇到更复杂的数据时，一次函数模型有时候很难很好地拟合数据，但是由于线性回归模型只是对”参数的线性”(“linear in the parameters”),所以可以在线性回归模型中对非线性模型进行拟合。这就是说我们可以先将输入值进行非线性变换之后，再放到线性模型中。In Ng’s courses he said this is Linear regression with higher order features. We can alse use SVM to derive new features. p(y|\\boldsymbol x,\\theta)=\\mathcal N(y|\\phi^\\top(x)\\boldsymbol\\theta,\\sigma^2)\\Longleftrightarrow y=\\phi^\\top(x)\\boldsymbol\\theta+\\epsilon=\\sum^{K-1}_{k=0}\\theta_k\\phi_k(x)+\\epsilon其中，是一个对的（非）线性变换，是特征向量的第k个分量。 一个实例：一种对输入数据常用的变换如下 \\phi(x)=\\left[\\begin{array}{c} \\phi_{0}(x) \\\\ \\phi_{1}(x) \\\\ \\vdots \\\\ \\phi_{K-1}(x) \\end{array}\\right]=\\left[\\begin{array}{c} 1 \\\\ x \\\\ x^{2} \\\\ x^{3} \\\\ \\vdots \\\\ x^{K-1} \\end{array}\\right] \\in \\mathbb{R}^{K}所以： f(x)=\\sum\\limits^{K-1}_{k=0}\\theta_kx^k=\\phi^\\top(x)\\boldsymbol\\theta现在看看参数在线性回归模型下的极大似然估计： \\Phi:=\\left[\\begin{array}{c} \\phi^{\\top}\\left(x_{1}\\right) \\\\ \\vdots \\\\ \\phi^{\\top}\\left(x_{N}\\right) \\end{array}\\right]=\\left[\\begin{array}{ccc} \\phi_{0}\\left(x_{1}\\right) & \\cdots & \\phi_{K-1}\\left(x_{1}\\right) \\\\ \\phi_{0}\\left(x_{2}\\right) & \\cdots & \\phi_{K-1}\\left(x_{2}\\right) \\\\ \\vdots & & \\vdots \\\\ \\phi_{0}\\left(x_{N}\\right) & \\cdots & \\phi_{K-1}\\left(x_{N}\\right) \\end{array}\\right] \\in \\mathbb{R}^{N \\times K}where and .这个矩阵被称为特征矩阵（feature matrix）或设计矩阵(design matrix)有了上面这个矩阵，我们可以将线性回归模型： p(y|\\boldsymbol x,\\boldsymbol \\theta)=\\mathcal N(y|\\boldsymbol x^\\top\\boldsymbol\\theta,\\sigma^2)\\Leftrightarrow y=\\boldsymbol x^\\top\\boldsymbol\\theta+\\epsilon,\\quad \\epsilon \\sim \\mathcal N(0,\\sigma^2) 从这个式子中可以看出，预测值的结果主要分布于均值的周围 写成： -\\log p(\\mathcal Y|\\mathcal X,\\boldsymbol\\theta)=\\frac{1}{2\\sigma^2}(y-\\Phi\\boldsymbol\\theta)^\\top(y-\\Phi\\boldsymbol\\theta)+\\operatorname{const}将两式子进行比较，发现二者只是将欢成了,所以直接利用模型的结论，得到的估计值： \\theta_{ML}=(\\Phi^\\top\\Phi)^{-1}\\Phi^\\top y 需要讨论的可逆性这个是不是支持向量机中的多项式核函数？ (x_1\\times x_2 + r)^d其中，r为多项式的参数，d为多项式的次数，、为观测值 噪声方差（Estimating the Noise Variance）我们之前的讨论都是假定是已知的，但是实际上可以利用极大似然估计的方式对噪声方差进行估计，所有的步骤与之前一致：将带入到似然函数中： \\begin{array}{l} \\log p\\left(\\mathcal{Y} \\mid \\mathcal{X}, \\boldsymbol{\\theta}, \\sigma^{2}\\right)=\\sum\\limits_{n=1}^{N} \\log \\mathcal{N}\\left(y_{n} \\mid \\phi^{\\top}\\left(\\boldsymbol{x}_{n}\\right) \\boldsymbol{\\theta}, \\sigma^{2}\\right) \\\\ =\\sum\\limits_{n=1}^{N}\\left(-\\frac{1}{2} \\log (2 \\pi)-\\frac{1}{2} \\log \\sigma^{2}-\\frac{1}{2 \\sigma^{2}}\\left(y_{n}-\\phi^{\\top}\\left(\\boldsymbol{x}_{n}\\right) \\boldsymbol{\\theta}\\right)^{2}\\right) \\\\ =-\\frac{N}{2} \\log \\sigma^{2}-\\frac{1}{2 \\sigma^{2}} \\underbrace{\\sum_{n=1}^{N}\\left(y_{n}-\\boldsymbol{\\phi}^{\\top}\\left(\\boldsymbol{x}_{n}\\right) \\boldsymbol{\\theta}\\right)^{2}}_{=: s}+\\text { const. } \\end{array}对求偏导： \\begin{aligned} & \\frac{\\partial \\log p\\left(\\mathcal{Y} \\mid \\mathcal{X}, \\boldsymbol{\\theta}, \\sigma^{2}\\right)}{\\partial \\sigma^{2}}=-\\frac{N}{2 \\sigma^{2}}+\\frac{1}{2 \\sigma^{4}} s=0 \\\\ \\Longleftrightarrow & \\frac{N}{2 \\sigma^{2}}=\\frac{s}{2 \\sigma^{4}} \\end{aligned} 所以得到的极大似然估计的结果为： \\sigma^2=\\frac{s}{N}=\\frac{1}{N}\\sum^N_{n-1}(y_n-\\phi^\\top(\\boldsymbol x_n)\\theta)^2 the maximum likelihood estimate of the noise variance is the empirical mean of the squared distances between the noise-free function values and the corresponding noisy observations at input locations . 线性回归中的过拟合（Overfitting in Linear Regression）我们可以使用均方根误差（root mean square error，RMSE）来衡量一个模型的好坏： \\sqrt{\\frac{1}{N}\\|y-\\Phi\\boldsymbol\\theta\\|^2}=\\sqrt{\\frac{1}{N}\\sum^N_{n=1}(y_n-\\phi^\\top(x_n)\\boldsymbol\\theta)^2}噪声参数不是一个自由模型参数，所以没有直接加到上式，所以没有包含到上面，这样做的好处就是能够使得计算前后的量纲保持一致。当多项式的次数小于训练样本数量的时候，可以得到一个唯一的极大似然估计值，当大于的时候，需要求解一个欠定方程组（有无穷多解的方程组），这样得到无穷多的估计值。采用不同级别的多项式模型拟合10个数据的结果如下图：各个模型的均方根误差：注意一点，训练集的RMSE不会增加。 极大后验估计（Maximum A Posteriori Estimation）当出现过拟合的时候，参数的数值会变得很大，为了解决这个问题，我们可以使用先验分布。这个先验分布标明了参数值在什么范围内是合理的。例如一个高斯先验,这个信息中暗示了参数的范围应该在之间（）.当数据集可用的时候，我们需要去找能够最大化后验分布的参数值,这个过程称为极大后验估计（Maximum a Posteriori Estimation,MAP）,后验分布可以利用贝叶斯公式求解： p(\\theta|\\mathcal X,\\mathcal Y)=\\frac{p(\\mathcal Y|\\mathcal X, \\theta)p(\\theta)}{p(\\mathcal Y|\\mathcal X)} 要求出参数向量,我们需要遵循与极大似然估计一致的方法，首先，先自然对数转换（log-transform）： \\log p(\\theta|\\mathcal X,\\mathcal Y)=\\log p(\\mathcal Y|\\mathcal X,\\theta)+\\log p(\\theta)+\\operatorname{const}其中，中包含独立于的项。可以看到，后验似然估计是参数先验（在输入数据之前的对参数的认知）和依赖于数据的似然之间的折中。要求的参数向量，我们要： \\theta_{MAP}\\in\\arg \\min_\\theta\\{-\\log p(\\mathcal Y|\\mathcal X,\\theta)-\\log p(\\theta)\\}将负对数后验对进行求导： -\\frac{\\mathrm{d} \\log p(\\boldsymbol{\\theta} \\mid \\mathcal{X}, \\mathcal{Y})}{\\mathrm{d} \\boldsymbol{\\theta}}=-\\frac{\\mathrm{d} \\log p(\\mathcal{Y} \\mid \\mathcal{X}, \\boldsymbol{\\theta})}{\\mathrm{d} \\theta}-\\frac{\\mathrm{d} \\log p(\\boldsymbol{\\theta})}{\\mathrm{d} \\theta} 第一项是之前提到的负自然对数似然的梯度： \\begin{aligned} \\frac{\\mathrm{d} \\mathcal{L}}{\\mathrm{d} \\theta} &=\\frac{\\mathrm{d}}{\\mathrm{d} \\theta}\\left(\\frac{1}{2 \\sigma^{2}}(y-X \\theta)^{\\top}(y-X \\theta)\\right) \\\\ &=\\frac{1}{2 \\sigma^{2}} \\frac{\\mathrm{d}}{\\mathrm{d} \\theta}\\left(y^{\\top} y-2 y^{\\top} X \\theta+\\theta^{\\top} \\boldsymbol{X}^{\\top} \\boldsymbol{X} \\theta\\right) \\\\ &=\\frac{1}{\\sigma^{2}}\\left(-\\boldsymbol{y}^{\\top} \\boldsymbol{X}+\\boldsymbol{\\theta}^{\\top} \\boldsymbol{X}^{\\top} \\boldsymbol{X}\\right) \\in \\mathbb{R}^{1 \\times D} \\end{aligned} 利用参数的一个（共轭）高斯先验: -\\log p(\\theta \\mid \\mathcal{X}, \\mathcal{Y})=\\frac{1}{2 \\sigma^{2}}(y-\\Phi \\theta)^{\\top}(y-\\Phi \\theta)+\\frac{1}{2 b^{2}} \\theta^{\\top} \\theta+\\text { const } 这里有点疑问，利用了 p(y|\\boldsymbol x,\\theta)=\\mathcal N(y|\\phi^\\top(x)\\boldsymbol\\theta,\\sigma^2)\\Longleftrightarrow y=\\phi^\\top(x)\\boldsymbol\\theta+\\epsilon=\\sum^{K-1}_{k=0}\\theta_k\\phi_k(x)+\\epsilon？？ 上式右边的第一个式子来源于自然对数似然，第二个式子来源于自然对数先验。所以自然对数先验对的先验为： -\\frac{d\\log p(\\theta|\\mathcal X,\\mathcal Y)}{d\\theta}=\\frac{1}{\\sigma^2}(\\theta^\\top\\Phi^\\top\\Phi-y^\\top\\Phi)+\\frac{1}{b^2}\\theta^\\top将梯度设置为0： \\begin{aligned} & \\frac{1}{\\sigma^{2}}\\left(\\theta^{\\top} \\Phi^{\\top} \\Phi-y^{\\top} \\Phi\\right)+\\frac{1}{b^{2}} \\theta^{\\top}=0^{\\top} \\\\ \\Longleftrightarrow & \\theta^{\\top}\\left(\\frac{1}{\\sigma^{2}} \\Phi^{\\top} \\Phi+\\frac{1}{b^{2}} I\\right)-\\frac{1}{\\sigma^{2}} y^{\\top} \\Phi=0^{\\top} \\\\ \\Longleftrightarrow & \\theta^{\\top}\\left(\\Phi^{\\top} \\Phi+\\frac{\\sigma^{2}}{b^{2}} I\\right)=y^{\\top} \\Phi \\\\ \\Longleftrightarrow & \\theta^{\\top}=y^{\\top} \\Phi\\left(\\Phi^{\\top} \\Phi+\\frac{\\sigma^{2}}{b^{2}} I\\right)^{-1} \\end{aligned}整理得： \\theta_{MAP}=(\\Phi^\\top\\Phi+\\frac{\\sigma^2}{b^2}I)^{-1}\\Phi^\\top y与极大似然估计的结果：相比较，只是在逆当中多了一项，这一项保证了是一个对称严格正定的。也就是说这个矩阵是可逆的，而且是线性方程的唯一解。同时他也反应了正则项(regularizer)的影响的大小 虽然先验能够让高次多项式变得更加光滑，但也是仅仅将过拟合的边界向后推移了，想要解决过拟合的问题需要其他的方法。 极大后验估计作为正则化带正则项的最小二乘的损失函数为： \\|\\boldsymbol y-\\boldsymbol\\Phi\\boldsymbol\\theta\\|^2+\\lambda\\|\\boldsymbol\\theta\\|_2^2这里的范数采用的是-范数,当的值越小，得到的结果中的个数就越多。当时，被称为最小绝对收缩和选择算子（least absolute shrinkage and selection operator，LASSO） 上式中的正则项可以理解为极大后验估计中的高斯自然对数先验（negative log-Gaussian prior），具体来说，对于一个正态分布的高斯自然对数先验为： -\\log p(\\boldsymbol\\theta)=\\frac{1}{2b^2}\\|\\boldsymbol \\theta\\|^2_2+\\operatorname{const}这里的正则项为与极大后验估计的先验一致。这样看来，正则化后的最小二乘损失函数包含的项与负自然对数似然和负自然对数先验有紧密关系，所以最小化最小二乘损失函数的过程与极大后验估计一致.最小化带正则项的最小二乘损失函数（regularized least-squares loss function）： \\boldsymbol\\theta_{RLS}=(\\boldsymbol\\Phi^\\top\\boldsymbol\\Phi+\\lambda \\boldsymbol I)^{-1}\\boldsymbol\\Phi^\\top \\boldsymbol y这个与极大后验估计一致，这里的正则项为,其中，是噪声方差，为（各向同性）高斯先验方差至此，我们讨论的都是点估计得到，以对目标函数进行优化。接下来我们讨论使用贝叶斯推断，通过获得所有合理的参数的均值得到优化结果。 贝叶斯线性回归（Bayesian Linear Regression）先前讨论的是采用极大似然估计和极大后验估计来估计模型的参数，极大似然估计容易出现过拟合的现象，尤其是在训练集比较小的时候。极大后验估计使用一个概率先验来解决这个问题。而贝叶斯回归不求出单一的参数，而是选择求所有合理的参数的均值。 模型（Model）\\begin{aligned}&prior \\quad p(\\boldsymbol\\theta)=\\mathcal N(\\boldsymbol m_0,\\boldsymbol S_0)\\\\ & likelihood\\quad p(y|\\boldsymbol x,\\boldsymbol\\theta)=\\mathcal (y|\\phi^\\top(x)\\boldsymbol\\theta,\\sigma)\\end{aligned}对应的图模型： 已观测变量与未观测变量的联合概率分布为： p(y,\\boldsymbol\\theta|x)=p(y|\\theta,x)p(\\boldsymbol\\theta) 推导过程 p(y,\\theta|x)=\\frac{p(y|\\theta,x)p(\\theta ,x)}{p(x)}=p(y|\\theta,x)\\cdot p(\\theta|x)所以x与是相互独立的？应该是与验证数据无关 预测先验（Prior Predictions）预测的最终目的不是获得模型的参数，而是获得预测值，在贝叶斯回归中，预测值是所有合理参数的预测值的均值： p(y_*|x_*)=\\int p(y_*|\\boldsymbol x_*,\\boldsymbol\\theta)p(\\boldsymbol\\theta)d\\boldsymbol\\theta=\\mathbb E_\\theta[p(y_*|\\boldsymbol x_*,\\boldsymbol\\theta)] 连续概率分布的均值，样品值乘以样品出现的概率，将他们之和加起来，得到均值 我们选取一个的（共轭）高斯先验作为模型，于是可以知道预测结果也是高斯分布，对于一个先验分布,对应的预测结果的分布为： p(y_*|\\boldsymbol x_*)=\\mathcal N(\\boldsymbol\\phi^\\top(\\boldsymbol x_*)\\boldsymbol m_0,\\phi^\\top(\\boldsymbol x_*)\\boldsymbol S_0\\phi(\\boldsymbol x_*)+\\sigma^2)贝叶斯回归模型为： p(\\theta) =\\mathcal N(m_0,S_0)\\\\ p(y|x,\\theta)=\\mathcal N(y|\\phi^\\top\\theta,\\sigma^2)x与y的对应关系为：$y^=\\phi^\\top(x^)\\theta所以对应的均值为：\\phi^\\top m_0由\\mathbb V_Y[y]=\\mathbb V_X[Ax+b]=\\mathbb V_X[Ax]=A\\mathbb V_X A^\\top=A\\Sigma A^\\top的对应的方差为：\\phi^\\top(x_)S_0\\phi(x_)$,加上噪声项即为上式 上式中的是由于测量误差导致的不确定分布。这里预测值是高斯分布是因为高斯共轭和边际化的性质。由于高斯噪音是相互独立的，所以： \\mathbb V[y_*]=\\mathbb V_\\boldsymbol\\theta[\\phi^\\top(x_*)\\boldsymbol\\theta]+\\mathbb V_\\epsilon[\\epsilon]如果我们考虑无噪音函数：$f(\\boldsymbol x_)=\\phi^\\top(x_)\\boldsymbol\\theta$ p(f(x_*))=\\mathcal N(\\phi^\\top(x_*)m_0,\\phi^\\top(x_*)S_0\\phi(x_*))这个式子与原先式子不同之处在于少了噪音项函数分布（Distribution over Functions）：我们可以用一系列的参数表示参数分布,而每一个参数对应一个函数于是可以得到对应函数的分布 p305 没弄清楚 置信区间和置信边界 后验分布（Posterior Distribution）利用贝叶斯公式可以计算参数的后验分布： p(\\theta|\\mathcal X,\\mathcal Y)=\\frac{p(\\mathcal Y|\\mathcal X, \\theta)p(\\theta)}{p(\\mathcal Y|\\mathcal X)}其中是训练的输入值，是训练目标。其中的边际似然（marginal likelihood/evidence）与参数无关： p(\\mathcal Y|\\mathcal X)=\\int p(\\mathcal Y|\\mathcal X, \\theta)p(\\theta)d\\theta=\\mathbb E_\\theta[p(\\mathcal Y|\\mathcal X,\\theta)]边际似然可以被看成是所有合理参数下预测值的均值。参数后验： \\begin{aligned}p(\\boldsymbol\\theta|\\mathcal X, \\mathcal Y) & =\\mathcal N(\\boldsymbol\\theta |\\boldsymbol m_N,\\boldsymbol S_N)\\\\ \\boldsymbol S_N &=(\\boldsymbol S_0^{-1}{+\\sigma^{-2}}\\Phi^\\top\\Phi)^{-1}\\\\\\boldsymbol m_N&=\\boldsymbol S_N(\\boldsymbol S_0^{-1}\\boldsymbol m_0+\\sigma^{-2}\\Phi^\\top \\boldsymbol y)\\end{aligned}其中的N代表的是训练集的大小。证明： 证明思路类似是用两种方式将参数后验表示出来，然后将对应部分的进行对比，得到想要的参数。 由贝叶斯公式可以得知，后验概率分布与似然概率分布和先验概率分布成比例 \\begin{array}{ll} \\text { Posterior } & p(\\boldsymbol{\\theta} \\mid \\mathcal{X}, \\mathcal{Y})=\\frac{p(\\mathcal{Y} \\mid \\mathcal{X}, \\boldsymbol{\\theta}) p(\\boldsymbol{\\theta})}{p(\\mathcal{Y} \\mid \\mathcal{X})} \\\\ \\text { Likelihood } & p(\\mathcal{Y} \\mid \\mathcal{X}, \\boldsymbol{\\theta})=\\mathcal{N}\\left(\\boldsymbol{y} \\mid \\boldsymbol{\\Phi} \\boldsymbol{\\theta}, \\sigma^{2} \\boldsymbol{I}\\right) \\\\ \\text { Prior } & p(\\boldsymbol{\\theta})=\\mathcal{N}\\left(\\boldsymbol{\\theta} \\mid \\boldsymbol{m}_{0}, \\boldsymbol{S}_{0}\\right) \\end{array}现在考虑自然对数先验与自然对数似然之和： \\begin{aligned}&\\log \\mathcal N(y|\\Phi\\theta,\\sigma^2 I)+\\log \\mathcal N(\\theta|m_0,S_0)\\\\&=-\\frac{1}{2}(\\sigma^{-2}(y-\\Phi\\theta)^\\top(y-\\Phi\\theta)+(\\theta-m_0)^\\top S_0^{-1}(\\theta-m_0))+\\operatorname{const}\\end{aligned}其中的const包含一些独立于的项。将上式进行展开：（将式子中的二次项一次项进行整合） \\begin{aligned} &-\\frac{1}{2}\\left(\\sigma^{-2} \\boldsymbol{y}^{\\top} \\boldsymbol{y}-2 \\sigma^{-2} \\boldsymbol{y}^{\\top} \\Phi \\theta+\\boldsymbol{\\theta}^{\\top} \\sigma^{-2} \\boldsymbol{\\Phi}^{\\top} \\boldsymbol{\\Phi} \\boldsymbol{\\theta}+\\boldsymbol{\\theta}^{\\top} \\boldsymbol{S}_{0}^{-1} \\boldsymbol{\\theta}\\right.\\\\ &\\left.-2 m_{0}^{\\top} S_{0}^{-1} \\theta+\\boldsymbol{m}_{0}^{\\top} \\boldsymbol{S}_{0}^{-1} \\boldsymbol{m}_{0}\\right) \\\\ =&-\\frac{1}{2}\\left(\\boldsymbol{\\theta}^{\\top}\\left(\\sigma^{-2} \\boldsymbol{\\Phi}^{\\top} \\boldsymbol{\\Phi}+\\boldsymbol{S}_{0}^{-1}\\right) \\boldsymbol{\\theta}-2\\left(\\sigma^{-2} \\Phi^{\\top} y+S_{0}^{-1} m_{0}\\right)^{\\top} \\theta\\right)+\\mathrm{const} \\end{aligned}我们可以发现上式与呈二次关系。 The fact that the unnormalized log-posterior distribution is a (negative) quadratic form implies that the posterior is Gaussian p(\\theta|\\mathcal X,\\mathcal Y)=\\exp(\\log p(\\theta|\\mathcal X,\\mathcal Y))\\propto \\exp(\\log p(\\mathcal Y|\\mathcal X,\\theta)+\\log p(\\theta))\\\\ \\propto \\exp(-\\frac{1}{2}(\\theta^\\top(\\sigma^{-2}\\Phi^\\top\\Phi+S_0^{-1})\\theta-2(\\sigma^{-2}\\Phi^\\top y+S_0^{-1}m_0)^\\top \\theta))最后需要从上式中找到均值和方差矩阵()： \\log \\mathcal{N}\\left(\\boldsymbol{\\theta} \\mid \\boldsymbol{m}_{N}, \\boldsymbol{S}_{N}\\right)=-\\frac{1}{2}\\left(\\boldsymbol{\\theta}-\\boldsymbol{m}_{N}\\right)^{\\top} \\boldsymbol{S}_{N}^{-1}\\left(\\boldsymbol{\\theta}-\\boldsymbol{m}_{N}\\right)+ const\\\\=-\\frac{1}{2}\\left(\\theta^{\\top} S_{N}^{-1} \\theta-2 m_{N}^{\\top} S_{N}^{-1} \\theta+\\boldsymbol{m}_{N}^{\\top} \\boldsymbol{S}_{N}^{-1} \\boldsymbol{m}_{N}\\right)通过比较上面二式可以得到： \\begin{array}{c} S_{N}^{-1}=\\Phi^{\\top} \\sigma^{-2} \\boldsymbol{I} \\Phi+S_{0}^{-1} \\\\ \\Longleftrightarrow \\boldsymbol{S}_{N}=\\left(\\sigma^{-2} \\boldsymbol{\\Phi}^{\\top} \\boldsymbol{\\Phi}+\\boldsymbol{S}_{0}^{-1}\\right)^{-1} \\\\ \\\\ \\boldsymbol{m}_{N}^{\\top} \\boldsymbol{S}_{N}^{-1}=\\left(\\sigma^{-2} \\boldsymbol{\\Phi}^{\\top} \\boldsymbol{y}+\\boldsymbol{S}_{0}^{-1} \\boldsymbol{m}_{0}\\right)^{\\top} \\\\ \\Longleftrightarrow \\boldsymbol{m}_{N}=\\boldsymbol{S}_{N}\\left(\\sigma^{-2} \\boldsymbol{\\Phi}^{\\top} \\boldsymbol{y}+\\boldsymbol{S}_{0}^{-1} \\boldsymbol{m}_{0}\\right) \\end{array} 完全平方的一般方法（General Approach to Completing the Squares）对于一个等式(是一个堆成正定矩阵)： x^\\top A^\\top x-2a^\\top x+const_1可以得到： (x-\\mu)^\\top \\Sigma(x-\\mu)+const_2其中，这部分需要补充 后验预测（Posterior Predictions） \\begin{aligned} p\\left(y_{*} \\mid \\mathcal{X}, \\mathcal{Y}, \\boldsymbol{x}_{*}\\right) &=\\int p\\left(y_{*} \\mid \\boldsymbol{x}_{*}, \\boldsymbol{\\theta}\\right) p(\\boldsymbol{\\theta} \\mid \\mathcal{X}, \\mathcal{Y}) \\mathrm{d} \\boldsymbol{\\theta} \\\\ &=\\int \\mathcal{N}\\left(y_{*} \\mid \\phi^{\\top}\\left(\\boldsymbol{x}_{*}\\right) \\boldsymbol{\\theta}, \\sigma^{2}\\right) \\mathcal{N}\\left(\\boldsymbol{\\theta} \\mid \\boldsymbol{m}_{N}, \\boldsymbol{S}_{N}\\right) \\mathrm{d} \\boldsymbol{\\theta} \\\\ &=\\mathcal{N}\\left(y_{*} \\mid \\phi^{\\top}\\left(\\boldsymbol{x}_{*}\\right) \\boldsymbol{m}_{N}, \\boldsymbol{\\phi}^{\\top}\\left(\\boldsymbol{x}_{*}\\right) \\boldsymbol{S}_{N} \\phi\\left(\\boldsymbol{x}_{*}\\right)+\\sigma^{2}\\right) \\end{aligned}右式中的第一个分布式利用训练得到的参数和输入值计算之后得到的结果的分布（$y^=\\phi(x^)\\theta）第二个分布是用训练集训练得到的参数\\theta\\phi^\\top(x_)S_N\\phi(x_)$表示关于后验的不确定性.上式可以等价地写成 \\mathbb E_{\\theta|\\mathcal X,\\mathcal Y}[p(y_*|x_*,\\theta)] 分布方程（Distribution over Functions）当我们使用积分将参数消掉时，我们得到了一个分布函数：如果我们从中取样，我们可以得到方程。均值方程为所有预测值的期望,函数的方差为从中对参数进行抽样,表示为第三张图： 无噪音函数值的均值和方差（Mean and Variance of Noise-Free Function Values）在很多情况下，我们并不关心(含噪音的)预测值的分布$p(y_|\\mathcal X, \\mathcal Y,x_)。我们更关注于无噪音的函数值f(x_)=\\phi^\\top(x_)\\theta$,可以得到该函数的均值和方差： \\begin{aligned} \\mathbb{E}\\left[f\\left(\\boldsymbol{x}_{*}\\right) \\mid \\mathcal{X}, \\mathcal{Y}\\right]=& \\mathbb{E}_{\\boldsymbol{\\theta}}\\left[\\phi^{\\top}\\left(\\boldsymbol{x}_{*}\\right) \\boldsymbol{\\theta} \\mid \\mathcal{X}, \\mathcal{Y}\\right]=\\phi^{\\top}\\left(\\boldsymbol{x}_{*}\\right) \\mathbb{E}_{\\boldsymbol{\\theta}}[\\boldsymbol{\\theta} \\mid \\mathcal{X}, \\mathcal{Y}] \\\\ &=\\phi^{\\top}\\left(\\boldsymbol{x}_{*}\\right) \\boldsymbol{m}_{N}=\\boldsymbol{m}_{N}^{\\top} \\phi\\left(\\boldsymbol{x}_{*}\\right), \\\\ \\mathbb{V}_{\\boldsymbol{\\theta}}\\left[f\\left(\\boldsymbol{x}_{*}\\right) \\mid \\mathcal{X}, \\mathcal{Y}\\right] &=\\mathbb{V}_{\\boldsymbol{\\theta}}\\left[\\phi^{\\top}\\left(\\boldsymbol{x}_{*}\\right) \\boldsymbol{\\theta} \\mid \\mathcal{X}, \\mathcal{Y}\\right] \\\\ &=\\phi^{\\top}\\left(\\boldsymbol{x}_{*}\\right) \\mathbb{V}_{\\boldsymbol{\\theta}}[\\boldsymbol{\\theta} \\mid \\mathcal{X}, \\mathcal{Y}] \\phi\\left(\\boldsymbol{x}_{*}\\right) \\\\ &=\\phi^{\\top}\\left(\\boldsymbol{x}_{*}\\right) \\boldsymbol{S}_{N} \\phi\\left(\\boldsymbol{x}_{*}\\right) \\end{aligned}我们可以发现均值与含噪音观测的均值一致，因为噪音的均值为0，因为噪音的方差为,所以当预测含噪音的函数值时，需要加上，无噪音的时候则不需要。还是没能很好地理解噪音这个概念 上图是由参数后验得到的后验分布。由上图可知，当多项式为低阶的时候，参数的分布不会很分散。而对于高阶的贝叶斯回归模型，后验概率的不确定性很大，这个信息对于决策系统（decision-making system）很重要。 边际似然的计算（Computing the Marginal Likelihood）在本节中，我们介绍参数为共轭高斯先验的贝叶斯线性回归的边际似然的计算。考虑以下参数形成的过程： \\begin{aligned}\\theta&\\sim \\mathcal N(m_0,S_0)\\\\y_n|x_n, \\theta&\\sim\\mathcal N(x_n^\\top\\theta,\\sigma^2),\\quad n=1,\\dots,N\\end{aligned}则对应的边际似然为： \\begin{aligned} p(\\mathcal Y|\\mathcal X)&=\\int p(\\mathcal Y|\\mathcal X, \\theta)p(\\theta)d\\theta\\\\&=\\int \\mathcal N(y|X\\theta,\\sigma^2I)\\mathcal N(\\theta|m_0,S_0)d\\theta\\end{aligned}上面这个式子可以理解为参数先验下的似然的期望：计算边际似然需要两个步骤，首先先确定边际似然是高斯分布，然后计算出这个高斯分布的均值和方差。由高斯分布的性质，两个高斯分布的乘积仍旧是高斯分布。下面开始计算这个高斯分布的均值和方差： \\mathbb E[\\mathcal Y|\\mathcal X]=\\mathbb E_{\\theta,\\epsilon}[X\\theta+\\epsilon]=X\\mathbb E_\\theta[\\theta]=Xm_0,\\quad \\epsilon \\sim \\mathcal N(0,\\sigma^2I)方差为： \\begin{aligned}\\operatorname{Cov}[\\mathcal Y|\\mathcal X]&=\\operatorname{Cov}_{\\theta,\\epsilon}[X\\theta+\\epsilon]=\\operatorname{Cov}[X\\theta]+\\sigma^2I\\\\ &=X\\operatorname{Cov}_\\theta[\\theta]X^\\top+\\sigma^2I=XS_0X^\\top+\\sigma^2I\\end{aligned}所以，边际似然为： \\begin{aligned} p(\\mathcal{Y} \\mid \\mathcal{X})=&(2 \\pi)^{-\\frac{N}{2}} \\operatorname{det}\\left(\\boldsymbol{X} \\boldsymbol{S}_{0} \\boldsymbol{X}^{\\top}+\\sigma^{2} \\boldsymbol{I}\\right)^{-\\frac{1}{2}} \\\\ & \\cdot \\exp \\left(-\\frac{1}{2}\\left(\\boldsymbol{y}-\\boldsymbol{X} \\boldsymbol{m}_{0}\\right)^{\\top}\\left(\\boldsymbol{X} \\boldsymbol{S}_{0} \\boldsymbol{X}^{\\top}+\\sigma^{2} \\boldsymbol{I}\\right)^{-1}\\left(\\boldsymbol{y}-\\boldsymbol{X} \\boldsymbol{m}_{0}\\right)\\right) \\\\&=\\mathcal N(y|Xm_0,XS_0X^\\top+\\sigma^2I) \\end{aligned} 与之前的内容进行联系，为什么形式是这样的？ 用正交投影解释极大似然估计（Maximum Likelihood as Orthogonal Projection）考虑一个简单的线性规划模型： y=x\\theta+\\epsilon,\\quad \\epsilon \\sim \\mathcal N(0,\\sigma^2)由原先的提到的极大似然估计，得到斜率参数： \\theta_{ML}=(X^\\top X)^{-1}X^\\top y=\\frac{X^\\top y}{X^\\top X}\\in \\mathbb R其中，和为训练集中的元素(都是向量，所以为标量，这也是将这一项放到分母的原因)。所以对应的目标为： X\\theta_{ML}=X\\frac{X^\\top y}{X^\\top X}=\\frac{XX^\\top}{X^\\top X}y所以可以理解为，我们的目标是找到的解。由原先的线性代数和解析几何，可以将上式理解为y在X张成的一维子空间的正交投影，其中为投影矩阵,为y在一维子空间中的正交投影的坐标，为在这个子空间中的正交投影。所以，极大似然估计的解得到的是在子空间中找到一个与观测值最接近的向量。这里的距离表示和 的最短（平方）距离 在广义的线性规划中： y=\\phi^\\top(x)\\theta+\\epsilon,\\quad \\epsilon \\sim \\mathcal N(0,\\sigma^2)其中,,利用极大似然估计得到参数结果： \\boldsymbol y\\approx \\Phi\\theta_{ML}\\\\\\theta_{ML}=(\\Phi^\\top\\Phi)^{-1}\\Phi^\\top \\boldsymbol y上式实际上就是一个往特征矩阵张成的K维子空间的投影。若将特征矩阵构造成规范正交，这时候就形成了一个规范正交基。因为所以，对应的投影为： \\Phi(\\Phi^\\top\\Phi)^{-1}\\Phi^\\top \\boldsymbol y = \\Phi\\Phi^\\top \\boldsymbol y=\\begin{pmatrix} \\sum\\limits^K_{k=1}\\phi_k\\phi_k^\\top\\end{pmatrix}\\boldsymbol y所以极大似然的投影这时候就是y向基向量的投影的和。 这部分需要深入理解一下，为什么？the coupling between different features has disappeared due to the orthogonality of the basis. Further Reading:1.In deffenrent cases we may choose deffenrent model functions which corresponding to the likelihood function2.generalized linear models:there is a a smooth and invertible function (which could be nonlinear), so that ,where which also . The first one is activate function, and the later one is linear function model. This can form a neural network model.,where A is weight matrix, b is bias vector so: \\begin{aligned} x_{k+1}&=f_k(x_k)\\\\f_k(x_k)&=\\sigma_k(A_kx_k+b_k)\\end{aligned}This is a K-layer deep neural network()","link":"/2021/06/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92Linear-Regression/"},{"title":"机器学习中的数学：（三）矩阵分解(Matrix Decompositions)","text":"@[toc]矩阵分解可以用于压缩矩阵，以尽可能少的空间存储一个矩阵，同时损失尽可能少的信息。同时对数据进行降维还可以减少发生维度灾难的发生。 维数灾难： 当数据维度提升的时候，因为空间体积提升过快，因而可用数据变得很稀疏。然而在高维空间中，所有的数据都很稀疏，从很多角度看都不相似，因而平常使用的数据组织策略变得极其低效。在机器学习问题中，需要在高维特征空间（每个特征都能够取一系列可能值）的有限数据样本中学习一种“自然状态”（可能是无穷分布），要求有相当数量的训练数据含有一些样本组合。给定固定数量的训练样本，其预测能力随着维度的增加而减小，这就是所谓的Hughes影响或Hughes现象（以Gordon F. Hughes命名）。 ———Wiki个人理解：随着维度的升高数据之间的距离加大，这导致数据组合而成的用于最终判断的特征难以被发现 行列式与迹（Determinant and Trace）行列式（Dterminant）行列式可以看成将一个方阵映射成一个实数。（只有方阵才有行列式）可以将行列式用于判断一个方阵是否可逆： 对于上/下三角矩阵的行列式的值为: \\operatorname{det}(\\boldsymbol{T})=\\prod_{i=1}^{n} T_{i i}对于n阶行列的计算，可以使用拉普拉斯展开(Laplace Expansion) 行列式的几何含义就是带有符号的多边形的体积，这个多边形是由行列式所对应的列向量通过平移之后组成的.注意到当至少其中的两个向量重合的时候，也就是这两个向量线性相关的时候，他们组成的几何体的体积为0，所以这时候他们组成的方阵的行列式为0.行列式的一些性质： 迹(Trace)假设是矩阵A的特征多项式，那么A的迹为： \\operatorname{tr}(\\boldsymbol A)=\\sum^k_{i=1}d_i\\lambda_i对于一个方阵的迹就是它所有对角线元素的和： tr(\\bold A):=\\sum\\limits_{i=1}^na_{ii}迹的一些性质：假设、是向量空间U的两个基向量，所以一定存在一个向量,使得: \\operatorname{tr}(\\boldsymbol{B})=\\operatorname{tr}\\left(\\boldsymbol{S}^{-1} \\boldsymbol{A} \\boldsymbol{S}\\right) \\stackrel{(4.19)}{=} \\operatorname{tr}\\left(\\boldsymbol{A} \\boldsymbol{S} \\boldsymbol{S}^{-1}\\right)=\\operatorname{tr}(\\boldsymbol{A})特征多项式：其中： c_0=det(\\bold A) \\\\ c_{n-1}=(-1)^{n-1}tr(\\bold A)特征多项式可以用于求解特征值和特征向量。 特征值与特征向量 特征向量不是唯一的，与特征向量共线的所有向量都是这个矩阵的特征向量。共线与共向：特征值是矩阵特征多项式的一个根。代数重度（algebraic multiplicity）：该特征是特征向量的几重根。特征空间：特征值对应的特征向量组成的向量空间就是特征空间 有疑问特征向量所张成的空间就是特征向量通过线性映射之后得到的。而特征向量所对应的特征值的正负对应着特征向量的指向的方向 特征值的几个非常有用的性质：1.矩阵和他的转置的特征值一样，但是特征向量不一定一样2.观察特征方程,这说明对应着核空间 3.相似矩阵（）的特征值保持一致，说明特征值是与基向量无关的（拥有这种性质的还有迹和行列式）4.正定矩阵拥有正的实特征值。 几何重度（Geometric Multiplicity，特征空间的维度）：对应的线性无关的特征向量的个数。 为什么？ 二维空间中的几何直观理解：对于特征方程（），等式右边是对向量x的一个变换（变换矩阵为A），右边为对x的一个伸展，二者相等，说明在经历过变换之后，x向量只是简单地发生了范数地增长，并没有离开原先地向量空间。而这个变换之后不离开原先向量空间的向量称为特征向量。特征向量组成的向量空间，称为特征空间，在特征空间中的所有向量经过变换之后也不会离开原先的张成空间。向量延展的倍数为变换矩阵的特征值特征向量与特征值的求解过程：由特征方程得到：当为零向量的时候，等式成立，但是我们想要一个非零向量，所以原来的式子的含义就变成，将一个向量压缩成一个零向量，这就是说在经过变换之后原先的向量发生了降维，这就是说不是满秩的，就好像是一个三维体经过变换之后变成了二维，这时候变换之后的几何体的体积变成了0，也就是相对应的行列式变成了0，所以、 下图是不同类型的线性映射时候特征值和行列式的情况：其中 为什么最后一个的行列式的值发生了变化？ 每一个特征空间在变换中对应着唯一一个特征值（倍数），所以当倍数（特征值）全部都是不同的时候，说明有所有的特征向量都是线性无关的。亏损矩阵对于一个非亏损矩阵（）不一定需要n个不同的特征值，但是一定需要n个特征向量组成的基。（注意到不同的向量在变换的时候延伸的倍数是可以一样的，所以会有一个特征值对应几个特征向量的情况） 谱定律：这说明一个对称矩阵可以进行特征分解,也就是说能够找到特征向量对应的规范正交基，使得其中D为对角矩阵，P由特征向量组成。 行列式与迹的意义：分别与面积（体积）和周长相关 柯列斯基分解（Cholesky Decomposition） 计算方式： 这在深度学习中有很多的应用，同时还可以用于计算行列式（上下三角矩阵的行列式非常好计算） 特征分解和对角化可对角化的条件：这需要P矩阵是满秩的特征分解这实际上就是A与D相似。P由A的特征向量组成，D由A的特征值组成（对角矩阵） 如何理解相似矩阵？如何理解谱定理？ 矩阵分解的几何直观理解 各部分对应的变换还是不是很清楚。特征值分解可以这样理解，首先先进行一次基变换，将正交基变换至由特征向量组成的向量空间中，然后进行延展（这就是变换矩阵A对应在特征向量中的变换Ax=）,最后将向量空间复原到原先的向量空间中。 对待方程,可以这样想，单位矩阵经过A矩阵变换之后等价于三个矩阵变化之后的结果。将一个矩阵分解之后，可以很方便地计算矩阵地行列式和n次方。 det(\\bold A)=det(\\bold P\\bold D\\bold P^{-1})=det(\\bold P)*det(\\bold D)*det(\\bold P^{-1})=\\prod_id_{ii}奇异值分解（Singular Value Decomposition，SVD）相对于特征值分解，奇异值分解使用范围更广，它不要求分解的矩阵是方阵。𝕦称为左奇异向量；𝕧称为右奇异向量。 矩阵起到拓展维度的作用，所以： SVD的几何直观解释 奇异值分解其实和特征值分解类似，只是在延伸的时候加了一些东西，这是因为矩阵为非方阵的时候，这样的变换会使向量发生维度的变化，所以矩阵在不是方阵的情况下，不仅仅使向量进行相对应的变换，还将维度进行了提升。 起到旋转的作用，起到拓展上域（codomain，到达域）维度的作用，最后U帮助向量升维。 上域 一个变换实例： 求解矩阵的SVD对于一个对称正定矩阵（SPD矩阵）有:所以一个SDP矩阵的SVD就是它的特征值分解。 计算一个矩阵,等价于求解上域（codomain）和定义域（domain）的规范正交基 What’s the graphic intuitions?And why? 求解右奇异向量 由谱定理得知，对称矩阵的特征向量组成规范正交基，也就是说对称矩阵能够相似对角化。而我们可以通过的方式得到一个半正定的对称矩阵。 \\boldsymbol{A}^{\\top} \\boldsymbol{A}=\\boldsymbol{P} \\boldsymbol{D} \\boldsymbol{P}^{\\top}=\\boldsymbol{P}\\left[\\begin{array}{ccc}\\lambda_{1} & \\cdots & 0 \\\\ \\vdots & \\ddots & \\vdots \\\\ 0 & \\cdots & \\lambda_{n}\\end{array}\\right] \\boldsymbol{P}^{\\top}将SVD带入： \\boldsymbol{A}^{\\top} \\boldsymbol{A}=\\left(\\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\right)^{\\top}\\left(\\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\right)=\\boldsymbol{V} \\boldsymbol{\\Sigma}^{\\top} \\boldsymbol{U}^{\\top} \\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}由于是正交矩阵，所以: \\boldsymbol{A}^{\\top} \\boldsymbol{A}=\\boldsymbol{V} \\boldsymbol{\\Sigma}^{\\top} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}=\\boldsymbol{V}\\left[\\begin{array}{ccc}\\sigma_{1}^{2} & 0 & 0 \\\\ 0 & \\ddots & 0 \\\\ 0 & 0 & \\sigma_{n}^{2}\\end{array}\\right] \\boldsymbol{V}^{\\top}由此可以得出，A的SVD的奇异值就是的特征值的开根号的结果。其特征矩阵就是右奇异矩阵。 对于左奇异矩阵采取相似的方式： \\begin{aligned} \\boldsymbol{A} \\boldsymbol{A}^{\\top} &=\\left(\\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\right)\\left(\\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\right)^{\\top}=\\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top} \\boldsymbol{V} \\boldsymbol{\\Sigma}^{\\top} \\boldsymbol{U}^{\\top}\\\\ &=\\boldsymbol{U}\\left[\\begin{array}{ccc} \\sigma_{1}^{2} & 0 & 0 \\\\ 0 & \\ddots & 0 \\\\ 0 & 0 & \\sigma_{m}^{2} \\end{array}\\right] \\boldsymbol{U}^{\\top} . \\end{aligned}现在将左右奇异矩阵联系起来：由于中的向量在经过A矩阵变换之后仍旧是正交向量，因为，\\left(\\boldsymbol{A} \\boldsymbol{v}_{i}\\right)^{\\top}\\left(\\boldsymbol{A} \\boldsymbol{v}_{j}\\right)=\\boldsymbol{v}_{i}^{\\top}\\left(\\boldsymbol{A}^{\\top} \\boldsymbol{A}\\right) \\boldsymbol{v}_{j}=\\boldsymbol{v}_{i}^{\\top}\\left(\\lambda_{j} \\boldsymbol{v}_{j}\\right)=\\lambda_{j} \\boldsymbol{v}_{i}^{\\top} \\boldsymbol{v}_{j}=0，\\quad i\\ne j单位化右奇异向量的像域： \\boldsymbol{u}_{i}:=\\frac{\\boldsymbol{A} \\boldsymbol{v}_{i}}{\\left\\|\\boldsymbol{A} \\boldsymbol{v}_{i}\\right\\|}=\\frac{1}{\\sqrt{\\lambda_{i}}} \\boldsymbol{A} \\boldsymbol{v}_{i}=\\frac{1}{\\sigma_{i}} \\boldsymbol{A} \\boldsymbol{v}_{i} 二者的关系？ 由上得到奇异方程： \\boldsymbol A\\boldsymbol v_i=\\sigma_i\\boldsymbol u_i,\\quad i=1,\\dots,r于是有： \\boldsymbol A\\boldsymbol V=\\Sigma\\boldsymbol U移项得： \\boldsymbol A=\\boldsymbol U\\Sigma\\boldsymbol V^\\top这就是矩阵A的SVD。 矩阵逼近（Matrix Approximation）外积：与内积不同，当两个向量相乘的时候，外积得到的是一个矩阵。有之前的SVD分解式，可以得到下式： \\boldsymbol{A}=\\sum_{i=1}^{r} \\sigma_{i} \\boldsymbol{u}_{i} \\boldsymbol{v}_{i}^{\\top}=\\sum_{i=1}^{r} \\sigma_{i} \\boldsymbol{A}_{i}但是加入我们不讲所有的外积都加上的话，得到一个秩为的矩阵，这个称为k秩逼近（rank-k approximation） \\widehat{\\boldsymbol{A}}(k):=\\sum_{i=1}^{k} \\sigma_{i} \\boldsymbol{u}_{i} \\boldsymbol{v}_{i}^{\\top}=\\sum_{i=1}^{k} \\sigma_{i} \\boldsymbol{A}_{i}谱模（spectral norm）谱模表示，一个向量在经历矩阵A的变换之后最长可以变成多长（下标2代表的是欧几里得空间）。可以证明，矩阵A的谱模就是它的最大的奇异值 埃卡特-杨定理这个定理量化了矩阵近似会造成的误差。 证明过程？ 总结","link":"/2021/04/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%EF%BC%9A%EF%BC%88%E4%B8%89%EF%BC%89%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3-Matrix-Decompositions/"},{"title":"机器学习中的数学：（一）线性代数","text":"本博客是对MATHEMATICS FOR MACHINE LEARNING的学习笔记，因为是全英文的书籍，所以在每节之后都会收集一些相关的术语，然后笔记中也可能会加入一些英文。当然，作为一个个人笔记，我会加入一些自己的理解，这些理解可能会因为自己的能力有限而不够深入并且有较大的局限性，但是，我会不断复习自己的笔记，并不断更新自己的理解。这正如孔子所说的：温故而知新，可以为师矣。ps:想要这本书的电子版可以私信我。pps:我认为大脑能更加轻易地记忆图片，图片会比文字更好理解，所以我会尽可能的多加一些图片在笔记中。 &lt;hr style=” border:solid; width:100px; height:1px;” color=#000000 size=1”&gt; @[toc] 前言这部分讲解了书籍的组成，对书籍的各个章节做了一些简要的介绍，并探讨了书籍的学习方式。总的来说，这本书分为两个部分，上半部分是将一些数学基础包含线性代数(Linear Algebra)、分析几何(Analytic Geometry)、矩阵分解(Matrix Decomposition)和概率论(Probability Theoty)，第二部分是讲解机器学习的四大支柱(pillars)技术。文中提及了两种学习模式：自顶向下和自底向上。两种方法都有各自的优势和劣势。我的学习模式类似于自底向上，先完成数学理论知识的学习然后再将学过的数学知识用于机器学习理论的学习中，这个过程帮助我进一步强化学过的数学知识，就当一个复习的过程。 &lt;hr style=” border:solid; width:100px; height:1px;” color=#000000 size=1”&gt; 一些题外话：在我接触机器学习的一些理论的时候，我发现这些理论在一定程度上与人类自己的认知过程有一定的相似之处，所以，我觉得将用这些理论去思考自己的学习过程，并且用自己的学习过程去理解这些理论都是可以帮助自己更好地提升对“学习”的理解。 Linear Algebra Linear algebra is the study of vectors and certain algebra rules to manipulate vectors. 线性代数就是向量+对向量的操作。而向量就是一个数据集，对应着具体事物的不同属性。放到空间中，向量就是方向+数量（direction and magnitude）。我们需要弄清楚的是，在不同的情形下，对向量的运算会对这些数字所对应的属性产生什么变化。例如两个向量的相加，可会将原先的向量在长度和方向上的变化。 前半部分介绍线性代数的基础知识，我只记录自己不熟悉的部分和大致内容。 Foundations逆 公式法： 解方程： 求解 解方程 通解 = 非齐次特解 + 非齐次通解The Minus-1 Trick（快速求解齐次方程通解）在行阶梯矩阵中，添加单位行向量，非零元素对应非主元元素位置，此时原先非主元元素所在的列向量就是通解向量。原矩阵： A=\\begin{bmatrix} 1 & 3 & 0 & 0 & 3 \\\\ 0&0&1&0&9 \\\\ 0&0&0&1&-4\\end{bmatrix}增广矩阵：通解： \\left\\{ x\\in \\mathbb R^5:x=\\lambda_1\\begin{bmatrix}3\\\\-1\\\\0\\\\0\\\\0\\end{bmatrix}+ \\lambda_2\\begin{bmatrix}3\\\\0\\\\9\\\\-1\\\\-1\\end{bmatrix}, \\lambda_1,\\lambda_2\\in \\mathbb R \\right\\}计算线性方程如果A是方阵并且可逆，可以通过逆直接求出来：推广至一般矩阵，需要用到伪逆（Moore-Penrose pseudo-inverse）： Ax = b \\Leftrightarrow A^TAx=A^Tb \\Leftrightarrow x = (A^TA)^{-1}A^Tb:Moore-Penrose pseudo-inverse但是这方法需要大量的矩阵运算，可能会在计算精度上有损失 这个逆是泛化的矩阵的逆，标记为。这里是巧妙地规避了对非方阵矩阵的求逆，而不改变原先的属性。对于一个任意矩阵, 它可以用于奇异值分解。 还可以使用高斯消元法，这个方法虽然广泛使用，但是需要立方数量级的算数运算，计算较大。 还有一种迭代方法（Iterative method）: x^{(k+1)}=Cx^{(k)}+d在迭代的过程中，残差（residual error）：$|x^{(k+1)}-x_|不断减小，最终向x_$收敛 Hadamard product矩阵对应位置元素相乘。 向量空间（Vector Space）Group: Object + Operations 我对这个定义的理解是，一个向量经过外积和向量积所能表示的所有的向量一个向量经过线性组合和数乘得到的所有的向量，这些所有的向量组成的空间就是这个向量的向量空间。（张成空间：两向量的全部线性组合构成的向量空间） 将一个向量看成向量空间中的一个点，这个点乘以所有的实数得到的所有的向量组成一条直线，这条直线就是这个向量张成的向量空间()。它与另外一个不平行的直线的所有的线性组合会得到一个平面，这就是两个向量张成的二维空间() 对这个定义的理解还需要补充 线性的严格定义：L(c \\vec v) = cL(\\vec v)\\\\ L(\\vec v + \\vec w) = L(\\vec v)+L(\\vec w)将L当成一种变换，对向量进行数量积之后进行变换和变换之后对向量进行数量积的结果是一致的。拥有这种性质的算子很多， 例如求导： 向量子空间（Vector subspace）向量子空间需要满足加法封闭性和数乘封闭性。也就是向量子空间中的向量在经过任意的数乘或线性组合之后得到的向量仍在这个子空间中。判断是否为向量子空间，需要满足封闭性，也就是经过对应的运算之后，向量仍旧属于原先的向量空间。 例：the closure property is violated;因为向量空间需要满足加法封闭性，也就是说在这个空间中向量之间的运算之后的向量，需要还在这个空间中，上面这个空间显然不满足这个条件。 线性无关矩阵线性无关就是说每一个都是相互独立的，不能由其他向量表示出来。表现在公式上： \\sum_{i=1}^{k} \\lambda_ix_i = 0当且仅当上式中为0时，成立，说明向量线性无关。空间上理解就是，每一个向量代表一个维度，少了其中一个就会导致降维,这也就是秩 。当有向量对维度的没有贡献的时候，就说这个向量是线性相关的。 Basis and RankGenerating set and basis生成集就是能够表示向量空间的向量集合，这也就是说生成集中向量通过线性组合等方式可以表示向量空间中的所有的向量（能通过数乘和线性组合表示整个向量空间的向量）。而生成集所形成的向量空间称为张成空间（span） V = (\\mathcal{V},+,\\cdot ), \\mathcal{A} = \\{x_1,x_2,....,x_k\\} \\subseteq \\mathcal{V}对于任意能被线性表出，则称是的一个生成集。所能线性表示的所有向量组成的空间成为的张成空间，表示为生成集中最小的集合成为基（basis） 下图展示了关于这个概念的等价描述：现在有一个问题，是不是任意n个n维的线性无关的向量都是n维空间的一个生成集呢？并不是，因为这个n个向量可能只能形成n维空间的一个子空间，并不能表示该空间当中所有的向量，所以并不是这个空间的一个生成集。 How can you describe it in graph?存疑 当向量组是线性无关的时候，每一个向量代表一个维度，将向量空间的维度表示为,如果，是的一个子空间，则有： dim({\\mathcal{V})} \\ge dim(\\mathcal{U}), if\\ and \\ only\\ if\\ \\mathcal{V}=\\mathcal{U}\\Rightarrow dim({\\mathcal{V})} = dim(\\mathcal{U})Rank秩可以表示为向量组中线性无关的列向量的个数，也就是向量组的向量空间的维度。其他还有一些相关的性质： 线性映射（Linear Mappings/vector space homomorphism/ linear transformation）对于向量空间和的线性映射有如下定义: \\forall \\boldsymbol x,\\boldsymbol y \\in \\boldsymbol V \\ \\forall \\lambda, \\psi \\in \\mathbb R:\\boldsymbol\\Phi(\\lambda \\boldsymbol x+\\psi \\boldsymbol y)=\\lambda\\boldsymbol\\Phi(\\boldsymbol x)+\\psi\\boldsymbol\\Phi(\\boldsymbol y)这样的映射关系可以用矩阵表示： \\Phi{(\\lambda x+\\psi y)}=[\\lambda\\ \\ \\ \\ \\ \\psi]\\begin{bmatrix} \\Phi_{(x)} \\\\ \\Phi_{(y)} \\end{bmatrix} \\quad下面是几个特殊的映射：满射就是y的所有元素都可以由x中的元素映射得来 逆映射：对于映射有 ：,则为的逆映射，表示为 一些特殊的线性映射： 有疑问？需要理解一下这里是解释为什么复数可以表示维二维坐标的形式，因为我们可以使用双线性映射将二维坐标数组转化成复数空间中的加法形式(利用一个映射就可以转换了) 同构：抓取一个数学对象最本质的信息（比如上面例子里的加法和乘法结构），而忽略其他没那么重要的信息（比如进制），然后把具有相同“本质信息”的对象视为一体。（例如一个对象中包含三个个体，那么所有包含三个个体的对象都可以说是同构的，因为他们都有3这个特征）同态：它是在两个本质不一定相同的数学对象之间建立联系（两不一定完全一致的对象是更大结构的一部分） 这个定理表明拥有相同维度的向量空间在一定程度上是相同的。𝕟𝕞：一个是n×m矩阵一个是nm维度向量，二者的维度是一样的，而且他们之间能够通过一种线性映射（双映射）相互转换. 如何在图形上理解n×m矩阵和nm维度向量是同形的？ 线性映射的矩阵表示对于一个元组中,各个向量的位置是不能交换的，也就是说这些向量的位置也是作为这个元组的一个信息，这样的元组称为有序基(ordered basis) 在此书中，用表示有序基； 表示（无序）基； 表示一个矩阵。 所以对于一个有序基,对于中的所有向量，都可以由唯一线性表出。即： x \\in \\mathbb{R}^n,x = \\alpha_1\\bold {b_1}+\\alpha_2\\bold{b_2}+....+\\alpha_n\\bold {b_n}组成的向量就是向量在向量空间中以为基向量的坐标。 向量的坐标依赖于基向量，在不同的基向量中的坐标不同。想要完成有一对基向量组成的向量空间中的向量映射到另一对基向量组成的向量空间中的向量，这可以使用一个矩阵完成，这样的矩阵被称为变换矩阵（Transformation Matrix） 一个向量空间中的向量可以表示为：表示为矩阵形式就是 \\bold a = [\\bold {e_1} \\ \\ \\bold {e_2}]\\begin{bmatrix}\\ x \\\\ y\\end{bmatrix}\\quad假设、是向量空间的基向量，所以上式可以表示为： \\bold a = \\begin{bmatrix} 1 \\ \\ \\ 0 \\\\ 0 \\ \\ \\ 1\\end{bmatrix} \\begin{bmatrix}\\ x \\\\ y\\end{bmatrix}\\quad这一个单位矩阵也可以看成一种变换，但是是一种原封不动的变换，现在假设有一个变换矩阵。所以，就相当于对原先的向量空间y轴上的延伸操作。这也是一种对向量的线性变换 基变换(Basis Change)这部分探寻向量空间发生变化之后，变换矩阵的情况。有几种情形，首先是在同一个向量空间中的基变换，这种变换也成为恒等映射（identity mapping）例如：表示在向量空间V中的恒等映射。还有一种向量空间发生变化的情况。在下图中，蓝色的字母代表有序基，箭头上的希腊字母代表着对应的变换矩阵我们能够通过原先的变换矩阵得到: \\Phi_{\\tilde C\\tilde B} = \\Xi_{\\tilde C C}\\circ \\Phi_{CB}\\circ\\Psi_{B\\tilde B} = \\Xi^{-1}_{C\\tilde C}\\circ \\Phi_{CB}\\circ\\Psi_{B\\tilde B}这也就是说一个基的多个变换可以等价于某一个单一的变换。 对上式的一个粗略的推导：等价与相似： 正则矩阵（Regular Matrix）: 我们常见的实数矩阵和复数矩阵中，正则矩阵=可逆矩阵 像集与核（Image and Kernel）零空间就是一个向量空间中的向量，经过映射之后，变成零向量的所有向量组成的向量空间，e.g: 的解就是A的一个零空间。因为总是成立，所以零空间不会是空的。零空间也可以用于确定列向量之间是否是线性相关的。如何从映射的角度，理解这个线性相关？ 假设存在这样的一个映射使得，中的一个子空间经过线性映射之后变成了一个0空间，说明这个过程发生了降维，零空间就是在转换之后损失掉的维度，而变换矩阵所在向量空间的维度，影响变换之后的向量空间的维度，而变换矩阵的列向量就是描述这样的维度的量，所对应的就是列空间 像集就是映射之后所对应的向量组成的向量空间。e.g:从上图知：的核空间是的一个向量子空间，而其像域是的一个向量子空间。所以，像域是在映射之后在的子空间，零空间是中映射之后变成中的零的一个向量子空间。 列空间变换矩阵列向量所形成的张成空间，就是列空间秩－零化度定理 思考这个等式为什么会成立？其实就是在变换过程中损失的维度和变换后的维度之和等于变换之前的向量空间的维度。而这样的损失是由于变换矩阵导致，这也就是说变换之后的维度等于变换矩阵的维度，这也就是为什么的像域是A的列空间了。上面那个结论其实说的就是在变换之后丢失了一些维度，所以，零空间至少是一维的，在这个空间上的向量又是无限多的，所以就是有无穷解了。 仿射空间（Affine Spaces）仿射子空间实际上就是一个不经过原点的子空间，描述为一个子空间加上一些偏置，使得这个空间不经过原点。例如。三维空间的一个仿射子空间就是一个不经过原点的点、线或者面。 想想这段话的含义想清楚仿射空间与线性非齐次方程之间的关系。 一个实例： 向量可以用向量空间的有序基线性表示，同样的仿射空间中的向量可以由同样的方式表示，只需要在每个向量中加上支持点（support point）即可 仿射映射与线性映射类似，仿射映射只不过是在线性映射之后加上一个偏置量（支撑点）。","link":"/2021/04/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%EF%BC%9A%EF%BC%88%E4%B8%80%EF%BC%89%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"},{"title":"机器学习中的数学：（二）解析几何","text":"解析几何(Analytic Geometry)这章将从几何的角度理解之前提及的一些概念。 范数(Norm)范数实际上就是向量的一个长度范数有以下性质： 第一个绝对齐次（？）实际上数量积不就是对向量长度的一个延伸，所以，缩放的量可以提出来。 第二个三角不等式，因为两个向量和这两个向量的向量和会形成一个三角形，三角形有一个性质就是两边之和大于等于第三边 最后一个是因为长度是非负的 下面是两种不同的范数，这种区别是对距离的定于不同导致的。 曼哈顿范数（Manhattan Norm）由上图可以了解到曼哈顿距离和欧几里得距离的区别，这样曼哈顿距离就是对应的向量（坐标）所有元素的绝对值之和。其实就是点在水平和竖直方向的位移总和。(表示向量的元素，表示绝对值)表示方式： 欧几里得范数（Euclidean Norm）这个使用的就是直观的“直线距离”：表示方式： 曼哈顿范数（左）和欧几里得范数（右）的实例： 内积（Inner Product）内积可以理解为，两个向量在同一向量空间（转换后）下的长度的乘积。点积：两维度相同的向量相乘最后得到一个实数。 x^\\top y = \\sum_{i=1}^{n}x_iy_i点积的几何含义：所以从图像上看，可以得到部分点积的性质：当两向量相反的时候，点积为负数；当两向量垂直的时候，点积为0（在另一个向量的投影的长度为0）。当两向量方向相同的时候，点积为正。内积的齐次性和对称性：两个向量哪个投影至哪个其实并没有什么区别，所以，二者乘积的顺序是无关紧要的。 点积为什么是这样计算的？ 广义内积双线性映射（bilinear mapping）当映射的参数顺序交换后，映射结果保持一致，这种性质称为对称(symmetric).当映射结果不会小于0， 这种性质称为正定（positive definite）这样，内积的广义定义就是一个正定、对称的双线性映射。 内积空间是不是就是向量空间中两两通过运算之后得到一个实数的向量组成的空间？理解一下上图最后一句化的含义。 对称正定矩阵（Symmetric, Positive Definite Matrices） 由于内积是正定的，所以有上式可以得出： \\forall x \\in V \\backslash \\{0\\}:x^T\\bold Ax > 0是任意的非零向量。对于一个满足上式的对称矩阵，称为正定矩阵 \\forall x \\in V \\backslash \\{0\\}:x^T\\bold Ax \\ge 0满足上式的对称矩阵称为半正定矩阵 可以使用一个正定矩阵定义一个内积：因为矩阵正定，所以。这一就是说，所以A的零空间只能是。同时，对角线的元素都大于0，原因如下： 长度与距离（Lengths and Distances）内积和范数之间的关系十分紧密。这样理解，（在欧氏几何内）内积其实就是一个向量在另一个向量上投影之后，得到的向量，这两个向量的长度的乘积就是内积。范数简单来说就是向量的长度。所以，两个相同的向量的内积就是这个向量的范数的平方。 \\|x\\| := \\sqrt {\\langle x, x\\rangle}柯西-施瓦茨不等式（Cauchy-Schwarz Inequality）：对于这个公式用图形非常好理解：不等式左边是投影之后的两向量的乘积（见之前点积部分介绍的投影），而右边是两向量没有经过投影的长度乘积。而只有两向量相等的时候，一个向量投影到另一个向量不会损失长度，这时候不等式取得等号，否则投影之后的向量长度都会变小。在欧几里得空间中有特例：距离和度规（Distance and Metric）：距离的定义：度规的定义：在数学中，度量（度规）或距离函数是个函数，定义了集合内每一对元素之间的距离。 度规和内积有类似的性质，但是他们在某方面又是不同的。当两个向量越接近的时候，内积越大，而度规越小。 夹角与正交性(Angles and Orthogonality)内积可以用于定义两向量的夹角：由之前提到的的柯西-施瓦茨不等式：|\\langle\\boldsymbol{x}, \\boldsymbol{y}\\rangle| \\leqslant\\|\\boldsymbol{x}\\|\\|\\boldsymbol{y}\\|可以得到： -1 \\leqslant \\frac{\\langle\\boldsymbol{x}, \\boldsymbol{y}\\rangle}{\\|\\boldsymbol{x}\\|\\|\\boldsymbol{y}\\|} \\leqslant 1在这个范围内，余弦函数的单调的。用来表示两个向量的相近程度。内积更重要的是可以为定义两向量的正交性:两向量正交实际上就是他们之间的夹角为,这时候的余弦值为0，由 \\cos \\omega=\\frac{\\langle\\boldsymbol{x}, \\boldsymbol{y}\\rangle}{\\|\\boldsymbol{x}\\|\\|\\boldsymbol{y}\\|}因为和都是正定的，所以当是，等于0.当x、y的范数（长度）为1时，称为规范化正交(orthonormal).当一个向量是时，它与所有的向量都正交。正交依赖于内积，所以在不同的内积的情况下，正交性可能不同。 正交矩阵 转置矩阵的变换关系？ \\|A x\\|^{\\top}=(A x)^{\\top}(A x)=x^{\\top} A^{\\top} A x=x^{\\top} \\boldsymbol{I} x=x^{\\top} x=\\|x\\|^{2}\\cos \\omega=\\frac{(\\boldsymbol{A} \\boldsymbol{x})^{\\top}(\\boldsymbol{A} \\boldsymbol{y})}{\\|\\boldsymbol{A} \\boldsymbol{x}\\|\\|\\boldsymbol{A} \\boldsymbol{y}\\|}=\\frac{\\boldsymbol{x}^{\\top} \\boldsymbol{A}^{\\top} \\boldsymbol{A} \\boldsymbol{y}}{\\sqrt{\\boldsymbol{x}^{\\top} \\boldsymbol{A}^{\\top} \\boldsymbol{A} \\boldsymbol{x} \\boldsymbol{y}^{\\top} \\boldsymbol{A}^{\\top} \\boldsymbol{A} \\boldsymbol{y}}}=\\frac{\\boldsymbol{x}^{\\top} \\boldsymbol{y}}{\\|\\boldsymbol{x}\\|\\|\\boldsymbol{y}\\|}由上可知，向量在经过正交变换之后，他们之间的夹角和长度都没有发生变化，实际上，正交变换就是将向量进行旋转操作。 规范正交基（Orthonormal Basis）一对规范正交基满足两个条件，二者之间的夹角和他们各自的长度。 规范（长度为1）且正交（两对基相互垂直） 格拉姆-施密特正交化 Gram–Schmidt process这里时利用高斯消元法来取得正交规范正交基 正交补（Orthogonal Complement）一个向量空间的两个子空间，这两个子空间的维度之和等于原先的向量空间的维度，准确来说，一个子空间占领原空间的部分维度，另一个子空间占领剩余的维度，二者在维度上没有关系。一个实例 这样，原先向量空间中的任意向量，都可以用这个子空间的有序基以及其正交补的有序基表示出来（分解）： \\boldsymbol{x}=\\sum_{m=1}^{M} \\lambda_{m} \\boldsymbol{b}_{m}+\\sum_{j=1}^{D-M} \\psi_{j} \\boldsymbol{b}_{j}^{\\perp}, \\quad \\lambda_{m}, \\psi_{j} \\in \\mathbb{R}其中，是原先的向量空间的一个向量，是原先空间的一个子空间的有序基，是这个子空间的正交补的有序基。 函数的内积有之前的点积： x^Ty = \\sum_{i = 1}^nx_iy_i当向量的维度有无限维时，可以将这个利用定积分的定义，写成积分形式。 \\int_{a}^{b}f(x) = \\lim_{\\lambda \\rarr 0}\\sum_{i=1}^nf(\\xi_i)\\Delta x_i,\\quad \\lambda = max\\{\\Delta x_1,\\Delta x_2,...,\\Delta x_n\\}从而： 当两个函数在一定区间上的定积分为0时，说这两个函数时正交函数。 所有的正交函数够成的一个子空间想要正确理解这个无穷维向量的内积，需要将积分延伸到希尔伯特空间（Hilbert space）中。 正交投影（Orthogonal Projections）在机器学习中，由于研究对象通常由多标签组成的，所以就不得不使用高维矩阵，但是实际上，大多数的信息仅仅存储在少部分的标签中，所以，当需要对矩阵进行可视化或者数据压缩的时候，为了减少造成的信息损失，可以使用正交投影，这样压缩之后的数据损失最小。下面是对投影的定义： 怎么理解？应该是对一个向量进行两次投影的与进行一次投影的效果是一致的。 假设一个向量被正交投影到向量空间V中，然后再被正交投影到W中，那么这个向量可以直接利用一次正交变换投影到W中.类似于 投影本质上就是一种对向量的变换，所以可以用矩阵来描述，所以投影操作对应的矩阵就是投影矩阵（projection matrices，） 正交投影到一维子空间可以通过以下三步求解投影矩阵： 1.找到坐标: \\left\\langle\\boldsymbol{x}-\\pi_{U}(\\boldsymbol{x}), \\boldsymbol{b}\\right\\rangle=0 \\stackrel{\\pi_{U}(\\boldsymbol{x})=\\lambda \\boldsymbol{b}}{\\Longleftrightarrow}\\langle\\boldsymbol{x}-\\lambda \\boldsymbol{b}, \\boldsymbol{b}\\rangle=0$$注意到$\\boldsymbol{x}-\\pi_{U}(\\boldsymbol{x})$是向量及其投影向量做差之后得到的向量，所以与投影到的向量正交。因为投影之后的向量属于向量空间U，所以可以用U中的有序基线性$\\bold b$表示。 $$\\langle\\boldsymbol{x}, \\boldsymbol{b}\\rangle-\\lambda\\langle\\boldsymbol{b}, \\boldsymbol{b}\\rangle=0 \\Longleftrightarrow \\lambda=\\frac{\\langle\\boldsymbol{x}, \\boldsymbol{b}\\rangle}{\\langle\\boldsymbol{b}, \\boldsymbol{b}\\rangle}=\\frac{\\langle\\boldsymbol{b}, \\boldsymbol{x}\\rangle}{\\|\\boldsymbol{b}\\|^{2}} .这里是利用了内积的双线性的性质，将原先的式子进行了拆分，最后的等式是利用了内积的对称性。之后分离出，任务完成。 \\lambda=\\frac{\\boldsymbol{b}^{\\top} \\boldsymbol{x}}{\\boldsymbol{b}^{\\top} \\boldsymbol{b}}=\\frac{\\boldsymbol{b}^{\\top} \\boldsymbol{x}}{\\|\\boldsymbol{b}\\|^{2}}（这里探究当内积为点积的情况） 2.找到投影点（投影后的向量）： \\pi_{U}(\\boldsymbol{x})=\\lambda \\boldsymbol{b}=\\frac{\\langle\\boldsymbol{x}, \\boldsymbol{b}\\rangle}{\\|\\boldsymbol{b}\\|^{2}} \\boldsymbol{b}=\\frac{\\boldsymbol{b}^{\\top} \\boldsymbol{x}}{\\|\\boldsymbol{b}\\|^{2}} \\boldsymbol{b}将之前的结果带入式中，最后的等式为当内积为点积的时候成立。 \\left\\|\\pi_{U}(\\boldsymbol{x})\\right\\| \\stackrel{(3.42)}{=} \\frac{\\left|\\boldsymbol{b}^{\\top} \\boldsymbol{x}\\right|}{\\|\\boldsymbol{b}\\|^{2}}\\|\\boldsymbol{b}\\| \\stackrel{(3.25)}{=}|\\cos \\omega|\\|\\boldsymbol{x}\\|\\|\\boldsymbol{b}\\| \\frac{\\|\\boldsymbol{b}\\|}{\\|\\boldsymbol{b}\\|^{2}}=|\\cos \\omega|\\|\\boldsymbol{x}\\| .点积为内积的情况下,同时，联立了 3.找到投影矩阵 \\pi_{U}(\\boldsymbol{x})=\\lambda \\boldsymbol{b}=\\boldsymbol{b} \\lambda=\\boldsymbol{b} \\frac{\\boldsymbol{b}^{\\top} \\boldsymbol{x}}{\\|\\boldsymbol{b}\\|^{2}}=\\frac{\\boldsymbol{b} \\boldsymbol{b}^{\\top}}{\\|\\boldsymbol{b}\\|^{2}} \\boldsymbol{x}于是： \\bold P_\\pi = \\frac{\\bold b\\bold b^T}{\\|\\bold b\\|^2}这样看投影矩阵就是一个对称矩阵。 正交投影到一般的子空间假设一个子空间,因为投影的向量属于U，所以，这个投影向量可以用U的有序基表示出来： \\bold \\pi_U(\\bold x) =\\sum\\limits_{i=1}^m\\lambda_i\\bold b_i1.找出投影的坐标: \\bold\\pi_U(\\bold x) = \\sum\\limits_{i=1}^m\\lambda_i\\bold b_i = \\bold B\\bold\\lambda\\\\\\bold B=[\\bold b_1,...,\\bold b_m]\\in\\mathbb R^{n\\times m},\\quad\\lambda=[\\lambda_1,...,\\lambda_m]^T\\in\\mathbb R^m假设内积为点乘： \\left\\langle\\boldsymbol{b}_{1}, \\boldsymbol{x}-\\pi_{U}(\\boldsymbol{x})\\right\\rangle=\\boldsymbol{b}_{1}^{\\top}\\left(\\boldsymbol{x}-\\pi_{U}(\\boldsymbol{x})\\right)=0\\\\\\vdots\\\\\\left\\langle\\boldsymbol{b}_{m}, \\boldsymbol{x}-\\pi_{U}(\\boldsymbol{x})\\right\\rangle=\\boldsymbol{b}_{m}^{\\top}\\left(\\boldsymbol{x}-\\pi_{U}(\\boldsymbol{x})\\right)=0由,带入到上式中： \\bold b^T_1(\\bold x - \\bold B\\bold\\lambda)=0\\\\\\vdots\\\\\\bold b^T_m(\\bold x-\\bold B\\lambda)=0转换成矩阵形式： \\begin{aligned} \\left[\\begin{array}{c} b_{1}^{\\top} \\\\ \\vdots \\\\ b_{m}^{\\top} \\end{array}\\right][x-B \\lambda]=0 & \\Longleftrightarrow B^{\\top}(x-B \\lambda)=0 & \\Longleftrightarrow B^{\\top} B \\lambda=B^{\\top} x . \\end{aligned}因为是U的有序基，所以他是可逆的，所以可以得到： \\lambda=(\\bold B^T\\bold B)^{-1}\\bold B^T\\bold x其中：称为伪逆，可以用于计算非方阵矩阵。2.找到投影向量：由,带入上式： \\pi_U(x) = \\bold B(\\bold B^T\\bold B)^{-1}\\bold B^T\\bold x3.找到投影矩阵：由,由上式可以得出： \\bold P_\\pi=\\bold B(\\bold B^T\\bold B)^{-1}\\bold B^T 原始向量与投影向量之差够成的向量的范数，称为重构误差（reconstruction error.）或者投影误差。 虽然说但是我们只需要用U的有序基就可以表示 用正交投影可以用于求非齐次方程无解的时候的近似解。当这个方程无解的时候，说明和不在同一个向量空间中，所以无法通过一些变换（）得到。这时候可以利用正交投影，将其中一个向量投影到另一个向量的向量空间中，这样可以得到一个近似解，其中的主要思想就是找到一个在A的张成空间中，与b最相近的向量。这样得到的解称为最小二乘解（least-squares solution） 格拉姆-施密特正交化（Gram-Schmidt Orthogonalization） 这里的目标是求出，利用已知的数据计算出这样就可以利用计算了。 我们可以使用向量以及其投影所在的向量空间的有序基作差，得到一个法向量。然后递归地将有序基转化成正交基。 \\bold {\\mathcal u}:=\\bold b_1 \\\\ \\mathcal u_k:=\\bold b_k- \\pi_{span[\\bold u_1,\\dots,\\bold u_{k-1}]}(\\bold b_k),\\quad k =2,\\dots,n其中，是之前缔造的正交向量组成的向量空间（） 在仿射空间中的正交投影先将目标向量与支撑点()相减，得到的向量就是以仿射空间为起点的，这时候，问题就转换成我们之前讨论过的问题了。\\pi_L(\\bold x)=\\bold x_0+\\pi_U(\\bold x-\\bold x_0) 旋转变换旋转实际上就是一种正交变换。在文中规定当旋转角度为正数的时候，图像作逆时针旋转。 在二维实空间中的旋转（Rotations in ）因为旋转之后的基向量仍然是线性无关的，所以，旋转也是一种基变换。由上可以得到旋转矩阵（旋转之后的向量）： \\Phi\\left(\\boldsymbol{e}_{1}\\right)=\\left[\\begin{array}{c}\\cos \\theta \\\\ \\sin \\theta\\end{array}\\right], \\quad \\Phi\\left(\\boldsymbol{e}_{2}\\right)=\\left[\\begin{array}{c}-\\sin \\theta \\\\ \\cos \\theta\\end{array}\\right]\\boldsymbol{R}(\\theta)=\\left[\\begin{array}{ll}\\Phi\\left(\\boldsymbol{e}_{1}\\right) & \\Phi\\left(\\boldsymbol{e}_{2}\\right)\\end{array}\\right]=\\left[\\begin{array}{cc}\\cos \\theta & -\\sin \\theta \\\\ \\sin \\theta & \\cos \\theta\\end{array}\\right] .在三维实空间中的旋转(Rotations in )可以这样理解，先固定一个坐标轴，然后从上往下看去，得到这个向量在另外两个基向量所形成的向量空间中正交投影，然后再作相应的旋转操作。 关于的旋转操作： \\bold R_1(\\theta)=\\left[\\begin{array}{c} \\Phi(\\bold e_1)&\\Phi(\\bold e_2) &\\Phi(\\bold e_3) \\end{array}\\right]=\\left[\\begin{array}{c} 1&0&0 \\\\0&\\cos\\theta&-\\sin\\theta\\\\0&\\sin\\theta&\\cos\\theta \\end{array}\\right]类似的，只要固定哪个坐标轴，哪个坐标轴就是基向量。 在维空间中的旋转吉文斯旋转（Givens Rotation）：实际上就是等价于单位矩阵对应位置上变成一个正弦或者余弦值。 旋转的特性简单来说就是变换之后向量之间的距离角度不变，三维及三维以上的旋转操作不满足交换律，二维的满足。","link":"/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%EF%BC%9A%EF%BC%88%E4%BA%8C%EF%BC%89%E8%A7%A3%E6%9E%90%E5%87%A0%E4%BD%95/"},{"title":"机器学习中的数学：（五）概率与分布(Probability and Distributions)","text":"概率空间的构造（Construction of a Probability Space）哲学问题（Philosophical Issues）这部分是对概率的一个解释。概率论是推理系统的一个基础，个人理解就是推理实际上就是找到对某件事情的可能性最大的结果。这里引入了一个合理性（plausibility），并用数学标准描述出来了。 在机器学习中，对概率的解释有两种，一种是贝叶斯式（the Bayesian）还有一种是频率论（Frequentist）前者用概率描述事物的不确定性，后者用在特定时间段中发生特定事情的频率。 概率和随机变量（Probability and Random Variables）几个概念：样品空间（sample space）：一个实验可能出现的所有的结果的集合。事件空间(event space):样品空间的一个子集概率P（probability）：,一个事件发生的概率。目标空间（target space）和随机变量(random variable)：为了找到样品空间中我们关注的量，用一个函数， 其中,称为随机变量。(对，随机变量实际上是一个函数) One way to understand the transformation of probability from events in via the random variable X is to associate it with the probability of the pre-image of S对于一个随机变量和目标空间的一个子集,则为经过变换的原象（pre-image），也就是中的经过的变换之后得到，所以有： P_X(S) = P(X\\in S)=P(X^{-1}(S))=P(\\{\\ \\omega\\in\\Omega:X(\\omega)\\in S \\})这里称或者为随机变量的分布（distribution）或者（law？） 个人理解，随机变量实际上就是对样品空间的某些特性的量化描述，例如，对于一个抛两个硬币的实验，在样品空间中，一次实验正面出现的次数可以为0、1、2，可以将这些数字对应到事件上去，这就是随机变量。 统计（Statistics）统计和概率往往是一起出现的，但是二者的侧重点不太一样，前者是关注找出能解释观察到的现象的内在过程。后者可以认为是一些过程的模型，其中的不确定性事件被随机变量存储下来，然后用概率的一些规律去弄清楚发生了什么。 离散概率和连续概率（Discrete and Continuous Probabilities）离散型概率和连续型概率的区别就是前者的目标空间是离散的，后者是连续的。也就是前者的随机变量是由一个个数组成，后者则是一个连续的区间。 离散型概率（Discrete Probabilities）由上图可以得到几个概念：联合概率（joint probability）：两个事件的交集 P(X =x_i, Y = y_i)=\\frac {n_{ij}}{N}也可以写成 边际概率（marginal probability）：条件概率（conditional probability）：当一个事件发生时另一个事件发生的概率 P(X=x_{i}|Y=y_{ij})=\\frac {n_{ij}}{r_j}连续性概率（Continuous Probabilities） 没弄懂。还有之后提到的，在连续空间中两个反直觉的问题：1. needs to be restricted to behave well under set complements, set intersections,and set unions2.测量集合的大小。量度（measure）、集的势（cardinality）：集合中的元素的个数，当两个集合中的元素个数相等的时候，称为等势Sets that behave well under set operations and additionally have a topology are called a Borel -algebra 概率密度函数用概率密度函数可以求解在给定区间当中的概率： P(a\\le X\\le)=\\int^a_bf(x)dx注意一点，一个点在连续函数中出现的概率为0，即在上式时. 累积分布函数即： F_X(x)=\\int^{x_1}_{-\\infin}\\dots\\int^{x_D}_{-\\infin}f(z_1,\\dots,z_D)dz_1\\dots dz_D加法法则、乘法法则和贝叶斯定理（Sum Rule, Product Rule, and Bayes’ Theorem）加法法则： p(\\boldsymbol{x})=\\left\\{\\begin{array}{ll}\\sum\\limits_{\\boldsymbol{y} \\in \\mathcal{Y}} p(\\boldsymbol{x}, \\boldsymbol{y}) & \\text { if } \\boldsymbol{y} \\text { is discrete } \\\\ \\\\ \\int_{\\mathcal{Y}} p(\\boldsymbol{x}, \\boldsymbol{y}) \\mathrm{d} \\boldsymbol{y} & \\text { if } \\boldsymbol{y} \\text { is continuous }\\end{array}\\right.推广至多变量：设: p(x_i)=\\int p(x_1,\\dots,x_D)d\\boldsymbol x_{\\backslash i}其中，,表示除了以外的所有的元素。 乘法法则 p(x,y) = p(y|x)p(x)\\\\ p(y,x)=p(x|y)p(y)由于随机变量的顺序无关紧要，所以上面两个式子是等价的。 贝叶斯公式这个公式可以由乘法法则推出。（也被称为概率逆（probabilistic inverse）） the posterior distribution is the quantity of interest as it encapsulates all available information from the prior and the data. 从上图中理解，最终的后验概率就是浅蓝色部分占蓝色部分的比例。称为先验概率，描述的是一些已知事件发生的概率，之后的是在这些已知事件中y发生的概率称为似然概率，最后是y事件在整体中发生的概率。 举一个例子，想要知道一群人当中脾气好的女生有多少，首先，女生在人群中比例可以看成先验概率，而女生中脾气好的人数比例可以看成似然概率，所以的意思就是脾气好的人中女生的比例,但是男生中也有脾气好的，所以用女生脾气好的人数，除以所有脾气好的人数就是想要求得概率了。 似然函数(likelihood function):在该数据下，数据拟合的好坏,也就是在当前参数的情况下对真是数据的匹配情况。具体来说就是在给的那个参数的情况下，取得预期值的概率的大小，即 边际似然（marginal likelihood/evidence） p(\\boldsymbol y):= \\int p(\\boldsymbol y|\\boldsymbol x)p(\\boldsymbol x)d \\boldsymbol x=\\mathbb E_X[p(\\boldsymbol y|\\boldsymbol x)]由上式可知，边际似然是与x相互独立的，这也被称为期望似然概率。 摘要统计和独立性（Summary Statistics and Independence） 摘要统计:In descriptive statistics, summary statistics are used to summarize a set of observations, in order to communicate the largest amount of information as simply as possible实际上就是用一种尽可能简洁得方式概括数据的信息。 均值和协方差（Means and Covariances）数学期望（Expected Value） g:\\mathbb R\\rightarrow\\mathbb R,\\quad X \\sim p(x) \\\\ \\\\ \\mathbb E_X[g(x)]=\\left\\{\\begin{array}{ll}\\int_\\mathcal Xg(x)p(x)dx,\\quad continuous\\\\ \\\\ \\sum\\limits_{x\\in\\mathcal X}g(x)p(x),\\quad discrete\\end{array}\\right.注意这个式子中是函数值乘以对应的概率值，所以最终得到的是映射值得概率均值。对于由有限个一维随机变量组成得数组： \\mathbb{E}_{X}[g(\\boldsymbol{x})]=\\left[\\begin{array}{c}\\mathbb{E}_{X_{1}}\\left[g\\left(x_{1}\\right)\\right] \\\\ \\vdots \\\\ \\mathbb{E}_{X_{D}}\\left[g\\left(x_{D}\\right)\\right]\\end{array}\\right] \\in \\mathbb{R}^{D}数学期望满足线性算子的性质： \\begin{aligned} \\mathbb{E}_{X}[f(\\boldsymbol{x})] &=\\int f(\\boldsymbol{x}) p(\\boldsymbol{x}) \\mathrm{d} \\boldsymbol{x} \\\\ &=\\int[a g(\\boldsymbol{x})+b h(\\boldsymbol{x})] p(\\boldsymbol{x}) \\mathrm{d} \\boldsymbol{x} \\\\ &=a \\int g(\\boldsymbol{x}) p(\\boldsymbol{x}) \\mathrm{d} x+b \\int h(\\boldsymbol{x}) p(\\boldsymbol{x}) \\mathrm{d} \\boldsymbol{x} \\\\ &=a \\mathbb{E}_{X}[g(\\boldsymbol{x})]+b \\mathbb{E}_{X}[h(\\boldsymbol{x})] \\end{aligned}均值（Mean）均值是描述映射前的数据的情况。对于一个随机变量,其中所以： \\mathbb E_X[\\boldsymbol x]=\\begin{bmatrix} \\mathbb E_{X_1}[x_1]\\\\\\vdots\\\\ \\mathbb E_{X_D}[x_D]\\end{bmatrix}\\in R^D \\mathbb{E}_{X_{d}}\\left[x_{d}\\right]:=\\left\\{\\begin{array}{ll} \\int_{\\mathcal{X}} x_{d} p\\left(x_{d}\\right) \\mathrm{d} x_{d} & \\text { if } X \\text { is a continuous random variable } \\\\ \\sum_{x_{i} \\in \\mathcal{X}} x_{i} p\\left(x_{d}=x_{i}\\right) & \\text { if } X \\text { is a discrete random variable } \\end{array}\\right.中位数（median）一组数据中大于一遍数据而小于另一边数据的数字。中位数能够有效地应对异常值。众数（mode）一组数据中出现次数最多的数字。在连续随机变量中，众数是概率密度最大的数。 上面两种数字对于高维的数据的处理时比较麻烦? 在高维数据中，各个维度的数值大小判断准则不统一。 协方差（Covariance）：协方差描述两个随机变量之间的相互关系（衡量两个随机变量的联合变化程度）。单变量： X,Y\\in \\mathbb R\\operatorname {Cov}_{X,Y}[x,y]:=\\mathbb E_{X,Y}[(x-\\mathbb E_X[x])(y-\\mathbb E_Y[y])]利用线性性质，可以将上式化简为： Cov[x,y]=\\mathbb E[xy]-\\mathbb E[x]\\mathbb E[y]随机变量与自己本身的协方差称为方差(variance)，即,表示为,方差的开根之后的值称为标准偏差(standard deviation)，表示为多变量：多变量方差：设随机变量有, 均值向量: \\begin{aligned} \\mathbb{V}_{X}[\\boldsymbol{x}] &=\\operatorname{Cov}_{X}[\\boldsymbol{x}, \\boldsymbol{x}] \\\\ &=\\mathbb{E}_{X}\\left[(\\boldsymbol{x}-\\boldsymbol{\\mu})(\\boldsymbol{x}-\\boldsymbol{\\mu})^{\\top}\\right]=\\mathbb{E}_{X}\\left[\\boldsymbol{x} \\boldsymbol{x}^{\\top}\\right]-\\mathbb{E}_{X}[\\boldsymbol{x}] \\mathbb{E}_{X}[\\boldsymbol{x}]^{\\top} \\\\ &=\\left[\\begin{array}{cccc} \\operatorname{Cov}\\left[x_{1}, x_{1}\\right] & \\operatorname{Cov}\\left[x_{1}, x_{2}\\right] & \\ldots & \\operatorname{Cov}\\left[x_{1}, x_{D}\\right] \\\\ \\operatorname{Cov}\\left[x_{2}, x_{1}\\right] & \\operatorname{Cov}\\left[x_{2}, x_{2}\\right] & \\ldots & \\operatorname{Cov}\\left[x_{2}, x_{D}\\right] \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\operatorname{Cov}\\left[x_{D}, x_{1}\\right] & \\ldots & \\ldots & \\operatorname{Cov}\\left[x_{D}, x_{D}\\right] \\end{array}\\right] \\end{aligned}上式中的矩阵称为协方差矩阵（covariance matrix），是一个对称半正定的矩阵。它描述了数据的分散情况。对角线元素为方差，非对角线元素为互协方差（cross-covariance） 相关性（Correlation）相关性描述两个随机变量之间的关系。 \\operatorname{corr}[x, y]=\\frac{\\operatorname{Cov}[x, y]}{\\sqrt{\\mathbb{V}[x] \\mathbb{V}[y]}} \\in[-1,1] .相关性矩阵就是标准化的随机变量（standardized random variables），即 If the greater values of one variable mainly correspond with the greater values of the other variable, and the same holds for the lesser values (that is, the variables tend to show similar behavior), the covariance is positive. 正相关与负相关 样本均值和样本方差（Empirical Means and Covariances）就是将原先的数据中拿出一部分的数据作为样本，所得出的均值和方差。之前提到的均值是全平均值（population mean），方差也一样。 方差的三种表达式（Three Expressions for the Variance）方差的定义式，但是因为需要求均值，又要将样本数逐一进行运算，所以需要将数据遍历两遍。 \\mathbb{V}_{X}[x]:=\\mathbb{E}_{X}\\left[(x-\\mu)^{2}\\right]对原始式进行整理得到下式，这个式子称为变量的原始分数形式（raw-score formula for variance），虽然这样可以避免对数据进行两次的遍历，但是这在数值上是不稳定的（numerically unstable）。（？精度上的损失？） \\mathbb{V}_{X}[x]=\\mathbb{E}_{X}\\left[x^{2}\\right]-\\left(\\mathbb{E}_{X}[x]\\right)^{2}方差还可以理解成数据中的所有数字与其他所有的数字之间的差距的均值。 \\frac{1}{N^{2}} \\sum_{i, j=1}^{N}\\left(x_{i}-x_{j}\\right)^{2}=2\\left[\\frac{1}{N} \\sum_{i=1}^{N} x_{i}^{2}-\\left(\\frac{1}{N} \\sum_{i=1}^{N} x_{i}\\right)^{2}\\right] there is an equivalence between the pairwise distances and the distances from the center of the set of points 随机变量的加法运算和变换（Sums and Transformations of Random Variables） 对于一个仿射变换有： 统计独立性(Statistical Independence)当两个随机变量相互独立的时候，有以下性质。注意最后一个，当两个随机变量相互独立的时候，相关性等于0，但是相关性等于0的时候，不能说明两个随机变量相互独立，因为独立性是描述随机变量之间的线性独立，假设随机变量之间的关系不是线性的，那么相关性为0时，不能说这两个随机变量是相互独立的。 两随机变量相互独立时的一些性质： \\begin{aligned}&p(\\boldsymbol{y} \\mid \\boldsymbol{x})=p(\\boldsymbol{y})\\\\&p(\\boldsymbol{x} \\mid \\boldsymbol{y})=p(\\boldsymbol{x}) \\\\ &\\mathbb{V}_{X, Y}[\\boldsymbol{x}+\\boldsymbol{y}]=\\mathbb{V}_{X}[\\boldsymbol{x}]+\\mathbb{V}_{Y}[\\boldsymbol{y}]\\\\ &\\operatorname{Cov}_{X, Y}[\\boldsymbol{x}, \\boldsymbol{y}]=\\mathbf{0}\\end{aligned}独立均匀分布（independent and identically distributed (i.i.d.)）变量之间相互独立，而且来自于同一个分布中。条件独立（conditional independence）表示为 p(x,y)=p(y|x)p(x)\\\\ p(x,y|z)=p(x|z)p(y|z),\\quad z\\in \\mathcal Z利用第一个式子将第二个式子的左边展开，得到： p(\\boldsymbol x, \\boldsymbol y|z)=p(\\boldsymbol x|\\boldsymbol y,z)p(\\boldsymbol y|z)与原始比较可以得到： p(x|y,z)=p(x|z)这样可以得到条件独立的另一个定义，也就是我们知道y这个结论，对最终的结果没有影响。原式可以理解为在z的条件下，两个随机变量相互独立。统计独立可以看成条件独立的一个特例： 随机变量的内积（Inner Products of Random Variables）两个相互独立的随机变量,有以下性质：() \\mathbb V(x+y)=\\mathbb V(x)+\\mathbb V(y)由于方差是立方项，所以上式可以联想到勾股定理（the Pythagorean theorem）。（每一个随机变量都可以看成一个向量空间中的向量）假设对于随机变量之间的内积的定义如下： :=\\operatorname{Cov}[x,y]根据这个定义可以得到随机变量的长度： \\| X\\| = \\sqrt{\\operatorname{Cov}[x,x]}=\\sqrt{\\mathbb V[x]}=\\sigma[x]这里可以看到，随机变量“越长”，所对应的数据就越分散。还可以根据两向量的角度的定义得到： \\cos \\theta=\\frac{\\langle X, Y\\rangle}{\\|X\\|\\|Y\\|}=\\frac{\\operatorname{Cov}[x, y]}{\\sqrt{\\mathbb{V}[x] \\mathbb{V}[y]}}可以看到两个随机变量的“夹角”的余弦值就是相关性（）所以，当两个随机变量相会垂直的时候，也就是时，这时候二者的夹角为90°，对应的余弦值为0，也就是说这两个随机变量时不相关的。 之后提到用用欧几里得距离去比较两个随机变量的分布并不是最好的方式，这里提到了一个领域信息几何（information geometry）一个新名词廖（manifold），这部分没有弄得很清楚，留到后续再进行深入学习 高斯分布（Gaussian Distribution）一维随机变量的高斯分布： p\\left(x \\mid \\mu, \\sigma^{2}\\right)=\\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} \\exp \\left(-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right)其中，代表均值，代表随机变量得方差。对于多元正态分布：（multivariate Gaussian distribution）（为均值向量，为协方差矩阵） p(\\boldsymbol{x} \\mid \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})=(2 \\pi)^{-\\frac{D}{2}}|\\boldsymbol{\\Sigma}|^{-\\frac{1}{2}} \\exp \\left(-\\frac{1}{2}(\\boldsymbol{x}-\\boldsymbol{\\mu})^{\\top} \\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu})\\right)其中，在图像中表示为：当时，将这种分布称为标准正态分布（standard normal distribution.） 高斯分布的边际分布和条件分布仍旧是高斯分布（Marginals and Conditionals of Gaussians are Gaussians）假设、是多维随机变量，则有： p(\\boldsymbol{x}, \\boldsymbol{y})=\\mathcal{N}\\left(\\left[\\begin{array}{l}\\boldsymbol{\\mu}_{x} \\\\ \\boldsymbol{\\mu}_{y}\\end{array}\\right],\\left[\\begin{array}{ll}\\boldsymbol{\\Sigma}_{x x} & \\boldsymbol{\\Sigma}_{x y} \\\\ \\boldsymbol{\\Sigma}_{y x} & \\boldsymbol{\\Sigma}_{y y}\\end{array}\\right]\\right) 、的条件分布也是高斯分布： \\begin{aligned} p(\\boldsymbol{x} \\mid \\boldsymbol{y}) &=\\mathcal{N}\\left(\\boldsymbol{\\mu}_{x \\mid y}, \\boldsymbol{\\Sigma}_{x \\mid y}\\right) \\\\ \\boldsymbol{\\mu}_{x \\mid y} &=\\boldsymbol{\\mu}_{x}+\\boldsymbol{\\Sigma}_{x y} \\boldsymbol{\\Sigma}_{y y}^{-1}\\left(\\boldsymbol{y}-\\boldsymbol{\\mu}_{y}\\right) \\\\ \\boldsymbol{\\Sigma}_{x \\mid y} &=\\Sigma_{x x}-\\boldsymbol{\\Sigma}_{x y} \\boldsymbol{\\Sigma}_{y y}^{-1} \\Sigma_{y x} \\end{aligned}这是是的条件分布。 边际分布： p(\\boldsymbol{x})=\\int p(\\boldsymbol{x}, \\boldsymbol{y}) \\mathrm{d} \\boldsymbol{y}=\\mathcal{N}\\left(\\boldsymbol{x} \\mid \\boldsymbol{\\mu}_{x}, \\boldsymbol{\\Sigma}_{x x}\\right) 高斯密度函数的乘积（Product of Gaussian Densities）对于两个高斯函数二者的乘积为：,其中： \\begin{aligned} C &=\\left(A^{-1}+B^{-1}\\right)^{-1} \\\\ c &=C\\left(A^{-1} a+B^{-1} b\\right) \\\\ c &=(2 \\pi)^{-\\frac{D}{2}}|A+B|^{-\\frac{1}{2}} \\exp \\left(-\\frac{1}{2}(a-b)^{\\top}(A+B)^{-1}(a-b)\\right) \\end{aligned}比例常数c也可以写成： c=\\mathcal N(a|b,A+B)=\\mathcal N(b|a,A+B)和运算和线性变换（Sums and Linear Transformations）当两个相互独立的且满足高斯分布的随机变量相加所得到的随机变量也满足高斯分布： p(x+y)=\\mathcal N(\\mu_x+\\mu_y,\\Sigma_x+\\Sigma_y)的均值和协方差可以通过之前提到的和运算的性质得到（） 可以利用加权和来定义一个满足高斯分布的随机变量（或者是将一个高斯随机变量分解成两个不同的满足高斯分布的随机变量）; p(x)=\\alpha p_1(x)+(1-\\alpha)p_2(x), \\ 1\\gt\\alpha\\gt0,(\\mu_1,\\sigma^2_1)\\ne (\\mu_2,\\sigma_2^2)其期望值和方差可以表示为： \\mathbb{E}[x]=\\alpha \\mu_{1}+(1-\\alpha) \\mu_{2}\\mathbb{V}[x]=\\left[\\alpha \\sigma_{1}^{2}+(1-\\alpha) \\sigma_{2}^{2}\\right]+\\left(\\left[\\alpha \\mu_{1}^{2}+(1-\\alpha) \\mu_{2}^{2}\\right]-\\left[\\alpha \\mu_{1}+(1-\\alpha) \\mu_{2}\\right]^{2}\\right) 原书p202有上面两个公式的推导过程，主要就是利用写出对应的定义式，也就是积分的形式，然后再利用积分的性质进行变换。对于方差公式的推导，可以利用方差与期望值之间的关系式。 总方差定律（law of total variance） \\mathbb V_X[x]=\\mathbb E_Y[\\mathbb V_X[x|y]]+\\mathbb V_Y[\\mathbb E_X[x|y]]对一个满足高斯分布的随机变量进行线性变换，即对进行线性变换,可以得到一个均值为0，方差为的高斯变量。而对一个高斯随机变量加上一个常数向量，高斯随机变量的均值会发生变化，但是方差会不发生变化。所以，对一个高斯变量进行线性变换或者是仿射变换都不会改变这个变量的分布。 假设随机变量Y为X经过线性变换之后的随机变量，即,所以有： \\mathbb E[y]=\\mathbb E[Ax]=A\\mathbb E[x]=A\\mu\\mathbb V[y]=\\mathbb V[Ax]=A\\mathbb V[x]A^\\top=A\\Sigma A^\\top所以随机变量Y可以写成： p(y) = \\mathbb N(y|A\\mu, A\\Sigma A^\\top)假设一个随机变量的均值是另一个随机变量经过线性变换之后得到的。假设变换矩阵高斯随机变量有，其均值为，可以表示为： p(\\boldsymbol y)=\\mathcal N(y|\\boldsymbol A\\boldsymbol x,\\Sigma)当我们想要求的概率分布时，可以由、的关系得到,但是当A不可逆时，这时候需要用到伪逆，所以有： x = (AA^\\top)^{-1}A^\\top y所以随机变量的分布为： p(\\boldsymbol{x})=\\mathcal{N}\\left(\\boldsymbol{x} \\mid\\left(\\boldsymbol{A}^{\\top} \\boldsymbol{A}\\right)^{-1} \\boldsymbol{A}^{\\top} \\boldsymbol{y},\\left(\\boldsymbol{A}^{\\top} \\boldsymbol{A}\\right)^{-1} \\boldsymbol{A}^{\\top} \\boldsymbol{\\Sigma} \\boldsymbol{A}\\left(\\boldsymbol{A}^{\\top} \\boldsymbol{A}\\right)^{-1}\\right)从多元高斯分布中取样（Sampling from Multivariate Gaussian Distributions） 取样步骤：In the case of a multivariate Gaussian, this process consists of three stages:first, we need a source of pseudo-random numbers that provide a uniform sample in the interval [0,1];second, we use a non-linear transformation such as the Box-Muller transform (Devroye, 1986) to obtain a sample from a univariate Gaussian;and third, we collate a vector of these samples to obtain a sample from a multivariate standard normal 想要从多维高斯分布中取样，可以利用高斯随机变量线性变换的性质：假设：，所以，所以。其中一种选取A矩阵的方法是使用Cholesky decomposition将协方差矩阵进行拆分。（但是需要矩阵是对称且正定的） 共轭及指数族（Conjugacy and the Exponential Family） 对概率分布的目标：指数族的优点：provides the right balance of generality while retaining favorable computation and inference properties 伯努利分布（Bernoulli distribution）一次伯努利试验的结果的概率：对于一个二元随机变量有,伯努利分布是由一个连续的参数控制，可以表示为: \\begin{aligned} &p(x|\\mu)=\\mu^x(1-\\mu)^{1-x},\\quad x\\in\\{0,1\\}\\\\ &\\mathbb E[x] = \\mu,\\\\ &\\mathbb V[x]=\\mu(1-\\mu)\\end{aligned}二项式分布（Binomial Distribution）多个伯努利实验的概率分布称为二项式分布：（简单来说第一个参数就是实验次数，第二个参数就是成功概率） \\begin{aligned} p(m \\mid N, \\mu) &=\\left(\\begin{array}{l}N \\\\ m\\end{array}\\right) \\mu^{m}(1-\\mu)^{N-m} \\\\ \\mathbb{E}[m] &=N \\mu \\\\ \\mathbb{V}[m] &=N \\mu(1-\\mu) \\end{aligned}贝塔分布（Beta Distribution）: p(\\mu|\\alpha,\\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\mu^{\\alpha-1}(1-\\mu)^{\\beta-1}\\mathbb E[\\mu] = \\frac{\\alpha}{\\alpha+\\beta},\\quad \\mathbb V[\\mu] = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}其中定义为： \\begin{aligned}&\\Gamma(t):=\\int^\\infin_0x^{t-1}\\operatorname{exp}(-x)dx,\\quad t\\gt0 \\\\ &\\Gamma(t+1)=t\\Gamma(t)\\end{aligned}贝塔函数在不同参数下的图像：贝塔分布在不同参数下的一些特性： 共轭（Conjugacy）先验分布(Prior distribution)先验分布就是你在取得实验观测值以前对一个参数概率分布的 主观判断 比如说你在抛硬币之前，你会认为取得正面的结果的 概率为为0.5当我们假设实验结果的分布满足均匀分布，这时候称为无信息先验(noninformative prior) 也就是说（继续上面的例子）你抛的硬币是不均匀的，所以，取得正面的概率为上的均匀分布，也就是说什么可能都有。随着实验的进行，这样的分布会根据实验结果被不断矫正。这样的概率分布也不会排除一些极端的结果的出现的概率。 共轭先验（Conjugacy Prior）也就是对于一个似然函数的先验分布假设成某种分布，然后利用贝叶斯公式计算出对应的后验分布，有时候得到的结果的形式是一致的。 假设一个二项式分布: p(x|N,\\mu)=\\begin{pmatrix}N\\\\ x \\end{pmatrix}\\mu^x(1-\\mu)^{N-x},\\quad x=0,1,\\dots,N它的参数满足: p(\\mu|\\alpha,\\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\mu^{\\alpha-1}(1-\\mu)^{\\beta-1}假设在x=h时： \\begin{aligned}p(\\mu|x=h,N,\\alpha,\\beta)&\\propto p(x|N,\\mu)p(\\mu|\\alpha,\\beta)\\\\ &\\propto\\mu^h(1-\\mu)^{(N-h)}\\mu^{\\alpha-1}(1-\\mu)^{\\beta-1}\\\\ &= \\mu^{h+\\alpha-1}(1-\\mu)^{(N-h)+\\beta-1} \\\\ &\\propto \\operatorname{Beta}(h+\\alpha,N-h+\\beta)\\end{aligned}所以，可以注意到这里的先验概率分布与后验概率分布的形式是一致的。 似然函数（Likelihood Function）:说明我们观测的数据是在参数下得来的。 由于利用贝叶斯公式计算后验概率分布的时候，需要用到边际分布概率，如果随机变量是连续的，那么就会需要使用积分，这会导致很多不必要的计算。有了先验共轭，我们就 不用计算复杂的含有积分的贝叶斯公式 便可得到后验分布。以下是常见的似然函数的先验共轭： 充分统计量（Sufficient Statistics） 充分统计量：(一个通俗的比喻解释)假设你辛辛苦苦收集的500个数据全都写在了一张纸上，这些数据是给你写论文用的，非常重要。突然有一天你的狗把你这张写满数据的纸吃掉了，这个时候假如你的数据满足正态分布，且你已经提前把这些数据的均值和方差记录在另外一张纸上了，那你的狗也没坏了什么大事——因为这两个充分统计量包含了这500个数据的所有有用信息。sufficient statistics: the idea that there are statistics that will contain all available information that can be inferred from data corresponding to the distribution under consideration. In other words, sufficient statistics carry all the information needed to make inference about the population, that is, they are the statistics that are sufficient to represent the distribution.(像是原先的数据中的一个子集，而这个子集可以代表所有的数据，也就是去除了一些冗余的数据) 如果向量包含的所有的信息，那么将称为充分统计量 接下来是充分统计的严格定义：也就是说一个概率密度函数可以被分解为独立于参数的部分和虽然依赖于但仅仅是依附于的（？） The more interesting case is that p(x | θ) is dependent only on φ(x) and not x itself. In this case, φ(x) is a sufficient statistic for θ. Explain this 所以我们可以使用一部分数据去估计样品分布的参数。 指数族（Exponential Family）对分布的三种可能的抽象：1.已知分布类型和对应的参数2.已知类型，需要根据数据确定此分布类型的参数值。3.考虑这种分布的族。指数族：这里的内积可以是任何类型的内积。但在本节当中只考虑点积。其中的被称为对数分割函数（log-partition function）是一个归一化常数，能保证分布汇总成或者积分成1.为了更好地理解指数族，我们可以将原先的定义式写成： p(\\boldsymbol x|\\boldsymbol\\theta)\\propto\\operatorname{exp}(\\boldsymbol\\theta^\\top\\phi(\\boldsymbol x))这里的参数被称为特征参数或自然参数（natural parameters） 之后给出了几个例子，但是我还是没有形成深刻的理解（待补充） 指数族能够很方便地找出分布的共轭对（conjugate pairs）对于一个随机变量属于指数族，所以有： p(\\boldsymbol{x} \\mid \\boldsymbol{\\theta})=h(\\boldsymbol{x}) \\exp (\\langle\\boldsymbol{\\theta}, \\boldsymbol{\\phi}(\\boldsymbol{x})\\rangle-A(\\boldsymbol{\\theta}))对于所有的指数族成员都能找到一个先验共轭 p(\\boldsymbol{\\theta} \\mid \\gamma)=h_{c}(\\boldsymbol{\\theta}) \\exp \\left(\\left\\langle\\left[\\begin{array}{l}\\gamma_{1} \\\\ \\gamma_{2}\\end{array}\\right],\\left[\\begin{array}{c}\\boldsymbol{\\theta} \\\\ -A(\\boldsymbol{\\theta})\\end{array}\\right]\\right\\rangle-A_{c}(\\boldsymbol{\\gamma})\\right)其中,,其维度为。充分统计量的共轭先验为这是指数族成员的共轭先验的一般形式，可以通过这个一般形式得到指数族成员的共轭先验。 变量变换和逆变换（Change of Variables/Inverse Transform）在本节当中，我们主要讨论当一个随机变量发生变换之后的分布情况。书中主要介绍了两种方法，一种是直接使用定义，另一种是使用换元法/变数法（change-of-variable approach） 、表示随机变量，、表示随机变量在目标空间中的取值。 假设两个随机变量、满足关系,根据定义可以得到的概率分布： P(Y=y) = P(U(X)=y)=P(X=U^{-1}(y))分布函数法（Distribution Function Technique）这里是使用累积分布函数，因为累积分布函数的对变量的偏导就是概率密度函数，所以在运算的过程中可以直接将两个随机变量之间的关系带入即可。假设两个随机变量的分布情况已知: F_Y(y) = P(Y\\le y)=P(U(X)\\le y)=P(X\\le U^{-1}(y))=F_X(U^{-1}(y))f(y)=\\frac{d}{dy}F_Y(y)概率积分变换（probability integral transform） 需要补充 通过这个变换，我们可以先从均匀分布中抽样，然后对抽样样品做对应的变换之后得到目标分布中的抽样结果。同样也可以用于假设性检验，检查样品是否来源于某一种分布当中。 换元（Change of Variables）\\int f(g(x))g'(x)dx=\\int f(u)du, \\quad u=g(x)假设一个随机变量和可逆函数,可以得到：,由概率密度函数的定义： F_Y(y)=P(Y\\le y)=P(U(X)\\le y)因为一个可逆函数在一个区间内严格单调，且如果原函数单调递增则反函数也会是单调递增的，所以： P(U(X)\\le y)=P(U^{-1}(U(X))\\le U^{-1}(y))=P(X\\le U^{-1}(y))=\\int^{U^{-1}(y)}_af(x)dx所以可以得到随机变量Y的累积概率函数： F_Y(y)=\\int^{U^{-1}(y)}_af(x)dx因为概率密度函数可以通过累积概率函数求导得到，即： f(y) = \\frac{d}{dy}F_y(y)=\\frac{d}{dy}\\int^{U^{-1}(y)}_af(x)dx又因为： \\int f\\left(U^{-1}(y)\\right) U^{-1^{\\prime}}(y) \\mathrm{d} y=\\int f(x) \\mathrm{d} x \\quad where \\quad x=U^{-1}(y)将上面二式联立： f(y)=\\frac{\\mathrm{d}}{\\mathrm{d} y} \\int_{a}^{U^{-1}(y)} f_{x}\\left(U^{-1}(y)\\right) U^{-1^{\\prime}}(y) \\mathrm{d} y注意到不是y的函数，所以可以将上式的积分为： f(y)=f_{x}\\left(U^{-1}(y)\\right) \\cdot\\left(\\frac{\\mathrm{d}}{\\mathrm{d} y} U^{-1}(y)\\right)为了让U为增函数和减函数的时候保持形式一致，可以将上式写成下面的形式： f(y)=f_{x}\\left(U^{-1}(y)\\right) \\cdot\\left|\\frac{\\mathrm{d}}{\\mathrm{d} y} U^{-1}(y)\\right|上面这种方法称为换元法（change-of-variable technique）其中，描述了经过变换U之后的体积变化。 对于多元随机变量的也是类似的，但是由于绝对值不能用于多元方程，但是我们可以使用雅可比行列式代替原先的绝对值。由于雅可比矩阵是一个偏导矩阵，且其行列式的值不为0，所以雅可比矩阵的逆是存在的。","link":"/2021/05/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%EF%BC%9A%EF%BC%88%E4%BA%94%EF%BC%89%E6%A6%82%E7%8E%87%E4%B8%8E%E5%88%86%E5%B8%83-Probability-and-Distributions/"},{"title":"机器学习中的数学：（四）矢量积分(Vector Calculus)","text":"单变量微分（Differentiation of Univariate Functions）定义：差商形式正式定义：割线在极限情况下变成切线 多项式导数的推导： \\begin{aligned} \\frac{\\mathrm{d} f}{\\mathrm{~d} x} &=\\lim _{h \\rightarrow 0} \\frac{f(x+h)-f(x)}{h}\\\\ &=\\lim _{h \\rightarrow 0} \\frac{(x+h)^{n}-x^{n}}{h} \\\\ &=\\lim _{h \\rightarrow 0} \\frac{\\sum_{i=0}^{n}\\left(\\begin{array}{l} n \\\\ i \\end{array}\\right) x^{n-i} h^{i}-x^{n}}{h} . \\end{aligned}由于所以： \\begin{aligned} \\frac{\\mathrm{d} f}{\\mathrm{~d} x} &=\\lim _{h \\rightarrow 0} \\frac{\\sum_{i=1}^{n}\\left(\\begin{array}{l} n \\\\ i \\end{array}\\right) x^{n-i} h^{i}}{h} \\\\ &=\\lim _{h \\rightarrow 0} \\sum_{i=1}^{n}\\left(\\begin{array}{c} n \\\\ i \\end{array}\\right) x^{n-i} h^{i-1} \\\\ &=\\lim _{h \\rightarrow 0}\\left(\\begin{array}{l} n \\\\ 1 \\end{array}\\right) x^{n-1}+\\underbrace{\\sum_{i=2}^{n}\\left(\\begin{array}{l} n \\\\ i \\end{array}\\right) x^{n-i} h^{i-1}}_{\\rightarrow 0 \\text { as } h \\rightarrow 0} \\\\ &=\\frac{n !}{1 !(n-1) !} x^{n-1}=n x^{n-1} . \\end{aligned}其中的是组合数 泰勒级数泰勒多项式： 对于在的泰勒级数为:(表示无穷多项都是是连续可微的，？)当时.称为麦克劳林级数(Maclaurin series)泰勒多项式表示对函数的一种近似,多项式的项越多,与原先的函数就越接近.下图中，表示的项展开。 三角函数的泰勒展开： \\begin{aligned} \\cos (x) &=\\sum_{k=0}^{\\infty}(-1)^{k} \\frac{1}{(2 k) !} x^{2 k}, \\\\ \\sin (x) &=\\sum_{k=0}^{\\infty}(-1)^{k} \\frac{1}{(2 k+1) !} x^{2 k+1} . \\end{aligned} 泰勒级数实际上是一种特殊的幂级数： f(x)=\\sum^\\infty_{k=0}a_k(x-c)^k,\\quad 幂级数一些求导法则： 偏导数和梯度（Partial Differentiation and Gradients）偏导数定义： \\begin{aligned} \\frac{\\partial f}{\\partial x_{1}} &=\\lim _{h \\rightarrow 0} \\frac{f\\left(x_{1}+h, x_{2}, \\ldots, x_{n}\\right)-f(x)}{h} \\\\ & \\vdots \\\\ \\frac{\\partial f}{\\partial x_{n}} &=\\lim _{h \\rightarrow 0} \\frac{f\\left(x_{1}, \\ldots, x_{n-1}, x_{n}+h\\right)-f(\\boldsymbol{x})}{h} \\end{aligned}可以将函数对所有变量的偏导数写成一个行向量： \\nabla_{\\boldsymbol{x}} f=\\operatorname{grad} f=\\frac{\\mathrm{d} f}{\\mathrm{~d} \\boldsymbol{x}}=\\left[\\begin{array}{llll} \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_{1}} & \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_{2}} & \\cdots & \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_{n}} \\end{array}\\right] \\in \\mathbb{R}^{1 \\times n}这个式子被称为的梯度或者雅可比矩阵（Jacobian）。对于一个多变量函数的偏导数（，）可以写成矩阵乘法的形式： \\frac{\\mathrm{d} f}{\\mathrm{~d}(s, t)}=\\frac{\\partial f}{\\partial \\boldsymbol{x}} \\frac{\\partial \\boldsymbol{x}}{\\partial(s, t)}=\\underbrace{\\left[\\frac{\\partial f}{\\partial x_{1}} \\quad \\frac{\\partial f}{\\partial x_{2}}\\right]}_{=\\frac{\\partial f}{\\partial \\boldsymbol{x}}} \\underbrace{\\left[\\begin{array}{cc} \\frac{\\partial x_{1}}{\\partial s} & \\frac{\\partial x_{1}}{\\partial t} \\\\ \\frac{\\partial x_{2}}{\\partial s} & \\frac{\\partial x_{2}}{\\partial t} \\end{array}\\right]}_{=\\frac{\\partial \\boldsymbol{x}}{\\partial(s, t)}} . 为了检验梯度计算结果的正确行，可以采用梯度验证（Gradient checking）的方式进行检验：这里用到了有限差分法（Finite difference method，FDM）：FDM are one of the most common approaches to the numerical solution of PDE（partial differential equations）, along with finite element methods.就是将连续函数离散化。 FDM的基本原理就是利用一个很小的数，判断自变量在这个范围中变化时对应的函数值的变化情况是否与梯度相似。 \\frac{d}{d\\theta}J(\\theta)\\approx \\frac{J(\\theta + \\epsilon)-J(\\theta-\\epsilon)}{2\\epsilon}, \\quad \\epsilon\\rightarrow 0 向量值函数的梯度（Gradients of Vector-Valued Functions）这样，就将原先的映射成,对于每一个：,也就是将原先的n维自变量映射成了一个实数。所以： \\frac{\\partial\\boldsymbol f(x)}{\\partial x_i}=\\left[\\begin{array}{cc}\\frac{\\partial f_1(x)}{\\partial x_i}\\\\\\vdots\\\\ \\frac{\\partial f_m(x)}{\\partial x_i} \\end{array}\\right]\\in \\mathbb R^m而一个函数对一个列向量的映射，也就是之前提到梯度，可以写成： \\nabla_{\\boldsymbol{x}} f=\\operatorname{grad} f=\\frac{\\mathrm{d} f}{\\mathrm{~d} \\boldsymbol{x}}=\\left[\\begin{array}{llll} \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_{1}} & \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_{2}} & \\cdots & \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_{n}} \\end{array}\\right] \\in \\mathbb{R}^{1 \\times n}代入上式，得到向量值方程的一阶偏导数： \\begin{aligned} J &=\\nabla_{x} f=\\frac{\\mathrm{d} f(x)}{\\mathrm{d} x}=\\left[\\begin{array}{ccc} \\frac{\\partial f(x)}{\\partial x_{1}} & \\cdots & \\frac{\\partial f(x)}{\\partial x_{n}} \\end{array}\\right] \\\\ &=\\left[\\begin{array}{ccc} \\frac{\\partial f_{1}(x)}{\\partial x_{1}} & \\cdots & \\frac{\\partial f_{1}(x)}{\\partial x_{n}} \\\\ \\vdots & & \\vdots \\\\ \\frac{\\partial f_{m}(x)}{\\partial x_{1}} & \\cdots & \\frac{\\partial f_{m}(x)}{\\partial x_{n}} \\end{array}\\right] \\\\ x &=\\left[\\begin{array}{c} x_{1} \\\\ \\vdots \\\\ x_{n} \\end{array}\\right], \\quad J(i, j)=\\frac{\\partial f_{i}}{\\partial x_{j}} . \\end{aligned}的一阶偏导数称为雅可比矩阵。雅可比矩阵用于求解映射之后图形的比例因子（scaling factor）想要找到比例因子，可以找出对应的变换矩阵，这个矩阵的行列式的绝对值就是面积变化的比例。但是这个适用于线性变换，当面对非线性变换的时候，需要采取另一种策略。想要知道当变化的时候的变化情况，我们可以使用偏导数得到变化信息。所以，雅可比矩阵可以表示相对应的变换矩阵。 非线性的情况时，采用逼近的方式获得比例因子 向量和对应的映射所处的维度与偏导数的关系： 矩阵梯度（Gradients of Matrices）矩阵的梯度的结果可能得到一个高维的矩阵，这种矩阵称为张量（Tensor）两种计算矩阵梯度的方法：一种是直接计算，最后将结果拼装起来，另一种是将矩阵变成一个向量， \\frac{d\\boldsymbol K}{d\\boldsymbol R}\\in \\mathbb R^{(N\\times N)\\times(M\\times N)}\\frac {d K_{pq}}{d\\boldsymbol R}\\in \\mathbb R^{1\\times(M\\times N)}K_{pq}=r_p^\\top r_q=\\sum^M_{m=1}\\boldsymbol R_{mq}\\boldsymbol R_{mp}\\frac{\\partial \\boldsymbol K_{pq}}{\\partial \\boldsymbol R_{ij}}=\\sum_{m=1}^M\\frac{\\partial}{\\partial R_{ij}}R_{mp}R_{mq}=\\partial_{pqij},\\partial_{} \\partial_{p q i j}=\\left\\{\\begin{array}{ll} R_{i q} & \\text { if } j=p, p \\neq q \\\\ R_{i p} & \\text { if } j=q, p \\neq q \\\\ 2 R_{i q} & \\text { if } j=p, p=q \\\\ 0 & \\text { otherwise } \\end{array} .\\right. 计算梯度时有用的恒等式（Useful Identities for Computing Gradients） \\begin{aligned} &\\frac{\\partial}{\\partial \\boldsymbol{X}} \\boldsymbol{f} (\\boldsymbol{X})^{\\top}=\\left(\\frac{\\partial \\boldsymbol{f}(\\boldsymbol{X})}{\\partial \\boldsymbol{X}}\\right)^{\\top}\\\\ &\\frac{\\partial}{\\partial \\boldsymbol{X}} \\operatorname{tr}(\\boldsymbol{f}(\\boldsymbol{X}))=\\operatorname{tr}\\left(\\frac{\\partial \\boldsymbol{f}(\\boldsymbol{X})}{\\partial \\boldsymbol{X}}\\right)\\\\ &\\frac{\\partial}{\\partial \\boldsymbol{X}} \\operatorname{det}(\\boldsymbol{f}(\\boldsymbol{X}))=\\operatorname{det}(\\boldsymbol{f}(\\boldsymbol{X})) \\operatorname{tr}\\left(\\boldsymbol{f}(\\boldsymbol{X})^{-1} \\frac{\\partial \\boldsymbol{f}(\\boldsymbol{X})}{\\partial \\boldsymbol{X}}\\right)\\\\ &\\frac{\\partial}{\\partial \\boldsymbol{X}} \\boldsymbol{f}(\\boldsymbol{X})^{-1}=-\\boldsymbol{f}(\\boldsymbol{X})^{-1} \\frac{\\partial \\boldsymbol{f}(\\boldsymbol{X})}{\\partial \\boldsymbol{X}} \\boldsymbol{f}(\\boldsymbol{X})^{-1}\\\\ &\\frac{\\partial \\boldsymbol{a}^{\\top} \\boldsymbol{X}^{-1} \\boldsymbol{b}}{\\partial \\boldsymbol{X}}=-\\left(\\boldsymbol{X}^{-1}\\right)^{\\top} \\boldsymbol{a} b^{\\top}\\left(\\boldsymbol{X}^{-1}\\right)^{\\top}\\\\ &\\frac{\\partial \\boldsymbol{x}^{\\top} \\boldsymbol{a}}{\\partial \\boldsymbol{x}}=\\boldsymbol{a}^{\\top}\\\\ &\\frac{\\partial \\boldsymbol{a}^{\\top} \\boldsymbol{x}}{\\partial \\boldsymbol{x}}=\\boldsymbol{a}^{\\top}\\\\ &\\frac{\\partial \\boldsymbol{a}^{\\top} \\boldsymbol{X} \\boldsymbol{b}}{\\partial \\boldsymbol{X}}=\\boldsymbol{a} \\boldsymbol{b}^{\\top}\\\\ &\\frac{\\partial \\boldsymbol{x}^{\\top} \\boldsymbol{B} \\boldsymbol{x}}{\\partial \\boldsymbol{x}}=\\boldsymbol{x}^{\\top}\\left(\\boldsymbol{B}+\\boldsymbol{B}^{\\top}\\right)\\\\ &\\frac{\\partial}{\\partial s}(x-A s)^{\\top} W(x-A s)=-2(x-A s)^{\\top} W A \\quad \\text { for symmetric } W\\\\ &(5.108) \\end{aligned} 计算: 反向传播和自动微分（Backpropagation and Automatic Differentiation）为了计算损失函数（Loss Function）的最小值，这时候需要对损失函数对其所有的参数求偏导，也就是求出损失函数的梯度。但是用传统的链式法则会使得中间步骤十分繁琐，所以有了反向传播算法（Backpropagation Algorithm)可以有效地解决损失函数的梯度的问题，并且运算速度与传统的链式法则的计算方式相同。 深度网络的梯度（Gradients in a Deep Network）在深度学习中，一个函数通常是由许多的函数复合而成的。 \\boldsymbol{y}=\\left(f_{K} \\circ f_{K-1} \\circ \\cdots \\circ f_{1}\\right)(\\boldsymbol{x})=f_{K}\\left(f_{K-1}\\left(\\cdots\\left(f_{1}(\\boldsymbol{x})\\right) \\cdots\\right)\\right)后一层神经元会使用前一层神经元的输出值作为该层的输入值，所以有： 为激活函数.是第i层的输出值。 为了训练这个神经网络，我们需要求解出损失函数梯度。假设： f_{0}:=x \\\\ f_{i}:=\\sigma_{i}\\left(A_{i-1} f_{i-1}+b_{i-1}\\right), \\quad i=1, \\ldots, K损失函数为： L(\\theta)=\\|y-f_K(\\theta,x)\\|^2,\\quad \\theta=\\{\\boldsymbol A_0,\\boldsymbol b_0,\\dots, \\boldsymbol A_{K-1},\\boldsymbol b_{K-1}\\}要求解这个函数的最小值，我们需要对损失函数求偏导。 \\begin{aligned} \\frac{\\partial L}{\\partial \\boldsymbol{\\theta}_{K-1}} &=\\frac{\\partial L}{\\partial \\boldsymbol{f}_{K}} \\frac{\\partial \\boldsymbol{f}_{K}}{\\partial \\boldsymbol{\\theta}_{K-1}} \\\\ \\frac{\\partial L}{\\partial \\boldsymbol{\\theta}_{K-2}} &=\\frac{\\partial L}{\\partial \\boldsymbol{f}_{K}}\\frac{\\partial f_{K}}{\\partial f_{K-1}} \\frac{\\partial \\boldsymbol{f}_{K-1}}{\\partial \\boldsymbol{\\theta}_{K-2}}\\\\ \\frac{\\partial L}{\\partial \\boldsymbol{\\theta}_{K-3}} &=\\frac{\\partial L}{\\partial \\boldsymbol{f}_{K}} \\frac{\\partial f_{K}}{\\partial f_{K-1}} \\frac{\\partial \\boldsymbol{f}_{K-1}}{\\partial f_{K-2}} \\frac{\\partial \\boldsymbol{f}_{K-2}}{\\partial \\boldsymbol{\\theta}_{K-3}} \\\\ \\frac{\\partial L}{\\partial \\boldsymbol{\\theta}_{i}} &=\\frac{\\partial L}{\\partial \\boldsymbol{f}_{K}} \\frac{\\partial f_{K}}{\\partial f_{K-1}} \\cdots \\frac{\\partial f_{i+2}}{\\partial f_{i+1}} \\frac{\\partial \\boldsymbol{f}_{i+1}}{\\partial \\boldsymbol{\\theta}_{i}} \\end{aligned}这样看来，当我们需要计算时，我们可以利用之前的简化计算。 \\frac{\\partial L}{\\partial \\boldsymbol\\theta_i}=\\frac{\\partial L}{\\partial \\boldsymbol\\theta_{i+1}}\\frac{\\partial \\boldsymbol f_{i+1}}{\\partial \\boldsymbol\\theta_i} 自动微分（Automatic Differentiation）反向传播算法实际上时自动微分中的一个特例。自动微分类似计算的时候用的还原法，将这些中间步骤用一个变量表示出来： y=f(g(h(x)))=f(g(h(w_0)))=f(g(w_1))=f(w_2)=w_3原始的链式法则： \\frac {dy}{dx}=\\frac{dy}{dw_2}\\frac{dw_2}{dw_1}\\frac{dw_1}{dx}=\\frac{df(w_2)}{dw_2}\\frac{dg(w_1)}{dw_1}\\frac{dh(w_0)}{dx}自动微分有两种模式：向前模式（forward mode）和向后模式（reverse mode）向前模式就是从内层函数到外层函数逐步进行求导，向后模式则是相反。 使用计算图（computational graphs），每个节点代表一个计算过程中的中间变量。例如：用计算图可以表示为： 可以描述为： For\\ \\ i=d+1,\\dots, D :\\quad x_i=g_i(x_{pa(x_i)})其中，表示节点的父节点。表示节点对应的计算函数。 这部分没什么弄懂，后续继续补充。计算图的那个部分。利用上面的关系可以得出： \\frac{df}{dx_i}=\\sum_{j:i\\in Pa(j)}\\frac{df}{dx_i}\\frac{dx_j}{dx_i}=\\sum_{j:i\\in Pa(j)}\\frac{df}{dx_j}\\frac{dg_i}{dx_i}这实际上就是利用链式法则求解出对中间变量的微分。对最后一个中间变量的微分为1 符号微分（Symbolic differentiation）之所以复杂是因为在运算过程中并没有中间变量，所以想要直接编码解决难度较大 高阶偏导数（Higher-Order Derivatives）当我们想要用牛顿法进行优化的时候，二阶偏导数就不得不被使用了。有一个符号需要注意：这个意思时先对y求导，然后再对x求导。海森矩阵（Hessian Matrix）海森矩阵存储函数的二阶偏导数。 \\nabla^2_{x,y}f(x,y)=\\boldsymbol{H}=\\left[\\begin{array}{cc}\\frac{\\partial^{2} f}{\\partial x^{2}} & \\frac{\\partial^{2} f}{\\partial x \\partial y} \\\\ \\frac{\\partial^{2} f}{\\partial x \\partial y} & \\frac{\\partial^{2} f}{\\partial y^{2}}\\end{array}\\right]表示函数在处的曲率 线性化和多元泰勒级数（Linearization and Multivariate Taylor Series）假设一个函数： \\begin{aligned} f: \\mathbb{R}^{D} & \\rightarrow \\mathbb{R} \\\\ \\quad \\boldsymbol{x} & \\mapsto f(\\boldsymbol{x}), \\quad \\boldsymbol{x} \\in \\mathbb{R}^{D} \\end{aligned}在处光滑，设,所以： f(x)=\\sum^\\infty_{k=0}\\frac{D^k_\\boldsymbol xf(x_0)}{k!}\\delta^k为在处的多元泰勒公式。其中,，表示对x的k阶偏导。和都是k阶张量，其中： \\boldsymbol{\\delta}^{k} \\in \\mathbb{R} \\overbrace{D \\times D \\times \\ldots \\times D}^{k \\text { times }}\\boldsymbol{\\delta}^{3}:=\\boldsymbol{\\delta} \\otimes \\boldsymbol{\\delta} \\otimes \\boldsymbol{\\delta}, \\quad \\boldsymbol{\\delta}^{3}[i, j, k]=\\delta[i] \\delta[j] \\delta[k]所以，（第一个中括号是前面偏导向量的索引） D_{\\boldsymbol{x}}^{k} f\\left(\\boldsymbol{x}_{0}\\right) \\boldsymbol{\\delta}^{k}=\\sum_{i_{1}=1}^{D} \\cdots \\sum_{i_{k}=1}^{D} D_{\\boldsymbol{x}}^{k} f\\left(\\boldsymbol{x}_{0}\\right)\\left[i_{1}, \\ldots, i_{k}\\right] \\delta\\left[i_{1}\\right] \\cdots \\delta\\left[i_{k}\\right]下面是上式的前三项： \\begin{array}{l} k=0, \\ldots, 3 \\text { and } \\delta:=x-x_{0}: \\\\ k=0: D_{\\boldsymbol{x}}^{0} f\\left(\\boldsymbol{x}_{0}\\right) \\boldsymbol{\\delta}^{0}=f\\left(\\boldsymbol{x}_{0}\\right) \\in \\mathbb{R} \\\\ k=1: D_{\\boldsymbol{x}}^{1} f\\left(\\boldsymbol{x}_{0}\\right) \\boldsymbol{\\delta}^{1}=\\underbrace{\\nabla_{\\boldsymbol{x}} f\\left(\\boldsymbol{x}_{0}\\right)}_{1 \\times D} \\underbrace{\\delta}_{D \\times 1}=\\sum_{i=1}^{D} \\nabla_{\\boldsymbol{x}} f\\left(\\boldsymbol{x}_{0}\\right)[i] \\delta[i] \\in \\mathbb{R} \\\\ k=2: D_{\\boldsymbol{x}}^{2} f\\left(\\boldsymbol{x}_{0}\\right) \\boldsymbol{\\delta}^{2}=\\operatorname{tr}(\\underbrace{\\boldsymbol{H}\\left(\\boldsymbol{x}_{0}\\right)}_{D \\times D} \\underbrace{\\delta}_{D \\times 1} \\underbrace{\\delta^{\\top}}_{1 \\times D})=\\delta^{\\top} \\boldsymbol{H}\\left(\\boldsymbol{x}_{0}\\right) \\boldsymbol{\\delta} \\\\ =\\sum_{i=1}^{D} \\sum_{j=1}^{D} H[i, j] \\delta[i] \\delta[j] \\in \\mathbb{R} \\\\ k=3: D_{\\boldsymbol{x}}^{3} f\\left(\\boldsymbol{x}_{0}\\right) \\boldsymbol{\\delta}^{3}=\\sum_{i=1}^{D} \\sum_{j=1}^{D} \\sum_{k=1}^{D} D_{x}^{3} f\\left(\\boldsymbol{x}_{0}\\right)[i, j, k] \\delta[i] \\delta[j] \\delta[k] \\in \\mathbb{R} \\end{array}其中表示在处的海森矩阵。 证明？ k=2: D_{\\boldsymbol{x}}^{2} f\\left(\\boldsymbol{x}_{0}\\right) \\boldsymbol{\\delta}^{2}=\\operatorname{tr}(\\underbrace{\\boldsymbol{H}\\left(\\boldsymbol{x}_{0}\\right)}_{D \\times D} \\underbrace{\\delta}_{D \\times 1} \\underbrace{\\delta^{\\top}}_{1 \\times D})=\\delta^{\\top} \\boldsymbol{H}\\left(\\boldsymbol{x}_{0}\\right) \\boldsymbol{\\delta} \\\\ =\\sum_{i=1}^{D} \\sum_{j=1}^{D} H[i, j] \\delta[i] \\delta[j] \\in \\mathbb{R} 补充反向传播（推导）我们想要求的是对损失函数对参数的求导的结果： \\frac{dL}{dv_i},i\\ge N-M+1利用链式法则： \\frac{dL}{dv_i}=\\sum_{j:i\\in Pa(j)}\\frac{dL}{dv_i}\\frac{dv_i}{dv_j}回想我们计算激活值的方法： v_i=\\sigma_i(w_i\\cdot v_{Pa(i)})所以我们可以计算： \\frac{dv_i}{dv_j}=\\sigma_i'(\\boldsymbol w_i\\cdot \\boldsymbol v_{Pa(i)})w_{iq},Pa(i)_q=j举个例子，假设,则激活值为： v_i=\\sigma_i(\\boldsymbol w_i\\cdot \\boldsymbol v_{(2,7,9)})展开即为下面这些式子： \\begin{aligned} \\frac{d v_{i}}{d v_{2}} &=\\sigma_{i}^{\\prime}\\left(\\mathbf{w}_{i} \\cdot \\mathbf{v}_{(2,7,9)}\\right) w_{i 1} \\\\ \\frac{d v_{i}}{d v_{7}} &=\\sigma_{i}^{\\prime}\\left(\\mathbf{w}_{i} \\cdot \\mathbf{v}_{(2,7,9)}\\right) w_{i 2} \\\\ \\frac{d v_{i}}{d v_{9}} &=\\sigma_{i}^{\\prime}\\left(\\mathbf{w}_{i} \\cdot \\mathbf{v}_{(2,7,9)}\\right) w_{i 3} . \\end{aligned}我们用带入到原先的式子中： \\frac{dv_i}{dv_j}=v_i'w_{iq},Pa(i)_q=j对应的向量形式为： \\frac{dv_i}{d\\mathbf v_{Pa(i)}}= v'_i\\mathbf w_i于是我们可以很容易得到：(带入已知式) \\begin{aligned} \\frac{d L}{d \\mathbf{w}_{i}} &=\\frac{d L}{d v_{i}} \\frac{d v_{i}}{d \\mathbf{w}_{i}} \\\\ &=\\frac{d L}{d v_{i}} \\sigma_{i}^{\\prime}\\left(\\mathbf{w} \\cdot \\mathbf{v}_{\\mathrm{Pa}(i)}\\right) \\mathbf{v}_{\\mathrm{Pa}(i)} \\\\ &=\\frac{d L}{d v_{i}} v_{i}^{\\prime} \\mathbf{v}_{\\mathrm{Pa}(i)} \\end{aligned}","link":"/2021/04/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%EF%BC%9A%EF%BC%88%E5%9B%9B%EF%BC%89%E7%9F%A2%E9%87%8F%E7%A7%AF%E5%88%86-Vector-Calculus/"},{"title":"机器学习中的数学：（六）连续优化(Continuous Optimization)","text":"@[toc]在本节中，主要讨论连续优化的两个主要分支：约束优化（constrained optimization）、无约束优化（unconstrained optimization）。在求解一个线性方程的最优问题的时候，可以对方程进行求导，让后让求导得到的式子赋值为0，接触的结果就是驻点（Stationary points），想要知道这个驻点是极大值还是极小值，需要看在该点的二阶导数的的值的情况。由于五次方及以上的高次方程没有代数解（Abel–Ruffini theorem），所以在一些情况下无法求解出求导式子的解析解，这时候我们可以设置一个初始点，为了求解极小值，只需要让点顺着梯度的反方向运动即可，但是这有可能无法得到全局最优解，而是得到一个局部最优解。 梯度下降法（Optimization Using Gradient Descent）梯度下降法是一种一阶优化算法，算法会不断更新参数的值，每一步的变化方向都是梯度的反方向（梯度方向的变化率最大。）梯度下降的目标是： \\min_xf(x)其中，：被称为目标函数（objective function）。在等高线图中，的变化方向与等高线相互垂直。 下面考虑多元方程的优化问题。下降最快的方向就是梯度的反方向,所以： \\boldsymbol{x}_{1}=\\boldsymbol{x}_{0}-\\gamma\\left((\\nabla f)\\left(\\boldsymbol{x}_{0}\\right)\\right)^{\\top}如果步长（step-size）,则 步长/学习率（Step-size）梯度实际上只给出了变化的方向，但是变化的大小是由学习率和当前梯度的绝对值决定的。梯度的绝对值由函数决定，学习率就成为了能够人为控制的变量。假如学习率过小，则取得最优解的耗时会很长，反之可能会在最优解两端左右震荡，也会可能会花费很多的时间求得最优解，在极端情况下还可能会发散。有一种称为自适应梯度法（Adaptive gradient methods）能够在每次迭代的时候更新学习率，以保证代价函数能够“平滑”地移动到最优解点。下面是几个经验性的结论： 每一次迭代代价函数都应该减少，否则减小学习率并撤回当前操作。 当函数值接近最优解点的时候，函数的梯度减少，这个时候应该适当地增大学习率，以加快收敛速度。 我们可以使用梯度下降法求解线性方程：求解一个线性方程就是求解,近似地等价于求解当平方误差最小时，x的取值：（这里使用欧几里得范数） \\min_x \\|Ax-b\\|^2=(Ax-b)^\\top(Ax-b）对上式对x进行求导： \\nabla_x=2(Ax-b)^\\top A这时可以使用梯度下降法求解出x的值。在求解线性方程的时候，梯度下降法的收敛速度由条件数（condition number）决定，即,条件数在本质上就是最大弯曲方向与最小弯曲方向的比率（在等高线图上）预处理子（preconditioner）在求解之前，先进行，使得有一个更好的条件数，其中称为预处理子。实际上就是对数量级进行匹配，使得等高线图上的图像更加均匀，这样能够加快收敛的速度。 带动量项的梯度下降（Gradient Descent With Momentum）当函数数量级不是很匹配的时候（表现在等高线图上就是一个狭长的圆），这时候，在执行梯度下降算法的时候，可能会出现在最优解两端不断震荡的现象，为了改善这种情况，可以给梯度下降赋予一些记忆，这个记忆就是动量项，记录先前一次迭代发生的变化。 \\begin{aligned} \\boldsymbol{x}_{i+1} &=\\boldsymbol{x}_{i}-\\gamma_{i}\\left((\\nabla f)\\left(\\boldsymbol{x}_{i}\\right)\\right)^{\\top}+\\alpha \\Delta \\boldsymbol{x}_{i} \\\\ \\Delta \\boldsymbol{x}_{i} &=\\boldsymbol{x}_{i}-\\boldsymbol{x}_{i-1}=\\alpha \\Delta \\boldsymbol{x}_{i-1}-\\gamma_{i-1}\\left((\\nabla f)\\left(\\boldsymbol{x}_{i-1}\\right)\\right)^{\\top} ,\\alpha\\in[0,1]\\end{aligned} the momentum term is useful since it averages out different noisy estimates of the gradient 随机梯度下降法（Stochastic Gradient Descent）由于在计算梯度的时候需要消耗很多的时间，所以可以考虑求解一个近似解即可并非需要求出精确解。在运行梯度下降的时候，我们需要求解出所有代价函数最小时，所对应的参数的值： L(\\boldsymbol\\theta)=\\sum^N_{n=1}L_n(\\boldsymbol \\theta)我们还可以使用负对数似然的形式表示代价函数： L(\\boldsymbol \\theta)=-\\sum_{n=1}^N\\log p(y_n|\\boldsymbol x_n,\\boldsymbol \\theta)其中为训练数据，为训练目标，为回归模型的参数。我们原先提到的梯度下降是批优化算法，也就是在更新的时候需要用到所有的训练数据。 \\boldsymbol \\theta_{i+1}=\\boldsymbol\\theta_i-\\gamma_i(\\nabla L(\\boldsymbol\\theta_i))^{\\top}=\\boldsymbol\\theta_i-\\gamma_i\\sum^N_{n=1}(\\nabla L_n(\\boldsymbol \\theta_i))^\\top当需要训练大量数据或是对应的方程无法简单地表示出来的时候，利用上式进行梯度下降将会消耗大量的计算资源。其实，我们并不一定需要使用所有的数据，我们可以使用其中的一部分数据进行训练，这种梯度下降法被称为小批量梯度下降法（mini-batch gradient descent）当样品的数量越多，所得到的梯度结果也就越接近真实值，但是也会消耗更多的计算资源。如果我们能够保持每次的数据小批量，那么数据噪音也许会帮助梯度下降算法跳出局部最优解。 在机器学习中有广泛应用，需要进行补充 约束优化和拉格朗格日乘数（Constrained Optimization and Lagrange Multipliers） 约束优化问题可以表示为： \\min_x f(x),s.t \\ g_i(x)\\le0 \\ \\ i = 1,\\cdots,m也可以使用指示函数（indicator function）指示函数可以表示一个元素是否在设定的集合内，用表示： J(x)=f(x)+\\sum^m_{i=1}\\boldsymbol 1(g_i(x))其中是无限阶跃函数（infinite step function）： \\boldsymbol 1(z)=\\left\\{\\begin{aligned} &0\\quad if\\ z\\le0 \\\\ &\\infin \\quad otherwise\\end{aligned}\\right.也就是当取值在约束范围之外时，会有一个无穷大的惩罚。拉格朗日算子 \\begin{aligned} \\mathfrak{L}(\\boldsymbol{x}, \\boldsymbol{\\lambda}) &=f(\\boldsymbol{x})+\\sum_{i=1}^{m} \\lambda_{i} g_{i}(\\boldsymbol{x}) &=f(\\boldsymbol{x})+\\boldsymbol{\\lambda}^{\\top} \\boldsymbol{g}(\\boldsymbol{x}) \\end{aligned}其中为拉格朗日乘子（Lagrange multiplier） 拉格朗日对偶（Lagrangian duality）在优化问题中，对偶是将一个变量（原始变量，primal variables）装换成另一种变量（对偶变量，dual variables）x 对偶问题是看待一个优化问题的两个角度。对偶问题的解是原始问题的一个下界。 原始问题（primal problem）： \\min_x f(x), s.t. \\quad g_i(x)\\le 0\\quad i = 1\\cdots,m对应的对偶问题（Lagrangian Dual Problem）:（将原始的问题转化成拉格朗日算子表示的式子） \\max_{\\lambda\\in\\mathbb R^m}\\mathfrak D(\\lambda),\\quad s.t.\\ \\lambda\\ge 0这里为对偶变量（dual variable）， 这里需要补充几点知识： 1.极大极小不等式（minimax inequality）对于任意一个有两个参数的函数有： \\max _{\\boldsymbol{y}} \\min _{\\boldsymbol{x}} \\varphi(\\boldsymbol{x}, \\boldsymbol{y}) \\leqslant \\min _{\\boldsymbol{x}} \\max _{\\boldsymbol{y}} \\varphi(\\boldsymbol{x}, \\boldsymbol{y})2.弱对偶（weak duality）原始变量对偶变量（duality gap） 下面的内容需要想想为什么？（为什么是下界，二者的关系是什么？） 当时，是代价函数的下界。所以： J(x)=\\max_{\\lambda\\ge0}\\mathfrak L(x,\\lambda)同时我们原先先要解决的问题是找到J(x)最小时的参数的值所以： \\min_{x\\in\\mathbb R^d}\\max_{\\lambda\\ge0}\\mathfrak L(x,\\lambda)再利用之前的极大极小不等式: \\min _{x \\in \\mathbb{R}^{d}} \\max _{\\boldsymbol{\\lambda} \\geqslant 0} \\mathfrak{L}(\\boldsymbol{x}, \\boldsymbol{\\lambda}) \\geqslant \\max _{\\boldsymbol{\\lambda} \\geqslant 0} \\min _{\\boldsymbol{x} \\in \\mathbb{R}^{d}} \\mathfrak{L}(\\boldsymbol{x}, \\boldsymbol{\\lambda}) .这也是弱对偶。这时候将问题转化成了,一个无约束的问题。 等式约束（Equality Constraints）： \\begin{array}{rl} \\min _{\\boldsymbol{x}} & f(\\boldsymbol{x}) \\\\ \\text { subject to } & g_{i}(\\boldsymbol{x}) \\leqslant 0 \\quad \\text { for all } \\quad i=1, \\ldots, m \\\\ & h_{j}(\\boldsymbol{x})=0 \\quad \\text { for all } \\quad j=1, \\ldots, n . \\end{array}其中的等式可以用两个不等式表示，然后就可以继续使用拉格朗日乘子了。（有一些需要补充） 凸优化（Convex Optimization） 注意一点：国内外对凹凸函数的定义有时相反 当一个优化问题的目标函数为凸函数，约束条件为凸集时，称这种问题为凸优化问题强对偶（strong duality）：原始问题和对偶问题的最优化结果是一致的。凸集:对于一个凸集（convex set）,如果任意的和任意的标量有： \\theta x+(1-\\theta)y\\in \\mathcal C其实凸集就是凸函数上方形成的一个区域中的集合，如下图。 凸函数：对于一个函数的定义域是一个凸集，那么如果这个函数是凸函数，则对于定义域内的所有的点、和标量有：（Jensen’s inequality） f(\\theta x+(1-\\theta)y)\\le\\theta f(x)+(1-\\theta)f(y)判断一个函数是否为凸函数，可以使用函数的梯度： f(y)\\ge f(x)+\\nabla_xf(x)^\\top(y-x)如果该函数二阶可导，则只要这个函数的海森矩阵是半正定的 线性规划（Linear Programming）目标函数和约束函数都是线性方程的优化问题 \\min_{x\\in\\mathbb R^d}c^\\top x,\\ s.t.\\ Ax\\le b其中：、这里包含d个变量和m个线性约束条件。对应的拉格朗日式为： \\mathfrak{L}(\\boldsymbol{x}, \\boldsymbol{\\lambda})=\\boldsymbol{c}^{\\top} \\boldsymbol{x}+\\boldsymbol{\\lambda}^{\\top}(\\boldsymbol{A} \\boldsymbol{x})将上式对x进行求导,并设为0，得： c+A^\\top \\lambda=0所以对偶问题为： \\max_{\\lambda\\in\\mathbb R^m}-b^\\top\\lambda,\\ \\ s.t.\\ c+A^\\top\\lambda=0, \\lambda\\ge 0二次规划问题（Quadratic Programming）\\min _{x\\in \\mathbb R^d}\\frac{1}{2}x^\\top Qx+c^\\top\\ \\ s.t.\\ Ax\\le b其中：,其中是一个正定矩阵，目标函数是凸函数（convex)。这种问题被称为二次规划问题。 利用拉格朗日乘子： \\begin{aligned} \\mathfrak{L}(\\boldsymbol{x}, \\boldsymbol{\\lambda}) &=\\frac{1}{2} \\boldsymbol{x}^{\\top} \\boldsymbol{Q} \\boldsymbol{x}+\\boldsymbol{c}^{\\top} \\boldsymbol{x}+\\boldsymbol{\\lambda}^{\\top}(\\boldsymbol{A} \\boldsymbol{x}-\\boldsymbol{b}) \\\\ &=\\frac{1}{2} \\boldsymbol{x}^{\\top} \\boldsymbol{Q} \\boldsymbol{x}+\\left(\\boldsymbol{c}+\\boldsymbol{A}^{\\top} \\boldsymbol{\\lambda}\\right)^{\\top} \\boldsymbol{x}-\\boldsymbol{\\lambda}^{\\top} \\boldsymbol{b} \\end{aligned}对上式进行整理之后，对x进行求导得： Qx+(c+A^\\top\\lambda)=0假设矩阵Q是可逆得： x= -Q^{-1}(c+A^\\top\\lambda)将上面二式联立可以得到拉格朗日对偶： \\mathfrak D(\\lambda)=-\\frac12(c+A^\\top\\lambda)^\\top Q^{-1}(c+A^\\top\\lambda)-\\lambda^\\top b对偶优化问题的解可以由下解得： \\max_{\\lambda\\in\\mathbb R^m}-\\frac 12(c+A^\\top\\lambda)^\\top Q^{-1}(c+A^\\top\\lambda)-\\lambda^\\top b,\\ \\ s.t. \\lambda\\ge 0Legendre-Fenchel变换和凸共轭(Legendre-Fenchel Transform and Convex Conjugate)支撑超平面（supporting hyperplane）：我们可以用一个支撑超平面来表示一个凸函数或者凸集，如下图所示： 凸共轭这也被称为Legendre-Fenchel变换其中，: supremum 上确界 A legendre transformation is a way of transforming a function of some variable into another function of another variable without losing any information. 上下确界：（子集中最大和最小的元素） 这部分需要补充 补充内容Legendre TransformSometime it’s much more easier to work with instead of f(x)\\rightarrow f(s),\\quad f(s) = \\frac{df(x)}{dx}Now we want a function which is changing with s, the function$f^(s)sf^-b$And if we use the transformation again, we will regain the original function: \\begin{aligned}f^{**}(x) & =x^\\top s-f^*(s)\\\\ &=x^\\top s-(s^\\top x - f(x))\\\\ & =f(x) \\end{aligned}Why using it we can solve the optimistics problems pretty fast: f^*(0)=0^\\top x_{\\min}-f(x_{\\min})\\\\f(x_{\\min})=-f^*(0)","link":"/2021/05/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%EF%BC%9A%EF%BC%88%E5%85%AD%EF%BC%89%E8%BF%9E%E7%BB%AD%E4%BC%98%E5%8C%96-Continuous-Optimization/"},{"title":"算法➡数学问题","text":"进制转换8➡10: 123_{oct} = 3 \\times8^0+2\\times8^1+1\\times8^2 = 83_{dec}10➡8: \\left.\\ \\begin{aligned} 83_{dec} \\div 8 = 10 ······3\\\\ 10_{dec}\\div 8 = 1······2\\\\ 1_{dec} \\div8 = 0······1\\\\ \\end{aligned} \\right\\uparrow其他的都是类似的。从低进制到高进制就按照第一种方式，否则按照第二种方式，二者实际上是一个逆过程。其他的可以先转换成十进制，然后再转换成目标进制。 最大公约数与最小公倍数最大公约数可以用于分数运算的时候的化简。 最大公约数最大公约数可以利用欧几里得算法（辗转相除法）进行求解。 设a、b均为正整数，则gcd(a,b) = gcd(b, a%b) 有了递推式之后，还需要一个递归边界，因为0与任意数字a的最大公约数为a，所以可以利用这个作为递归的出口。在这里需要a&gt;b所以应该在先判断a和b的大小。12345678910111213141516171819202122232425262728293031323334int gcd1(int a, int b){ if(a &lt; b){ int temp = a; a = b; b = temp; } if(b == 0) return a; else return gcd(b, a % b);}//等价形式int gcd2(int a, int b){ if(a &lt; b){ int temp = a; a = b; b = temp; } return !b ? a : gcd(b, a % b);}//辗转相除法int gcd3(int a, int b){ if(a &lt; b){ int temp = a; a = b; b = temp; } while(b != 0){ int temp = a % b; a = b; b = temp; } return a; } 素数判断素数素数的定义是除了1和本身之外不能被其他整数整除的一类数。因为假设一个数字k可以整除数字n，那么有所以这里可以得到，也是可以整除n的。这也就是说这两个数一定是一个大于等于sqrt(n)，一个小于sqrt(n)的，所以只需要遍历2~sqrt(n)(范围之内的所有整数，检查是否存在能够整除目标数字的数即可)（反证法，假设该数能够整除目标数字，而能够整除目标数字的数是成对出现的）12345678910bool isPrime(int n){ if(n &lt;= 1)return false; else{//这个else语句是可以不要的 int sqr = sqrt(1.0 * n);//由于sqrt函数需要浮点型，所以这里乘以1.0 for(int i = 2; i &lt;= sqr; ++i){ if(n % i == 0)return false; } return true; }} 素数表的获取由于判断一个数字是否属于素数的时间复杂度为O(),所以想要获取n个素数的时间复杂度为O(n* )123456789101112const int maxn = 101;int prime[maxn], pNum = 0;bool p[maxn] = {0};void Find_Prime(){ for(int i = 1; i &lt; maxn; ++i){ if(isPrime(i) == true){ prime[pNum++] = i; p[i] = true; } }}还有一种算法是欧拉筛选法，其时间复杂度为O(nlong long n) 质因子分解 质因子分解就是将一个非质数分解成素数的乘积，素数在乘积中可以重复出现。 对一个正整数n 来说，如果它存在［2, n］范围内的质因子，要么这些质因子全部小于等于sqrt(n），要么只存在一个大于sqrt(n）的质因子，而其余质因子全部小于等于sqrt(n） 算法思想：求出素数表，然后用输入的参数x与该素数取余数，直到无法被整除，换下一个素数，直到x变成0。之后按照格式进行输出。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//自己写的，水平有限，后续会对此进行优化//判断是否为质数bool isPrime(int x) { if (x &lt; 2)return false; double sq = sqrt(x * 1.0); int num = 2; while (num &lt;= sq) { if (x % num == 0)return false; num++; } return true;}//质数的结构体，包含质数数字本身，以及在分解式中出现的次数struct prime{ int data = 0; int num = 0;};//质因子分解void prime_factorization(int x) { prime prime_list[200]; int index = 0; int copy = x; //考虑到输入参数本身就是质数的情况，边界设置为i&lt;=x for (int i = 2; i &lt;= x; ++i) { if (isPrime(i))prime_list[index++].data = i; } for (int i = 0; i &lt; 10; ++i) { int temp = prime_list[i].data; while (x % temp == 0 &amp;&amp; x != 0) { prime_list[i].num++; x /= temp; } } //输出 printf(\"%d=\", copy); bool flag = true;//标记是否为第一个数字 for (int i = 0; i &lt;= index; ++i) { for (int j = 0; j &lt; prime_list[i].num; ++j) { if (flag != true)printf(\"*\"); //printf(\"*\"); printf(\"%d\", prime_list[i].data); flag = false; } } //getchar();} 大数运算大数乘法将两个数字按照位从小到大从低位到高位依次加入到数组中。将其中的一个乘数从按位从小到大乘以另外一个数，加到数组中。每一位只加上计算结果的个位数，进位加到下一位中。最后的结果数组中可能还会有某一位超过十的数字的位，这时候就取余，调整成各位就可以了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//初级版本，还有在后序进行改进的 void stimuMulti(int a[], int an, int b[],int bn) { //初始化结果数组 int result[100]; fill(result, result + 100, 0); //计算各位的值 for (int i = 1; i &lt;= bn; ++i) { int carry = 0;//进位 int index_result = i;//错位相加（开始的位置错一位） //关键部分 for (int j = 1; j &lt;= an; ++j) { result[index_result++] += (b[i] * a[j]) % 10; carry = (a[j] * b[i]) / 10; result[index_result] += carry; } //将最后一位的下一位作为结束标志 if (i == bn)result[++index_result] = -1; } //调整，将大于十的位调整为小于十 int i = 1; while (result[i++] != -1) { if (result[i] &gt;= 10) { int carry = result[i] / 10; result[i] %= 10; //当最后一位需要进位的时候 if (result[i + 1] == -1) { result[i + 2] = -1; result[i + 1]++; } result[i + 1] += carry; } } //输出 cout &lt;&lt; endl; bool flag = false; for (int j = i - 2; j &gt;= 1; --j) { //将最高位前面的0全部忽略掉 if (result[j] == 0 &amp;&amp; flag == false) { continue; } flag = true; printf(\"%d\", result[j]); } if (flag == false)printf(\"0\"); 几何问题由三点的坐标求所构成的三角形的面积有几个比较常用的计算面积公式： S_{\\Delta ABC} = \\frac 12 \\vert \\vec a\\vert \\vert \\vec b\\vert sin海伦公式： S_{\\Delta ABC} = \\sqrt {p(p-a)(p-b)(p-c)},其中p = \\frac {a+b+c}{2}1234567891011121314151617181920//利用了第一个求面积的公式struct point{ double x,y;};//求两点形成的向量point decPoint(point p1, point p2){ point res; res.x = p1.x - p2.x; res.y = p1.y - p2.y; return res;}//求两向量的叉乘double mutiPoint(point p1, point p2){ return (p1.x*p2.y - p2.x*p1.y);}//求面积double areaOfThreePoint(point a, point b, point c){ return fabs(multipoint(decPoint(B, A), decPonint(C, A))/2.0);} 判断点是否在三角形内针对这个问题有几个虽然麻烦但是十分直观的做法。1.计算该点和三角形三点组成的面积之和，若于三角形面积相等，则该点在三角形内。2.计算该点与三角形所有任意两点组成的夹角之和，判断是否等于360°。还有一种是利用叉乘。想要该点在三角形内，只需要该点在三条边的下面/上面。如果该点在三角形内部，那么该点与三角形三点形成的向量和三角形三条边形成的向量的叉乘的方向是一致的。叉乘的计算方式如下： 设a(x_1,y_1),b(x_2,y_2),则\\vec a×\\vec b = (x_1*y_2-x_1*y_1)\\vec j, \\vec a×\\vec b = \\vert a\\vert \\vert b\\vert*sin(\\theta) 所以可以借用两个向量的叉乘的正负情况，判断二者是否在同一方向上。 算法思想：创建一个方向函数，将三点的坐标作为参数，计算出各边的向量，然后计算出叉乘，将叉乘的结果的正负作为返回值。判断所有的叉乘结果的符号是否都相等。123456789101112131415161718192021222324252627282930313233343536373839404142434445//转载自牛客网https://www.nowcoder.com/questionTerminal/f9c4290baed0406cbbe2c23dd687732c#include &lt;bits/stdc++.h&gt;using namespace std;int direction(double x1, double y1, double x2, double y2, double x3, double y3){ /* 求向量V和点(x3, y3)之间的位置关系，(x1, y1)是V的起点，(x2, y2)是V的终点 */ //得到向量V x2 -= x1; y2 -= y1; //V的起点(x1, y1)与目标点(x3, y3)构成新的向量U x3 -= x1; y3 -= y1; double res = x3 * y2 - x2 * y3;//求两向量U和V的外积（叉积） if(res &lt; 0) return -1;//&lt;0在逆时针方向 if(res == 0) return 0;//=0共线 if(res &gt; 0) return 1;//&gt;0说明点在向量顺时针方向}int main(){ double x1, y1; double x2, y2; double x3, y3; cin &gt;&gt; x1 &gt;&gt; y1; cin &gt;&gt; x2 &gt;&gt; y2; cin &gt;&gt; x3 &gt;&gt; y3; double x4, y4; cin &gt;&gt; x4 &gt;&gt; y4; //(x1, y1)与(x2, y2)构成向量V1 //(x2, y2)与(x3, y3)构成向量V2 //(x3, y3)与(x1, y1)构成向量V3 int res1 = direction(x1, y1, x2, y2, x4, y4); int res2 = direction(x2, y2, x3, y4, x4, y4); int res3 = direction(x3, y3, x1, y1, x4, y4); if(abs(res1 + res2 + res3) == 3){//全-1或全1，表示点(x4, y4)同时在三个向量的同一侧 cout &lt;&lt; \"Yes\"; }else { cout &lt;&lt; \"No\"; } return 0;} 集合问题子集问题原文：https://mp.weixin.qq.com/s/qT6WgR6Qwn7ayZkI3AineA 数学归纳法对于的子集，通过观察发现，原数组的子集跟它子集的子集是有关联的。注意到：Subset_{\\{1,2,3\\}} -Subset_{\\{1,2\\}} = \\{3\\},\\{1,3\\},\\{2,3\\},\\{1,2,3\\}而这个子集又是可以从的子集中，每一个子集加上一个元素3之后的结果。同样，的子集又可以通过的子集加上元素2之后得来。所以， Subset_{\\{1,2,3\\}} = Subset_{\\{1,2\\}} + \\{Subset_{\\{1,2\\}} append \\{3\\}\\}\\\\ Subset_{\\{1,2\\}} = Subset_{\\{1\\}} + \\{Subset_{\\{1\\}} append \\{2\\}\\}\\\\ Subset_{\\{1\\}} = Subset_{\\{\\}} + \\{Subset_{\\{\\}} append \\{1\\}\\}所以可以将空数组作为基元素。 1234567891011121314151617vector&lt;vector&lt;int&gt;&gt; subsets(vector&lt;int&gt;&amp; nums) { // base case，返回一个空集 if (nums.empty()) return {{}}; // 把最后一个元素拿出来 int n = nums.back(); nums.pop_back(); // 先递归算出前面元素的所有子集 vector&lt;vector&lt;int&gt;&gt; res = subsets(nums); int size = res.size(); for (int i = 0; i &lt; size; i++) { // 然后在之前的结果之上追加 res.push_back(res[i]);//这里是将原先的数组赋值了一份过来然后再往结尾的地方加上最后一个元素 res.back().push_back(n); } return res;} 但是这种写法的时间复杂度和空间复杂度很大[O()]，下面用的是回溯法去求解。 回溯法下面是东哥总结的回溯法模板：123456789result = []def backtrack(路径, 选择列表): if 满足结束条件: result.add(路径) return for 选择 in 选择列表: 做选择 backtrack(路径, 选择列表) 撤销选择可以发现，前半部分因为是递归的因素，所以会不断在选择列表中加入元素，当递归全部结束的时候，会不断将原先加入的元素剔除，再进行递归，这个就类似于树的深度优先遍历。123456789101112131415161718192021vector&lt;vector&lt;int&gt;&gt; res;vector&lt;vector&lt;int&gt;&gt; subsets(vector&lt;int&gt;&amp; nums) { // 记录走过的路径 vector&lt;int&gt; track; backtrack(nums, 0, track); return res;}void backtrack(vector&lt;int&gt;&amp; nums, int start, vector&lt;int&gt;&amp; track) { res.push_back(track); // 注意 i 从 start 开始递增 for (int i = start; i &lt; nums.size(); i++) { // 做选择 track.push_back(nums[i]); // 回溯 backtrack(nums, i + 1, track); // 撤销选择 track.pop_back(); }}将这个过程可视化： 由上图可以发现，每个节点都是子集，所以在继续访问节点之前，先将节点信息保存。进行回溯的条件为，判断可供选择元素的数量，体现在循环数组中，当没有元素可供选择的时候，for语句就会退出。这时候就会退出全部算法，或者是退出当前递归层。返回递归的时候，将向量中的元素弹出，并且更新选择列表（体现在递归函数的输入的参数）。注意这里的选择列表的选取方式，这里更新之后的选择列表就是当前标志指针所指的之后的所有元素。 全排列每次都选取一个元素，并做好标记（防止元素被重复选取），然后重新遍历一遍所有元素，与之匹配，直到数组中的数量满足要求，将结果输出。 12345678910111213141516171819202122232425262728//处理排列的idex号位void generateP(int index){ //这是递归边界，前面的元素全部排列完毕，现在是要将数组输出 if (index == n + 1) { for (int i = 1; i &lt;= n; ++i) { printf(\"%d\", p[i]); } printf(\"\\n\"); return; } //遍历检查所有的元素，这里引用了外部的变量n，由主函数定义 for (int x = 1; x &lt;= n; ++x) { //哈希表是来表示索引元素是否已经加入数组了 if (hashTable[x] == false) { p[index] = x;//以x作为头部的时候 hashTable[x] = true;//更新状态 //这里是继续下一位，注意这里还没有将哈希表重置，所以原先作为首部的元素是不会再被赋值了 generateP(index + 1); hashTable[x] = false;//完成递归项中的一个，重置状态 } } count++; return;}","link":"/2021/03/10/%E7%AE%97%E6%B3%95%E2%9E%A1%E6%95%B0%E5%AD%A6%E9%97%AE%E9%A2%98/"},{"title":"计算机教育缺失的一课","text":"Shell 工具和脚本 在bash中，单引号中不会替换变量，双引号会 echo '$HOME' 输出 $HOME echo \"$HOME\" 输出 /home/username !! 会替换成上一条命令 $1 表示函数本身，$2 表示第一个参数，$3 表示第二个参数，依次类推 $? 表示上一条命令的返回值(错误代码) 0 表示成功; 1 表示失败 $# 表示参数个数, $* 表示所有参数, $@ 表示所有参数, $$ 表示当前进程的进程号 /dev/null 是一个特殊的文件，所有写入它的内容都会被丢弃(黑洞文件) 批量创建文件夹 mkdir dir{1..10}，创建文件也可以使用同样的方式。 大括号内部的实际上可以算是一个组合元素 touch {foo,bar}.{py,cpp,c,java} #!/usr/bin/env python 这实际上是在指定这个脚本使用的解释器，这样可以直接使用./script.py来运行脚本，而不需要python script.py 查找文件（夹） find . -name src -type d 查找当前目录下的所有名为src的文件夹 find . -name \"*.tmp\" -exec rm {} \\; 查找当前目录下的所有.tmp文件并删除 grep -R foobar . ls -R 递归列出所有文件 Vim数据整理 sed: Stream Editor 支持使用正则表达式进行查询修改： sed 's/old-text/new-text/g' filename sort: 将内容进行排序 , uniq -c: 统计重复行的次数 sort filename | uniq -c","link":"/2024/06/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%99%E8%82%B2%E7%BC%BA%E5%A4%B1%E7%9A%84%E4%B8%80%E8%AF%BE/"},{"title":"面对对象的续集","text":"1.主要的内容 泛型编程 面对对象的继承关系（底层内容） 书籍： Effective （modern）C++标准库——&gt; 如何用，如何实现 转换函数 conversion function1234567891011121314151617181920class Fraction{public: Fraction(int num, int den = 1) : m_numerator(num), m_denominator(den) { } // 转换函数 operator double() const { return (doubl) (m_numerator / m_denominator); }private: int m_numerator; int m_denominator;}// 调用Fraction f(3, 5);// 先检查是否重载了+，然后尝试将f转换成允许的类型（还是要检查需要的函数是否被重载）double d = 4 + f; non-explicit-one-argument constructor123456789101112131415161718192021222324class Fraction{public: Fraction(int num, int den=1) : m_numerator(num), m_denominator(den){ } Fraction operator+(const Fraction&amp; f){ return Fraction(...); } // 在这里的案例中，会产生歧义，这会报错（这使得两种可以的选择） //operator double() const { // return (doubl) (m_numerator / m_denominator);%%tor / m_denominator); //}private: int m_numerator; int m_denominator;}// 调用Fraction f(3, 5);// 这里会将3转换成Fraction类型，以适应重载函数double d = f + 3; 12345678910111213141516171819202122232425class Fraction{public: // explicit：不会自动调用 explicit Fraction(int num, int den=1) : m_numerator(num), m_denominator(den){ } operator double() const { return (doubl) (m_numerator / m_denominator); } Fraction operator+(const Fraction&amp; f){ return Fraction(...); }private: int m_numerator; int m_denominator;}// 调用Fraction f(3, 5);// 这里3将不能转换为Fraction，会报错（double 无法转换成Fraction）double d = f + 3; 4.pointer-like classes智能指针12345678910111213141516171819202122232425262728293031323334template&lt;class T&gt;class shared_ptr{public: T&amp; operator*() const { return *px; } T* operator-&gt;() const { return px; } shared_ptr(T* p) : px(p){ }private: T* px; long* pn;....};// 调用struct Foo{ .... void method(void) {....}};shared_ptr&lt;Foo&gt; sp(new Foo);Foo f(*sp);// 这里比较特殊，箭头操作符在执行之后会继续对返回值执行操作// 注意这里的→操作符用于获取指针，同时还用于获取指针所指向的类中的方法sp-&gt;method();// 等价px-&gt;method(); 迭代器 5.function-like classes 仿函数我们将任何一个能够接受”（）”（函数调用符号）的东西叫做函数或者时像函数的东西。实际上，就是尝试对”（）“进行重载12345template &lt;class T&gt;struct identity : public unary_function { // 在标准库中会继承这样的base classes const T&amp; operator()(const T&amp; x) const { return x; }}; 6.namespace 经验谈这样在进行测试的时候可以使用重名的函数，不用去想其他的名字（Great thoughts）12345678910111213141516171819202122232425262728using namespace std;// -------------------------------#include&lt;iostream&gt;#include&lt;memory&gt;namespace jj01{ void test_member_template() { ..... }}// --------------------------------# include&lt;iostream&gt;# include&lt;list&gt;namespace jj02{ template&lt;typename T&gt; using Lst = list&lt;T, allocator&lt;T&gt;&gt;; void test_template_param() { ... }}int main (int argc, char** argv){ jj01::test_member_template(); jj02::test_template_template_param();} 9. 成员模板在模板函数中，在被调用之前函数可以被编译，在传入参数之后，这个函数会被重新编译，这可能导致编译失败（不支持的类型）1234567891011121314151617181920212223template &lt;class T1, class T2&gt;struct pair { typedef T1 first_type; typedef T2 second_type; T1 first; T2 second; pair() : first(T1()), second(T2()) { } pair(const T1&amp; a, const T2&amp; b) : first(a), second(b) { } // 成员模板（外部被确定之后，内部还是不确定的） template &lt;class U1, class U2&gt; pair(const pair&lt;U1, U2&gt;&amp; p) // 这里是要求传入的初始值需要能够转换成T类型（一次作为初始化值，是T的子类） : first(p.first), second(p.second)};pair&lt;Derived1, Derived2&gt; p;pair&lt;Base1, Base2&gt;p2(p);|pair&lt;Base1, Base2&gt;p2(pair&lt;Derived1, Derived2&gt;()); 子类指针能够指向父类，但是反之不能 鲤鱼是一种鱼类，但是鱼类不是鲤鱼12Base1* ptr = new Derived1; // up-castshared_ptr&lt;Base1&gt;sptr(new Derived1); // 模拟up-cast 10、11. 模板特化泛化12template &lt;class Key&gt;struct has { }; 特化1234template&lt;&gt;struct hash&lt;char&gt;{ size_t operator() (char x) const { return x; }};偏特化123456789101112131415161718192021222324252627// 数量特化：只对其中一个参数进行特化（不完全特化）template&lt;typename T, typename Alloc=...&gt;class vector{ .....};template &lt;typename Alloc=....&gt;class vector&lt;bool, Alloc&gt;{ .... } // 只有一个参数被指定了// 范围特化：指定特化的范围template &lt;typename T&gt; class C{ ....};// 这里的模板变量与前面的不是同一个template &lt;typename T&gt;class C&lt;T*&gt; // 指定的是任意的指针{ .....};// 调用C&lt;string&gt; obj1;C&lt;string*&gt; obj2; // 调用的函数不同 12.模板模板参数123456789101112131415161718192021template&lt;typename T, template &lt;typename T&gt; class Container &gt;class XCls{private: Container&lt;T&gt; c;public: .....};// ----------------------------template &lt;typename T&gt;using Lst = list&lt;T, allocator&lt;T&gt;&gt;;// ----------------------------// 这种参数能够让用户传入一个未被指定的容器XCls&lt;string, list&gt;mylst1; // 直接使用会报错XCLs&lt;string, Lst&gt; mylst2; 14.三个主题variadic templates(C++11)：数量不确定的模板12345678910111213141516void print(){ // 最后会仅仅传入0个参数，这时候会调用这个重载函数}// ... 实际上是一种操作符了template &lt;typename T, typename... Types&gt;void print(const T&amp; firstArg, const Types&amp;... args){ // 查看包的大小： sizeof...(args) cout &lt;&lt; firstArg &lt;&lt; endl; print(args...); // 递归打印其中的组合的元素}// 调用print(7.5, \"hello\", bitset&lt;16&gt;(377), 42); auto(C++11)123456789list&lt;string&gt; c;...list&lt;string&gt;::iterator ite;ite = find(c.begin(), c.end(), target);// 使用auto，仅用于类型推导auto ite = find(c.begin(), c.end(), target);//但是不能用于申明变量auto ite; // × ranged-base for1234567891011vector&lt;int&gt; vec;....for(auto elem : vec) { // copy .....}// 要修改原始数据，则需要传引用（引用就是指针）for(auto&amp; elem : vec){ elem *= 3;} 15. Reference引用类型一定要设定初值 1234567int x = 0;int* p = &amp;x;int&amp; r = x; // r代表x，现在r, x 都是0。 实际上就是一个别名int x2 = 5;r = x2; // r不能重新代表其他实物，心啊在r, x都是5int&amp; r2 = r; 对象和他的reference大小相同，地址也相同（全都是假象）reference通常不用与声明，而是用于参数类型和返回类型的描述123456// 下面两种函数不能共存.二者之间的签名一致double imag (const double&amp; im);double imag (const double im);// 这时候的函数签名与上面不同double imag (const double&amp; im) const { ... }注意: const也是签名的一部分， 16. 复合&amp;继承关系下的构造和析构123456// 由内到外调用构造函数Derived::Derived(..):Base() {....};// 由外到内调用析构函数Derived::~Derived(...){....~Base()}; 关于vptr和vtbl vtbl: virtual table, 为了实现C++的多态，C++使用了一种动态绑定的技术。这个技术的核心是虚函数表 一个类占用了多少的内存，主要看类中声明的变量。继承不仅仅会继承变量，同时也会继承父类的函数的调用权，所以父类有虚函数，子类一定有。当子类重载虚函数的时候，会重新申请一个函数空间，让对应的虚表中的元素指向这个空间。 这里子类重载了父类的虚函数，所以在子类的虚表中，对应的虚表中的指针会指向一个新的虚函数（B::vfunc1()），所以这三次继承下来，一共会产生四个虚函数。对于p的调用，用C语言写出来是12(*(p-&gt;vptr[n])(p); /*或者图中下方的形式*/ /*这时候，调用出来的函数是不确定的，需要根据p指向的类型进行确定，这个就是动态绑定（虚机制）*/静态绑定&amp;动态绑定动态绑定的条件： 通过指针调用函数 有一个向上的转型（子类调用，到时候会调用子类的重载函数） 调用的是虚函数 18.关于this在C++类中，都有一个隐藏的参数this 19. 动态绑定关于const：const对象能够调用const函数，不能调用非const函数，非const对象两者都可以调用。实际上一个常量对象会被多个用户使用（指向同一个对象），当某一个用户需要修改的对象的时候，只需要将其做一份拷贝，这个过程称为Copy on Write. 所以，设置两种不同的函数，一种给常量对象调用，一种是给非常量对象调用，同时，在C++中，规定常量成员函数的const和non-const版本同时存在，const对象只能调用const版本，non-const只能调用non-const版本。 22.示例当一个对象拥有虚函数的时候，则对应的会多出一个指针（虚指针）构建对象数组的时候，每一个元素都会调用一次构造函数分配数组内存的时候，会额外申请一块，用于记录数组的大小（多一个counter） 23.重载new() &amp; delete()前提：1.每一版本的声明都必须是独特的参数列表，参数列表的第一参数必须是size_t，其余参数以new所指定的placement arguments为初值，出现在new(...)小括号内的就是placement arguments。123void* operator new(size_t size, long extra){ return malloc(size + extra);}","link":"/2022/10/12/%E9%9D%A2%E5%AF%B9%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%BB%AD%E9%9B%86/"},{"title":"面对对象编程","text":"1.C++编程简介C++: 语言+标准库 2. 头文件与类的声明防卫式声明：123456/* Header file: complex.h*/# ifndef __COMPLEX__# define __COMPLEX__....# endif写任意一个头文件都应该加上这种防卫语句 头文件的布局12345678910111213141516# ifndef __headerName__# ....// 前置声明class className;type&amp; func(type* var1);// 类声明class Name{.....};// 类定义Name::function ...# endif 3. 构造函数函数可以进行重载，编译器会将函数根据函数签名和其中的参数进行编码，以此作为区分。 4.参数传递与返回值当构造函数放在private区域中，外界将不能够直接创建这个类。但是在一种设计模式Singleton中，会将构造函数放在private区域中。 单例类Singleton保证了程序中同一时刻最多存在该类的一个对象。123456789101112131415161718class A{public: static A&amp; getInstance(); setup(){...}private: A(); A(const A&amp; rhs); .....};A&amp; A::getInstance(){ static A a; return a;}//创建A::getInstance().setup(); 传递函数参数由于pass by value 是将变量整体进行传递，当变量比较大的时候，效率比较低，所以在传递参数的时候，应该尽量pass by reference(底层是传递指针)， 这样传递的参数可能会在函数中被修改，所以可以通过传递到const中1234void func(const className&amp;); // 这样传递的方式不会修改传递的值ostream&amp;operator &lt;&lt; (ostream&amp; os, const int&amp; x){....} 返回值传递在返回的时候也应该尽量使用pass by reference 友元函数友元函数可以使用private中的数据。 相同class的各个object互为友元：1234567891011121314151617181920class complex{public: complex (double r = 0, double i = 0) : re (r), im (i) { } int func(const complex&amp; param) { return param.re + param.im; }private: double re, im;}/******************************************************************/{ complex c1(2,1); complex c2; c2.func(c1);} 设计类的几个要点 数据尽量放在private中 参数、返回值尽量pass by reference（可能） 需要加const尽量加 构造函数尽量使用冒号的赋值方法 什么时候不能返回引用一些参数通过一些操作之后的结果，需要在函数中申请一个空间存储这个结果，但是在函数结束的时候，这个空间就会被释放掉，这时候再返回原先这里的地址就没有意义了。（局部变量在函数结束的时候被删除）12345678910111213inline complex&amp;__doapl(complex* ths, const complex&amp; r) // 第一个参数会被改变，第二不会{ ths-&gt;re += r.re; ths-&gt;im += r.im; return *ths;*}inline complex&amp;complex::operator += (const complex&amp; r){ return __doapl (this, r);} 4. 操作符重载与临时对象操作符重载中包含一个隐藏参数this（不能写出来） 12345678910111213141516// do assinment plus(doapl)inline complex&amp; // 用reference速度快 __adopl(complex* ths, const complexr){ ths-&gt;re += r.re; ths-&gt;im += r.im; return *ths; // 返回该地址上的值}// c1 += c2 时，可以改用void接受，但是当连加出现时（c3 += c2 += c1）时，不行inline complex&amp; complex::operator += (const complex&amp; r){ // 使用这种方法的原因是可复用性 return __adopl (this, r); // this在参数列表中不能写出来，但是能够使用} 传递者无需知道接受者是以reference形式接受非成员函数（无this）：12345678910111213inline complex // 不能返回引用，因为这里返回的必定时局部对象operator = (const complex&amp; x, const complex&amp; y){ return complex ( real (x) + real (y) , imag (x) + imag (y)) ;}inline complexoperator + (const complex&amp; x, double y){ return complex (real (x) + y, imag (x)); // 临时对象（无名称，STL用得多）}.... 12345678{ complex c1(2,1); complex c2; complex c3 = c1 + c2; complex c4 = c1 + 4; complex c5 = 4 + c1;} 123456789// 这种重载函数只能写为全局函数，不能写成成员函数（cout可能不认识你的参数类型， 访问定义的类)// cout的数据类型是iostream， os的状态会被改变（传入的内容改变的）# include &lt;iostream.h&gt; // 不一定放在文件开头ostream&amp; // cout &lt;&lt; c1;时可以使用void接收，但是cout&lt;&lt;c1&lt;&lt;c2;时，不能用void接收operator &lt;&lt; (ostream&amp; os, const complex&amp; x){ return os &lt;&lt; '(' &lt;&lt; real (x) &lt;&lt; ',' &lt;&lt; imag (x) &lt;&lt; ')' ;} 传递的是double类型的时候，传值和传引用效率一样。 7.三大函数：拷贝函数，拷贝复制，析构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#ifndef __MYSTRING__#define __MYSTRING__class String{public: // Big Three String(const char* cstr = 0); // 需要赋值，不能设置为const //如果class中带有指针， 一定不能使用默认版本（符号重载等） String(const String&amp; str); // 拷贝构造 String&amp; operator=(const String&amp; str); // 拷贝复制 ~String(); char* get_c_str() const { return m_data; }private: char* m_data; // 指针占4byte};inlineString::String(const char* cstr = 0){ if(cstr) { m_data = new char[strlen(cstr) + 1]; // 最后还有一个结束符号 strcpy(m_data, cstr); } else{ // 空字符串 m_data = new char[1]; *m_data = '\\0'; }}inline String::~String(){ delete[] m_data; // 释放申请的动态内存}// 拷贝赋值：先将原先的变量中的内容删除，然后将新的内容赋值给这个变量// 返回类型是考虑到了连串的赋值的情况（否则可以将void作为返回类型）inlineString&amp; String::operator=(const String&amp; str) // &amp;：reference{ // &amp;： 取地址 if (this == &amp;str) // 效率高且防止赋值内容的地址被释放，这会报错！ return *this; // 三步 delete[] m_data; m_data = new char[ strlen(str.m_data) + 1 ]; strcpy(m_data, str.m_data); return *this;}#include &lt;iostream.h&gt;ostream&amp; operator&lt;&lt;(ostream&amp; os, const String&amp; str){ os &lt;&lt; str.get_c_str(); return os;}#endif 123// 调用String s3(s1); //拷贝构造s3 = s2; // 拷贝赋值 当类中存在指针成员的时候，必须要有拷贝构造和拷贝赋值使用默认的操作会使得赋值对象和原先的对象指向相同的地址（浅拷贝），你实际上会得到一个别名（alias）。 8.堆，栈与内存管理栈：存在于作用域的一类内存空间。函数本体中声明的任何变量其所使用的内存块都取自这种栈。 堆（heap）：用操作系统分配的一种global内存变量，动态申请的变量的内存会被放到堆中。 stack object: 作用域结束之后会被自动清理static object: 作用域结束之后依旧存在。程序结束才被删除global object: 整个程序结束之后才会删除，可以看成一种static objectheap object: 如果不释放，可能导致内存泄漏，因为在函数中声明的指针变量在作用域结束之后就会被删除，而对应的内存块还被占用着，这时候我们就失去了对这个内存块的控制了。 12345678910111213141516Complex* pc = new Complex(1, 2);// transformed by compilerComplex *pc;// complex 中的私有变量需要的内存大小void* mem = operator new ( sizeof(Complex) ); // allocating the memorypc = static_cast&lt;Complex*&gt;(mem); // change variable typepc-&gt;Complex::Complex(1, 2); // constructor function// DeleteString* ps = new String(\"Hello\");delete ps;// equalString::~String(ps);operator delete(ps); 为了标记占用的内存块，规定在内存块的开头和结尾加上一个cookie标记内存块的大小和状态。 1234String* p = new String[3];delete[] p; // 唤起3次析构函数delete p; // 只调用一次析构函数，导致除了头元素外的元素所在的空间出现内存泄漏 拓展补充：类模板、函数模板及其他static：非static类中，成员函数只有一份，不同类调用的实际上是同一个成员函数，只是传入了不同的成员变量。静态数据，在内存中只有一份，这意味着这个数据对所有类都是一致的。静态函数，没有this 指针，所以不能处理普通数据，只能处理静态数据12345678910111213141516class Account{public: static double m_rate; static void set_rate(const double&amp; x) { m_rate = x; }};// 静态变量需要在类外进行初始化double Account::m_rate = 8.0;int main(){ // 两种调用静态函数的方法 Account::set_rate(5.0); Account a; a.set_rate(7.0);} Singleton中调用静态函数的方法1234567891011121314class A{public: static A&amp; getInstance( return a; ); setup() { ... };private: A(); A(const A&amp; rhs); static A a;};// CallA::getInstance().setup(); 更好的实现方法，单例仅使用的时候才会被构建123456789101112131415161718class A{public: static A&amp; getInstance(); setup() { ... }private: A(); A(const A&amp; rhs); ...};A&amp; A::getInstance(){ static A a; return a;}A::getInstance().setup(); 进一步补充：cout对&lt;&lt;操作符进行了多种多样的重载 类模板类型未指定,在定义类的时候使用。在调用的时候需要指定类型 函数模板函数模板不需要指定类型，可以根据传入变量的类型进行自动推导123456template &lt;class T&gt;inlineconst T&amp; min(const T&amp; a, const T&amp; b){ return b &lt; a ? b : a; // 对于操作数的重载需要在类定义中定义} namespace避免重名函数、类冲突123456// 三种打开方式using namespace std;using std:cout;std::cout &lt;&lt; ; 11.组合与继承复合： 容器中包含其他类型（类似结构体）设计模式：配接（adapter）12345678910111213141516template&lt;class T&gt;class queue{ ....protected: deque&lt;T&gt; c; // 底层容器public: // 所有的方法实际上都是由c中的操作函数完成的 bool empty() const { return c.empty(); } size_type soze() const { return c.size(); } reference front() { return c.front(); } reference back() { return c.back(); } void push(const value_type&amp; x) { c.push_back(x); } void pop() { c.pop_front(); }};复合情况下的构造和析构container -&gt; component 构造由内而外（内部的成分, 默认会调用默认的构造函数） 析构由外而内 委托(Delegation): composition by reference1234567891011121314// file String.cppclass StringRep;class String{public: String(); String(const char* s); String(const String&amp; s); String &amp;operator=(const String&amp; s); ~String(); ....private: // 所有的实现都在这个类中 StringRep* rep; // pimpl} Pimpl(Pointer to implementation) 是一种减少代码依赖和编译时间的C++编程技巧，其基本思想是将一个外部可见类(visible class)的实现细节（一般是所有私有的非虚成员）放在一个单独的实现类(implementation class)中，而在可见类中通过一个私有指针来间接访问该实现类123456789101112# include \"String.hpp\"namespace{class StringRep{friend class String; StringRep(const char* s); ~StringRep(); int count; char* rep;};}String::String(){ .... }这时候多个类实际上共享一组变量，当需要修改的时候，会单独复制一个出来 继承123456789101112struct _List_node_base{ _List_node_base* _M_next; _List_node_base* _M_prev;};template&lt;typename _Tp_&gt;struct _List_node : public _List_node_base // 三种继承public、private、protected{ _Tp _M_data;}; 构造和析构与复合一致（先调用父类的构造函数， 析构则是先执行子类的析构函数）12Derived::Deriveed(...):Base() {....}; Derived::~Derived(...){... ~Base() };base class的构造函数必须是虚函数，否则会出现 undefined behavior 12.虚函数与多态12345678910class Shape{public: virtual void draw() const = 0; // pure virtual: 必须重定义（无法事先定义的函数） virtual void error(const std::string&amp; msg); // impure virtual：有默认定义 int objectID() const; // non-vitual：不希望重定义 ...};class Rectangle: public Shape { ... };class Ellipse: public Shape { ... }; 虚函数继承: Template Method(模板函数法 )1234567891011121314151617181920212223242526// Application frameworkCDocument::OnFileOpen(){ .... Serialize() // 这个函数延缓到子类中实现 .....}// Applicationclass CMyDoc: public CDocument{ virtual Serialize() { ... }};// Call the father function by sonmain(){ CMyDoc myDoc; .... myDoc.OnFileOpen(); // 实际上的调用动作 CDocument::OnFileOpen(&amp;myDoc);}委托+继承******************************* 需要补充 \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* 123456789101112131415161718192021222324252627282930class Subject{ int m_value; vector&lt;Observer*&gt;m_views;public: // 注册 void attach(Observer* obs) { m_views.push_back(obs); } void set_val(int value) { m_value = value; notify(); } // 通知更新数据 void notify() { for (int i = 0; i &lt; m_views.size(); ++i) m_views[i]-&gt;update(this, m_value); }};class Observer{public: virtual void update(Subject* sub, int value);}; ### 13.委托相关设计 ![](https://Baymine.github.io/images/面对对象编程/20220907193955.png) 12345678910111213141516171819202122232425262728class Component{ int value;public: Component(int val) { value=val; } // 不能设置为纯虚函数，因为有一些子类对这个动作是没有定义的 virtual void add(Component*) { } };class Primitive: public Component{public: Primitive(int val): Component(val) {}};class Composite: public Component{ vector&lt;Component*&gt;c;public: Composite(int val): Component(val) { } void add (Component* elem){ c.push_back(elem); } ....}; 为什么父类指针能够指向子类，但是子类指针指向父类可能导致不安全？ 委托+继承将新建的类与框架搭配到一起，需要创建好的类加入到框架的容器中去。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 原型#include&lt;iostream.h&gt;enum imageType{ LAST, SPOT};class Image{public: virtual void draw() = 0; static Image *findAndColone(imageType);protected: virtual imageType returnType() = 0; virtual Image *clone() = 0; static void addPrototype(Image *image) { _prototypes[_nextSlot++] = image; }private: // 存放类原型 static Image *_prototypes[10]; static int _nextSlot;};// 静态变量需要在类外进行初始化Image *Image::_prototypes[];int Imgage::_nextSlot;// 通过变量类型找出需要调用的原型Image *Image::findAndClone(imageType type){ for(int i = 0; i &lt; _nextSlot; i++) if(_prototypes[i]-&gt;returnType() == type) return _prototypes[i]-&gt;clone(); // 得到目标类的一个备份}// 子类class LandSatImage:public Image{ // 创建一个静态的自己，然后放到父类的那个容器中 // 这里需要两个不同的构造函数，一个用于给父类原型时创建类用的，一个时父类在调用这个原型clone时用的，为了将这两种构造函数进行区分，他们的参数之间存在差异 ....} 设计模式模版模式 写代码过程中有种只见树木不见森林的感觉，因为一些主流程被封装起来了。（框架） 晚绑定 找到系统当中的稳定因素，对不稳定因素进行封装。 练习：类图当中区分稳定因素和不稳定因素 策略模式考虑未来的代码的可能的变化。 复用是二进制层面上额复用，不是代码复制粘贴。 多继承：主继承+接口继承，这是一种比较好的编程实践。Java当中是支持接口多继承的 装饰器模式优化理由：使用继承得到的类汪汪是随着需求进行变化，这样子类急剧膨胀，同时充斥着重复代码。 由于继承带来的代码量的提升（在继承过程中的分化，继承类之间存在一定重复的代码，但是他们之间又存在差异） 基类指针作为成员变量，这样在运行时确定具体的类，从而实现不同的功能 组合优于继承 相同的字段往上提，重新写一个类作为接口（马丁福勒思想） 桥模式 主要为了避免一个类在多个维度上拓展功能而出现的类爆炸 这个时候会对类进行拆分，这样使得这两个维度的拓展不会相互影响（其中一个继承其他的功能通过组合的方式加入到类当中） 工厂模式 面向接口编程，将变量声明为一个抽象类 优化场景：在面向接口编程的时候，成员变量是抽象类，但是在创建的时候又需要依赖具体的类 通过面对对象的手段，将所要创建的具体对象工作延迟到子类，从而实现一种拓展（而非更改）的 绕开new 抽象工厂 将一系列相关的类创建过程放到一个类当中 其中方式一系列的工厂方法 原型模式在成员变量当中加入一个原型变量，在使用的时候，通过这个原型变量进行拷贝，从而实现一个新的对象。 当一个对象的创建过程比较复杂的时候，可以使用原型模式，将这个对象的创建过程放到一个类当中，然后通过这个类进行拷贝，从而实现一个新的对象。 构造器 有时候将一个初始化的过程放到一个Init函数当中是为了避免在构造函数当中调用虚函数 由于在构造函数数当中调用虚函数可能导致在子类中调用的是父类的虚函数（因为构造顺序是：先构造父类然后构造子类，这个时候子类的虚函数还不存在，但是父类在构造函数当中已经对其进行调用了。） 分步骤构建一个复杂的对象，其中分步骤是一个稳定的算法，而复杂的各个对象则经常发生变化 单例模式 双检查锁 在加锁之前先检查实例是否为空，之后加锁之后再次检查实例是否为空 避免读的状态不加锁 存在的问题：由于内存读写reorder导致的不安全 在申请空间的时候可能会因为指令重拍，先将地址赋值给单例对象，然后再调用构造函数初始化，这个时候可能会导致其他线程访问到一个未初始化的对象（只有内存地址但是没有构造） 享元模式 用共享技术支持大量细粒度的对象 对象池 门面模式 在子系统内部和外部的解耦，用一个稳定的接口隔离变化体 更加注重架构的层次看整个系统","link":"/2022/10/12/%E9%9D%A2%E5%AF%B9%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B/"},{"title":"论文笔记","text":"@[toc] Multi-band weighted lp norm minimization for image denois内容学习Low rank matrix approximation (LRMA)谱模（Spectral Norm，矩阵的模）： \\|A\\|_{2}=\\sqrt{\\lambda_{\\max }\\left(A^{*} A\\right)}=\\sigma_{\\max }(A)范数的下标表示这个模是在欧几里得空间下的。实际上就是说A的谱模就是A的最大奇异值。矩阵的低秩近似：浅显地理解就是舍弃掉矩阵中地一些行、列，而造成最小的损失。Schatten norms： 其实这个p值代表的是这个范数所在的空间，当p=2时，即为欧几里得空间。 Schatten p-norm ：（） \\|A\\|_{p}=\\left(\\sum_{i=1}^{\\min \\{m, n\\}} \\sigma_{i}^{p}(A)\\right)^{\\frac{1}{p}}当p=2时：Frobenius norm当p=1时：nuclear norm，定义为 \\|A\\|_{*}=\\operatorname{trace}\\left(\\sqrt{A^{*} A}\\right)=\\sum_{i=1}^{\\min \\{m, n\\}} \\sigma_{i}(A)当p=时：Frobenius norm 文中提到了核范数最小化来求解矩阵的低秩逼近，但是容易产生一个问题：”this is likely to overshrink the rank components due to having the same threshold.”所以现在有一个问题，就是如何使用范数最小化来求解矩阵的低秩逼近？ 一个运算符号：arg min在这里表示当这个运算符后面的式子取得最小值的时候，X的值。 复习一下范数：范数实际上就是将一个实数或者虚数向量空间映射到一个非负实数的函数。表现起来像是距离。 软阈值函数（Soft-threshold Function） \\operatorname{soft}(x, T)=\\left\\{\\begin{array}{cc} x+T & x \\leq-T \\\\ 0 & |x| \\leq T \\\\ x-T & x \\geq T \\end{array}\\right. 软阈值函数可以用于求解优化问题： \\argmin_x \\|\\boldsymbol X-\\boldsymbol B\\|^2_F+\\lambda\\|\\boldsymbol X\\|_*此问题最终解的形式就是软阈值函数。 加性高斯白噪声（additive white Gaussian noise）一种用于模拟自然噪音的模型。 Additive white Gaussian noise (AWGN) is a basic noise model used in information theory to mimic the effect of many random processes that occur in nature. The modifiers denote specific characteristics: Additive because it is added to any noise that might be intrinsic to the information system.White refers to the idea that it has uniform power across the frequency band for the information system. It is an analogy to the color white which has uniform emissions at all frequencies in the visible spectrum.Gaussian because it has a normal distribution(正态分布) in the time domain with an average time domain value of zero. 时域（Time domain）:描述数学函数或物理信号对时间的关系.就是描述函数随时间变化的情况。 正则化（regularization）正则化是为了防止问题过拟合，在拟合方程中加上一些惩罚项，以减少拟合的参数。 regularization is the process of adding information in order to solve an ill-posed problem or to prevent overfitting.The regularization term, or penalty, imposes a cost on the optimization function to make the optimal solution unique. 一个正则式往往加到代价函数中： \\min_f \\sum^n_{i=1}V(f(x_i),y_i)+\\lambda R(f)其中，V为代价函数，表示预测值与之间的差距，是一个控制正则式权重的项。为对f函数复杂程度的惩罚函数。 拉格朗日乘数（Lagrange multiplier）拉格朗日乘数是一种用于求解线性约束问题中的极大值或者极小值的策略。主要思想就是将一个约束问题转化成一个非约束问题。大致可以描述为：一个函数在线性约束下的最优问题，这样可以得到拉格朗日函数(Lagrangian Function): \\mathcal L(x,\\lambda)=f(x)-\\lambda g(x)Optimization by Simulated AnnealingMetropolis algorithmMarkvo ChainA Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.概率的无记忆性（memorylessness）：In other words, conditional on the present state of the system, its future and past states are independent. \\Pr(X_{n+1}=x\\mid X_{1}=x_{1},X_{2}=x_{2},\\ldots ,X_{n}=x_{n})=\\Pr(X_{n+1}=x\\mid X_{n}=x_{n})Travelling salesman problem Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city?” Heuristic (computer science)In mathematical optimization and computer science, heuristic (from Greek εὑρίσκω “I find, discover”) is a technique designed for solving a problem more quickly when classic methods are too slow, or for finding an approximate solution when classic methods fail to find any exact solution.","link":"/2021/04/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"bugs","slug":"bugs","link":"/tags/bugs/"},{"name":"侯捷C++","slug":"侯捷C","link":"/tags/%E4%BE%AF%E6%8D%B7C/"},{"name":"OS","slug":"OS","link":"/tags/OS/"},{"name":"C++ primer","slug":"C-primer","link":"/tags/C-primer/"},{"name":"DB","slug":"DB","link":"/tags/DB/"},{"name":"Projects","slug":"Projects","link":"/tags/Projects/"},{"name":"computer network","slug":"computer-network","link":"/tags/computer-network/"},{"name":"C++","slug":"C","link":"/tags/C/"}],"categories":[],"pages":[]}